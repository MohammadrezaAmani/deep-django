{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#\n",
    "# Copyright 2016 Confluent Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "\n",
    "from verifiable_client import VerifiableClient\n",
    "\n",
    "from confluent_kafka import Consumer, KafkaError, KafkaException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerifiableConsumer(VerifiableClient):\n",
    "    \"\"\"\n",
    "    confluent-kafka-python backed VerifiableConsumer class for use with\n",
    "    Kafka's kafkatests client tests.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, conf):\n",
    "        \"\"\"\n",
    "        conf is a config dict passed to confluent_kafka.Consumer()\n",
    "        \"\"\"\n",
    "        super(VerifiableConsumer, self).__init__(conf)\n",
    "        self.conf[\"on_commit\"] = self.on_commit\n",
    "        self.consumer = Consumer(**conf)\n",
    "        self.consumed_msgs = 0\n",
    "        self.consumed_msgs_last_reported = 0\n",
    "        self.consumed_msgs_at_last_commit = 0\n",
    "        self.use_auto_commit = False\n",
    "        self.use_async_commit = False\n",
    "        self.max_msgs = -1\n",
    "        self.assignment = []\n",
    "        self.assignment_dict = dict()\n",
    "\n",
    "    def find_assignment(self, topic, partition):\n",
    "        \"\"\"Find and return existing assignment based on topic and partition,\n",
    "        or None on miss.\"\"\"\n",
    "        skey = \"%s %d\" % (topic, partition)\n",
    "        return self.assignment_dict.get(skey)\n",
    "\n",
    "    def send_records_consumed(self, immediate=False):\n",
    "        \"\"\"Send records_consumed, every 100 messages, on timeout,\n",
    "        or if immediate is set.\"\"\"\n",
    "        if self.consumed_msgs <= self.consumed_msgs_last_reported + (\n",
    "            0 if immediate else 100\n",
    "        ):\n",
    "            return\n",
    "\n",
    "        if len(self.assignment) == 0:\n",
    "            return\n",
    "\n",
    "        d = {\n",
    "            \"name\": \"records_consumed\",\n",
    "            \"count\": self.consumed_msgs - self.consumed_msgs_last_reported,\n",
    "            \"partitions\": [],\n",
    "        }\n",
    "\n",
    "        for a in self.assignment:\n",
    "            if a.min_offset == -1:\n",
    "                # Skip partitions that havent had any messages since last time.\n",
    "                # This is to circumvent some minOffset checks in kafkatest.\n",
    "                continue\n",
    "            d[\"partitions\"].append(a.to_dict())\n",
    "            a.min_offset = -1\n",
    "\n",
    "        self.send(d)\n",
    "        self.consumed_msgs_last_reported = self.consumed_msgs\n",
    "\n",
    "    def send_assignment(self, evtype, partitions):\n",
    "        \"\"\"Send assignment update, evtype is either 'assigned' or 'revoked'\"\"\"\n",
    "        d = {\n",
    "            \"name\": \"partitions_\" + evtype,\n",
    "            \"partitions\": [\n",
    "                {\"topic\": x.topic, \"partition\": x.partition} for x in partitions\n",
    "            ],\n",
    "        }\n",
    "        self.send(d)\n",
    "\n",
    "    def on_assign(self, consumer, partitions):\n",
    "        \"\"\"Rebalance on_assign callback\"\"\"\n",
    "        old_assignment = self.assignment\n",
    "        self.assignment = [AssignedPartition(p.topic, p.partition) for p in partitions]\n",
    "        # Move over our last seen offsets so that we can report a proper\n",
    "        # minOffset even after a rebalance loop.\n",
    "        for a in old_assignment:\n",
    "            b = self.find_assignment(a.topic, a.partition)\n",
    "            b.min_offset = a.min_offset\n",
    "\n",
    "        self.assignment_dict = {a.skey: a for a in self.assignment}\n",
    "        self.send_assignment(\"assigned\", partitions)\n",
    "\n",
    "    def on_revoke(self, consumer, partitions):\n",
    "        \"\"\"Rebalance on_revoke callback\"\"\"\n",
    "        # Send final consumed records prior to rebalancing to make sure\n",
    "        # latest consumed is in par with what is going to be committed.\n",
    "        self.send_records_consumed(immediate=True)\n",
    "        self.do_commit(immediate=True, asynchronous=False)\n",
    "        self.assignment = list()\n",
    "        self.assignment_dict = dict()\n",
    "        self.send_assignment(\"revoked\", partitions)\n",
    "\n",
    "    def on_commit(self, err, partitions):\n",
    "        \"\"\"Offsets Committed callback\"\"\"\n",
    "        if err is not None and err.code() == KafkaError._NO_OFFSET:\n",
    "            self.dbg(\"on_commit(): no offsets to commit\")\n",
    "            return\n",
    "\n",
    "        # Report consumed messages to make sure consumed position >= committed position\n",
    "        self.send_records_consumed(immediate=True)\n",
    "\n",
    "        d = {\"name\": \"offsets_committed\", \"offsets\": []}\n",
    "\n",
    "        if err is not None:\n",
    "            d[\"success\"] = False\n",
    "            d[\"error\"] = str(err)\n",
    "        else:\n",
    "            d[\"success\"] = True\n",
    "            d[\"error\"] = \"\"\n",
    "\n",
    "        for p in partitions:\n",
    "            pd = {\"topic\": p.topic, \"partition\": p.partition, \"offset\": p.offset}\n",
    "            if p.error is not None:\n",
    "                pd[\"error\"] = str(p.error)\n",
    "            d[\"offsets\"].append(pd)\n",
    "\n",
    "        if len(self.assignment) == 0:\n",
    "            self.dbg(\n",
    "                \"Not sending offsets_committed: No current assignment: would be: %s\" % d\n",
    "            )\n",
    "            return\n",
    "\n",
    "        self.send(d)\n",
    "\n",
    "    def do_commit(self, immediate=False, asynchronous=None):\n",
    "        \"\"\"Commit every 1000 messages or whenever there is a consume timeout\n",
    "        or immediate.\"\"\"\n",
    "        if (\n",
    "            self.use_auto_commit\n",
    "            or self.consumed_msgs_at_last_commit + (0 if immediate else 1000)\n",
    "            > self.consumed_msgs\n",
    "        ):\n",
    "            return\n",
    "\n",
    "        # Make sure we report consumption before commit,\n",
    "        # otherwise tests may fail because of commit > consumed\n",
    "        if self.consumed_msgs_at_last_commit < self.consumed_msgs:\n",
    "            self.send_records_consumed(immediate=True)\n",
    "\n",
    "        if asynchronous is None:\n",
    "            async_mode = self.use_async_commit\n",
    "        else:\n",
    "            async_mode = asynchronous\n",
    "\n",
    "        self.dbg(\n",
    "            \"Committing %d messages (Async=%s)\"\n",
    "            % (self.consumed_msgs - self.consumed_msgs_at_last_commit, async_mode)\n",
    "        )\n",
    "\n",
    "        retries = 3\n",
    "        while True:\n",
    "            try:\n",
    "                self.dbg(\"Commit\")\n",
    "                offsets = self.consumer.commit(asynchronous=async_mode)\n",
    "                self.dbg(\"Commit done: offsets %s\" % offsets)\n",
    "\n",
    "                if not async_mode:\n",
    "                    self.on_commit(None, offsets)\n",
    "\n",
    "                break\n",
    "\n",
    "            except KafkaException as e:\n",
    "                if e.args[0].code() == KafkaError._NO_OFFSET:\n",
    "                    self.dbg(\"No offsets to commit\")\n",
    "                    break\n",
    "                elif e.args[0].code() in (\n",
    "                    KafkaError.REQUEST_TIMED_OUT,\n",
    "                    KafkaError.NOT_COORDINATOR,\n",
    "                    KafkaError._WAIT_COORD,\n",
    "                ):\n",
    "                    self.dbg(\"Commit failed: %s (%d retries)\" % (str(e), retries))\n",
    "                    if retries <= 0:\n",
    "                        raise\n",
    "                    retries -= 1\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                else:\n",
    "                    raise\n",
    "\n",
    "        self.consumed_msgs_at_last_commit = self.consumed_msgs\n",
    "\n",
    "    def msg_consume(self, msg):\n",
    "        \"\"\"Handle consumed message (or error event)\"\"\"\n",
    "        if msg.error():\n",
    "            self.err(\"Consume failed: %s\" % msg.error(), term=False)\n",
    "            return\n",
    "\n",
    "        if self.verbose:\n",
    "            self.send(\n",
    "                {\n",
    "                    \"name\": \"record_data\",\n",
    "                    \"topic\": msg.topic(),\n",
    "                    \"partition\": msg.partition(),\n",
    "                    \"key\": msg.key(),\n",
    "                    \"value\": msg.value(),\n",
    "                    \"offset\": msg.offset(),\n",
    "                }\n",
    "            )\n",
    "\n",
    "        if self.max_msgs >= 0 and self.consumed_msgs >= self.max_msgs:\n",
    "            return  # ignore extra messages\n",
    "\n",
    "        # Find assignment.\n",
    "        a = self.find_assignment(msg.topic(), msg.partition())\n",
    "        if a is None:\n",
    "            self.err(\n",
    "                \"Received message on unassigned partition %s [%d] @ %d\"\n",
    "                % (msg.topic(), msg.partition(), msg.offset()),\n",
    "                term=True,\n",
    "            )\n",
    "\n",
    "        a.consumed_msgs += 1\n",
    "        if a.min_offset == -1:\n",
    "            a.min_offset = msg.offset()\n",
    "        if a.max_offset < msg.offset():\n",
    "            a.max_offset = msg.offset()\n",
    "\n",
    "        self.consumed_msgs += 1\n",
    "\n",
    "        self.consumer.store_offsets(message=msg)\n",
    "        self.send_records_consumed(immediate=False)\n",
    "        self.do_commit(immediate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AssignedPartition(object):\n",
    "    \"\"\"Local state container for assigned partition.\"\"\"\n",
    "\n",
    "    def __init__(self, topic, partition):\n",
    "        super(AssignedPartition, self).__init__()\n",
    "        self.topic = topic\n",
    "        self.partition = partition\n",
    "        self.skey = \"%s %d\" % (self.topic, self.partition)\n",
    "        self.consumed_msgs = 0\n",
    "        self.min_offset = -1\n",
    "        self.max_offset = 0\n",
    "\n",
    "    def to_dict(self):\n",
    "        \"\"\"Return a dict of this partition's state\"\"\"\n",
    "        return {\n",
    "            \"topic\": self.topic,\n",
    "            \"partition\": self.partition,\n",
    "            \"minOffset\": self.min_offset,\n",
    "            \"maxOffset\": self.max_offset,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description=\"Verifiable Python Consumer\")\n",
    "    parser.add_argument(\"--topic\", action=\"append\", type=str, required=True)\n",
    "    parser.add_argument(\"--group-id\", dest=\"conf_group.id\", required=True)\n",
    "    parser.add_argument(\"--group-instance-id\", dest=\"conf_group.instance.id\")\n",
    "    parser.add_argument(\"--broker-list\", dest=\"conf_bootstrap.servers\", required=True)\n",
    "    parser.add_argument(\"--bootstrap-server\", dest=\"conf_bootstrap.servers\")\n",
    "    parser.add_argument(\n",
    "        \"--session-timeout\", type=int, dest=\"conf_session.timeout.ms\", default=6000\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--enable-autocommit\",\n",
    "        action=\"store_true\",\n",
    "        dest=\"conf_enable.auto.commit\",\n",
    "        default=False,\n",
    "    )\n",
    "    parser.add_argument(\"--max-messages\", type=int, dest=\"max_messages\", default=-1)\n",
    "    parser.add_argument(\n",
    "        \"--assignment-strategy\", dest=\"conf_partition.assignment.strategy\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--reset-policy\", dest=\"topicconf_auto.offset.reset\", default=\"earliest\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--verbose\",\n",
    "        action=\"store_true\",\n",
    "        dest=\"verbose\",\n",
    "        default=False,\n",
    "        help=\"Per-message stats\",\n",
    "    )\n",
    "    parser.add_argument(\"--consumer.config\", dest=\"consumer_config\")\n",
    "    parser.add_argument(\n",
    "        \"-X\",\n",
    "        nargs=1,\n",
    "        dest=\"extra_conf\",\n",
    "        action=\"append\",\n",
    "        help=\"Configuration property\",\n",
    "        default=[],\n",
    "    )\n",
    "    args = vars(parser.parse_args())\n",
    "\n",
    "    conf = {\n",
    "        \"broker.version.fallback\": \"0.9.0\",\n",
    "        # Do explicit manual offset stores to avoid race conditions\n",
    "        # where a message is consumed from librdkafka but not yet handled\n",
    "        # by the Python code that keeps track of last consumed offset.\n",
    "        \"enable.auto.offset.store\": False,\n",
    "    }\n",
    "\n",
    "    if args.get(\"consumer_config\", None) is not None:\n",
    "        args.update(VerifiableClient.read_config_file(args[\"consumer_config\"]))\n",
    "\n",
    "    args.update([x[0].split(\"=\") for x in args.get(\"extra_conf\", [])])\n",
    "\n",
    "    VerifiableClient.set_config(conf, args)\n",
    "\n",
    "    vc = VerifiableConsumer(conf)\n",
    "    vc.use_auto_commit = args[\"conf_enable.auto.commit\"]\n",
    "    vc.max_msgs = args[\"max_messages\"]\n",
    "    vc.verbose = args[\"verbose\"]\n",
    "\n",
    "    vc.dbg(\"Pid %d\" % os.getpid())\n",
    "    vc.dbg(\"Using config: %s\" % conf)\n",
    "\n",
    "    vc.dbg(\"Subscribing to %s\" % args[\"topic\"])\n",
    "    vc.consumer.subscribe(args[\"topic\"], on_assign=vc.on_assign, on_revoke=vc.on_revoke)\n",
    "\n",
    "    failed = False\n",
    "\n",
    "    try:\n",
    "        while vc.run:\n",
    "            msg = vc.consumer.poll(timeout=1.0)\n",
    "            if msg is None:\n",
    "                # Timeout.\n",
    "                # Try reporting consumed messages\n",
    "                vc.send_records_consumed(immediate=True)\n",
    "                # Commit every poll() timeout instead of on every message.\n",
    "                # Also commit on every 1000 messages, whichever comes first.\n",
    "                vc.do_commit(immediate=True)\n",
    "                continue\n",
    "\n",
    "            # Handle message (or error event)\n",
    "            vc.msg_consume(msg)\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        vc.dbg(\"KeyboardInterrupt\")\n",
    "        vc.run = False\n",
    "        pass\n",
    "\n",
    "    except Exception as e:\n",
    "        vc.dbg(\"Terminating on exception: %s\" % str(e))\n",
    "        failed = True\n",
    "\n",
    "    vc.dbg(\"Closing consumer\")\n",
    "    vc.send_records_consumed(immediate=True)\n",
    "\n",
    "    if not failed:\n",
    "        try:\n",
    "            if not vc.use_auto_commit:\n",
    "                vc.do_commit(immediate=True, asynchronous=False)\n",
    "            vc.consumer.close()\n",
    "        except Exception as e:\n",
    "            vc.dbg(\"Ignoring exception while closing: %s\" % str(e))\n",
    "            failed = True\n",
    "\n",
    "    vc.send({\"name\": \"shutdown_complete\", \"failed\": failed})\n",
    "\n",
    "    vc.dbg(\"All done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}