{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#\n",
    "# Copyright 2016-2020 Confluent Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "\n",
    "\"\"\"\n",
    "    Avro schema registry module: Deals with encoding and decoding of messages with avro schemas\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "\n",
    "from confluent_kafka import Consumer, Producer\n",
    "from confluent_kafka.avro.cached_schema_registry_client import (\n",
    "    CachedSchemaRegistryClient,\n",
    ")\n",
    "from confluent_kafka.avro.error import ClientError\n",
    "from confluent_kafka.avro.load import load, loads  # noqa\n",
    "from confluent_kafka.avro.serializer import SerializerError  # noqa\n",
    "from confluent_kafka.avro.serializer import KeySerializerError, ValueSerializerError\n",
    "from confluent_kafka.avro.serializer.message_serializer import MessageSerializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvroProducer(Producer):\n",
    "    \"\"\"\n",
    "    .. deprecated:: 2.0.2\n",
    "\n",
    "    This class will be removed in a future version of the library.\n",
    "\n",
    "    Kafka Producer client which does avro schema encoding to messages.\n",
    "    Handles schema registration, Message serialization.\n",
    "\n",
    "    Constructor arguments:\n",
    "\n",
    "    :param dict config: Config parameters containing url for schema registry (``schema.registry.url``)\n",
    "                        and the standard Kafka client configuration (``bootstrap.servers`` et.al).\n",
    "    :param str default_key_schema: Optional default avro schema for key\n",
    "    :param str default_value_schema: Optional default avro schema for value\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        default_key_schema=None,\n",
    "        default_value_schema=None,\n",
    "        schema_registry=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        warnings.warn(\n",
    "            \"AvroProducer has been deprecated. Use AvroSerializer instead.\",\n",
    "            category=DeprecationWarning,\n",
    "            stacklevel=2,\n",
    "        )\n",
    "\n",
    "        sr_conf = {\n",
    "            key.replace(\"schema.registry.\", \"\"): value\n",
    "            for key, value in config.items()\n",
    "            if key.startswith(\"schema.registry\")\n",
    "        }\n",
    "\n",
    "        if sr_conf.get(\"basic.auth.credentials.source\") == \"SASL_INHERIT\":\n",
    "            # Fallback to plural 'mechanisms' for backward compatibility\n",
    "            sr_conf[\"sasl.mechanism\"] = config.get(\n",
    "                \"sasl.mechanism\", config.get(\"sasl.mechanisms\", \"\")\n",
    "            )\n",
    "            sr_conf[\"sasl.username\"] = config.get(\"sasl.username\", \"\")\n",
    "            sr_conf[\"sasl.password\"] = config.get(\"sasl.password\", \"\")\n",
    "            sr_conf[\"auto.register.schemas\"] = config.get(\"auto.register.schemas\", True)\n",
    "\n",
    "        ap_conf = {\n",
    "            key: value\n",
    "            for key, value in config.items()\n",
    "            if not key.startswith(\"schema.registry\")\n",
    "        }\n",
    "\n",
    "        if schema_registry is None:\n",
    "            schema_registry = CachedSchemaRegistryClient(sr_conf)\n",
    "        elif sr_conf.get(\"url\", None) is not None:\n",
    "            raise ValueError(\n",
    "                \"Cannot pass schema_registry along with schema.registry.url config\"\n",
    "            )\n",
    "\n",
    "        super(AvroProducer, self).__init__(ap_conf, **kwargs)\n",
    "        self._serializer = MessageSerializer(schema_registry)\n",
    "        self._key_schema = default_key_schema\n",
    "        self._value_schema = default_value_schema\n",
    "\n",
    "    def produce(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Asynchronously sends message to Kafka by encoding with specified or default avro schema.\n",
    "\n",
    "        :param str topic: topic name\n",
    "        :param object value: An object to serialize\n",
    "        :param str value_schema: Avro schema for value\n",
    "        :param object key: An object to serialize\n",
    "        :param str key_schema: Avro schema for key\n",
    "\n",
    "        Plus any other parameters accepted by confluent_kafka.Producer.produce\n",
    "\n",
    "        :raises SerializerError: On serialization failure\n",
    "        :raises BufferError: If producer queue is full.\n",
    "        :raises KafkaException: For other produce failures.\n",
    "        \"\"\"\n",
    "        # get schemas from  kwargs if defined\n",
    "        key_schema = kwargs.pop(\"key_schema\", self._key_schema)\n",
    "        value_schema = kwargs.pop(\"value_schema\", self._value_schema)\n",
    "        topic = kwargs.pop(\"topic\", None)\n",
    "        if not topic:\n",
    "            raise ClientError(\"Topic name not specified.\")\n",
    "        value = kwargs.pop(\"value\", None)\n",
    "        key = kwargs.pop(\"key\", None)\n",
    "\n",
    "        if value is not None:\n",
    "            if value_schema:\n",
    "                value = self._serializer.encode_record_with_schema(\n",
    "                    topic, value_schema, value\n",
    "                )\n",
    "            else:\n",
    "                raise ValueSerializerError(\"Avro schema required for values\")\n",
    "\n",
    "        if key is not None:\n",
    "            if key_schema:\n",
    "                key = self._serializer.encode_record_with_schema(\n",
    "                    topic, key_schema, key, True\n",
    "                )\n",
    "            else:\n",
    "                raise KeySerializerError(\"Avro schema required for key\")\n",
    "\n",
    "        super(AvroProducer, self).produce(topic, value, key, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvroConsumer(Consumer):\n",
    "    \"\"\"\n",
    "    .. deprecated:: 2.0.2\n",
    "\n",
    "    This class will be removed in a future version of the library.\n",
    "\n",
    "    Kafka Consumer client which does avro schema decoding of messages.\n",
    "    Handles message deserialization.\n",
    "\n",
    "    Constructor arguments:\n",
    "\n",
    "    :param dict config: Config parameters containing url for schema registry (``schema.registry.url``)\n",
    "                        and the standard Kafka client configuration (``bootstrap.servers`` et.al)\n",
    "    :param schema reader_key_schema: a reader schema for the message key\n",
    "    :param schema reader_value_schema: a reader schema for the message value\n",
    "    :raises ValueError: For invalid configurations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        schema_registry=None,\n",
    "        reader_key_schema=None,\n",
    "        reader_value_schema=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        warnings.warn(\n",
    "            \"AvroConsumer has been deprecated. Use AvroDeserializer instead.\",\n",
    "            category=DeprecationWarning,\n",
    "            stacklevel=2,\n",
    "        )\n",
    "\n",
    "        sr_conf = {\n",
    "            key.replace(\"schema.registry.\", \"\"): value\n",
    "            for key, value in config.items()\n",
    "            if key.startswith(\"schema.registry\")\n",
    "        }\n",
    "\n",
    "        if sr_conf.get(\"basic.auth.credentials.source\") == \"SASL_INHERIT\":\n",
    "            # Fallback to plural 'mechanisms' for backward compatibility\n",
    "            sr_conf[\"sasl.mechanism\"] = config.get(\n",
    "                \"sasl.mechanism\", config.get(\"sasl.mechanisms\", \"\")\n",
    "            )\n",
    "            sr_conf[\"sasl.username\"] = config.get(\"sasl.username\", \"\")\n",
    "            sr_conf[\"sasl.password\"] = config.get(\"sasl.password\", \"\")\n",
    "\n",
    "        ap_conf = {\n",
    "            key: value\n",
    "            for key, value in config.items()\n",
    "            if not key.startswith(\"schema.registry\")\n",
    "        }\n",
    "\n",
    "        if schema_registry is None:\n",
    "            schema_registry = CachedSchemaRegistryClient(sr_conf)\n",
    "        elif sr_conf.get(\"url\", None) is not None:\n",
    "            raise ValueError(\n",
    "                \"Cannot pass schema_registry along with schema.registry.url config\"\n",
    "            )\n",
    "\n",
    "        super(AvroConsumer, self).__init__(ap_conf, **kwargs)\n",
    "        self._serializer = MessageSerializer(\n",
    "            schema_registry, reader_key_schema, reader_value_schema\n",
    "        )\n",
    "\n",
    "    def poll(self, timeout=None):\n",
    "        \"\"\"\n",
    "        This is an overriden method from confluent_kafka.Consumer class. This handles message\n",
    "        deserialization using avro schema\n",
    "\n",
    "        :param float timeout: Poll timeout in seconds (default: indefinite)\n",
    "        :returns: message object with deserialized key and value as dict objects\n",
    "        :rtype: Message\n",
    "        \"\"\"\n",
    "        if timeout is None:\n",
    "            timeout = -1\n",
    "        message = super(AvroConsumer, self).poll(timeout)\n",
    "        if message is None:\n",
    "            return None\n",
    "\n",
    "        if not message.error():\n",
    "            try:\n",
    "                if message.value() is not None:\n",
    "                    decoded_value = self._serializer.decode_message(\n",
    "                        message.value(), is_key=False\n",
    "                    )\n",
    "                    message.set_value(decoded_value)\n",
    "                if message.key() is not None:\n",
    "                    decoded_key = self._serializer.decode_message(\n",
    "                        message.key(), is_key=True\n",
    "                    )\n",
    "                    message.set_key(decoded_key)\n",
    "            except SerializerError as e:\n",
    "                raise SerializerError(\n",
    "                    \"Message deserialization failed for message at {} [{}] offset {}: {}\".format(\n",
    "                        message.topic(), message.partition(), message.offset(), e\n",
    "                    )\n",
    "                )\n",
    "        return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}