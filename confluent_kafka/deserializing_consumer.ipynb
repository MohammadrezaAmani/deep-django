{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Copyright 2020 Confluent Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "\n",
    "from confluent_kafka.cimpl import Consumer as _ConsumerImpl\n",
    "\n",
    "from .error import ConsumeError, KeyDeserializationError, ValueDeserializationError\n",
    "from .serialization import MessageField, SerializationContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeserializingConsumer(_ConsumerImpl):\n",
    "    \"\"\"\n",
    "    A high level Kafka consumer with deserialization capabilities.\n",
    "\n",
    "    `This class is experimental and likely to be removed, or subject to incompatible API\n",
    "    changes in future versions of the library. To avoid breaking changes on upgrading, we\n",
    "    recommend using deserializers directly.`\n",
    "\n",
    "    Derived from the :py:class:`Consumer` class, overriding the :py:func:`Consumer.poll`\n",
    "    method to add deserialization capabilities.\n",
    "\n",
    "    Additional configuration properties:\n",
    "\n",
    "    +-------------------------+---------------------+-----------------------------------------------------+\n",
    "    | Property Name           | Type                | Description                                         |\n",
    "    +=========================+=====================+=====================================================+\n",
    "    |                         |                     | Callable(bytes, SerializationContext) -> obj        |\n",
    "    | ``key.deserializer``    | callable            |                                                     |\n",
    "    |                         |                     | Deserializer used for message keys.                 |\n",
    "    +-------------------------+---------------------+-----------------------------------------------------+\n",
    "    |                         |                     | Callable(bytes, SerializationContext) -> obj        |\n",
    "    | ``value.deserializer``  | callable            |                                                     |\n",
    "    |                         |                     | Deserializer used for message values.               |\n",
    "    +-------------------------+---------------------+-----------------------------------------------------+\n",
    "\n",
    "    Deserializers for string, integer and double (:py:class:`StringDeserializer`, :py:class:`IntegerDeserializer`\n",
    "    and :py:class:`DoubleDeserializer`) are supplied out-of-the-box in the ``confluent_kafka.serialization``\n",
    "    namespace.\n",
    "\n",
    "    Deserializers for Protobuf, JSON Schema and Avro (:py:class:`ProtobufDeserializer`, :py:class:`JSONDeserializer`\n",
    "    and :py:class:`AvroDeserializer`) with Confluent Schema Registry integration are supplied out-of-the-box\n",
    "    in the ``confluent_kafka.schema_registry`` namespace.\n",
    "\n",
    "    See Also:\n",
    "        - The :ref:`Configuration Guide <pythonclient_configuration>` for in depth information on how to configure the client.\n",
    "        - `CONFIGURATION.md <https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md>`_ for a comprehensive set of configuration properties.\n",
    "        - `STATISTICS.md <https://github.com/edenhill/librdkafka/blob/master/STATISTICS.md>`_ for detailed information on the statistics provided by stats_cb\n",
    "        - The :py:class:`Consumer` class for inherited methods.\n",
    "\n",
    "    Args:\n",
    "        conf (dict): DeserializingConsumer configuration.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if configuration validation fails\n",
    "    \"\"\"  # noqa: E501\n",
    "\n",
    "    def __init__(self, conf):\n",
    "        conf_copy = conf.copy()\n",
    "        self._key_deserializer = conf_copy.pop(\"key.deserializer\", None)\n",
    "        self._value_deserializer = conf_copy.pop(\"value.deserializer\", None)\n",
    "\n",
    "        super(DeserializingConsumer, self).__init__(conf_copy)\n",
    "\n",
    "    def poll(self, timeout=-1):\n",
    "        \"\"\"\n",
    "        Consume messages and calls callbacks.\n",
    "\n",
    "        Args:\n",
    "            timeout (float): Maximum time to block waiting for message(Seconds).\n",
    "\n",
    "        Returns:\n",
    "            :py:class:`Message` or None on timeout\n",
    "\n",
    "        Raises:\n",
    "            KeyDeserializationError: If an error occurs during key deserialization.\n",
    "\n",
    "            ValueDeserializationError: If an error occurs during value deserialization.\n",
    "\n",
    "            ConsumeError: If an error was encountered while polling.\n",
    "        \"\"\"\n",
    "\n",
    "        msg = super(DeserializingConsumer, self).poll(timeout)\n",
    "\n",
    "        if msg is None:\n",
    "            return None\n",
    "\n",
    "        if msg.error() is not None:\n",
    "            raise ConsumeError(msg.error(), kafka_message=msg)\n",
    "\n",
    "        ctx = SerializationContext(msg.topic(), MessageField.VALUE, msg.headers())\n",
    "        value = msg.value()\n",
    "        if self._value_deserializer is not None:\n",
    "            try:\n",
    "                value = self._value_deserializer(value, ctx)\n",
    "            except Exception as se:\n",
    "                raise ValueDeserializationError(exception=se, kafka_message=msg)\n",
    "\n",
    "        key = msg.key()\n",
    "        ctx.field = MessageField.KEY\n",
    "        if self._key_deserializer is not None:\n",
    "            try:\n",
    "                key = self._key_deserializer(key, ctx)\n",
    "            except Exception as se:\n",
    "                raise KeyDeserializationError(exception=se, kafka_message=msg)\n",
    "\n",
    "        msg.set_key(key)\n",
    "        msg.set_value(value)\n",
    "        return msg\n",
    "\n",
    "    def consume(self, num_messages=1, timeout=-1):\n",
    "        \"\"\"\n",
    "        :py:func:`Consumer.consume` not implemented, use\n",
    "        :py:func:`DeserializingConsumer.poll` instead\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}