{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Confluent Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "\"\"\"\n",
    "Kafka admin client: create, view, alter, and delete topics and resources.\n",
    "\"\"\"\n",
    "import concurrent.futures\n",
    "import warnings\n",
    "\n",
    "from confluent_kafka import ConsumerGroupState as _ConsumerGroupState\n",
    "from confluent_kafka import (\n",
    "    ConsumerGroupTopicPartitions as _ConsumerGroupTopicPartitions,\n",
    ")\n",
    "from confluent_kafka import IsolationLevel as _IsolationLevel\n",
    "\n",
    "from .._model import TopicCollection as _TopicCollection\n",
    "from ..cimpl import KafkaException  # noqa: F401\n",
    "from ..cimpl import (\n",
    "    OFFSET_INVALID,\n",
    "    KafkaError,\n",
    ")\n",
    "from ..cimpl import TopicPartition as _TopicPartition\n",
    "from ..cimpl import _AdminClientImpl\n",
    "from ._acl import AclOperation  # noqa: F401\n",
    "from ._acl import AclBinding, AclBindingFilter\n",
    "from ._cluster import DescribeClusterResult  # noqa: F401\n",
    "\n",
    "# Unused imports are keeped to be accessible using this public module\n",
    "from ._config import ConfigSource  # noqa: F401\n",
    "from ._config import ConfigResource\n",
    "from ._group import ConsumerGroupListing  # noqa: F401\n",
    "from ._listoffsets import OffsetSpec  # noqa: F401\n",
    "from ._metadata import BrokerMetadata  # noqa: F401\n",
    "from ._resource import ResourceType  # noqa: F401\n",
    "from ._scram import UserScramCredentialAlteration  # noqa: F401\n",
    "from ._scram import (\n",
    "    ScramCredentialInfo,\n",
    "    ScramMechanism,\n",
    "    UserScramCredentialDeletion,\n",
    "    UserScramCredentialUpsertion,\n",
    ")\n",
    "from ._topic import TopicDescription  # noqa: F401\n",
    "\n",
    "try:\n",
    "    string_type = basestring\n",
    "except NameError:\n",
    "    string_type = str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdminClient(_AdminClientImpl):\n",
    "    \"\"\"\n",
    "    AdminClient provides admin operations for Kafka brokers, topics, groups,\n",
    "    and other resource types supported by the broker.\n",
    "\n",
    "    The Admin API methods are asynchronous and return a dict of\n",
    "    concurrent.futures.Future objects keyed by the entity.\n",
    "    The entity is a topic name for create_topics(), delete_topics(), create_partitions(),\n",
    "    and a ConfigResource for alter_configs() and describe_configs().\n",
    "\n",
    "    All the futures for a single API call will currently finish/fail at\n",
    "    the same time (backed by the same protocol request), but this might\n",
    "    change in future versions of the client.\n",
    "\n",
    "    See examples/adminapi.py for example usage.\n",
    "\n",
    "    For more information see the `Java Admin API documentation\n",
    "    <https://docs.confluent.io/current/clients/javadocs/org/apache/kafka/clients/admin/package-frame.html>`_.\n",
    "\n",
    "    Requires broker version v0.11.0.0 or later.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, conf):\n",
    "        \"\"\"\n",
    "        Create a new AdminClient using the provided configuration dictionary.\n",
    "\n",
    "        The AdminClient is a standard Kafka protocol client, supporting\n",
    "        the standard librdkafka configuration properties as specified at\n",
    "        https://github.com/edenhill/librdkafka/blob/master/CONFIGURATION.md\n",
    "\n",
    "        At least 'bootstrap.servers' should be configured.\n",
    "        \"\"\"\n",
    "        super(AdminClient, self).__init__(conf)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_topics_result(f, futmap):\n",
    "        \"\"\"\n",
    "        Map per-topic results to per-topic futures in futmap.\n",
    "        The result value of each (successful) future is None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = f.result()\n",
    "            for topic, error in result.items():\n",
    "                fut = futmap.get(topic, None)\n",
    "                if fut is None:\n",
    "                    raise RuntimeError(\n",
    "                        \"Topic {} not found in future-map: {}\".format(topic, futmap)\n",
    "                    )\n",
    "\n",
    "                if error is not None:\n",
    "                    # Topic-level exception\n",
    "                    fut.set_exception(KafkaException(error))\n",
    "                else:\n",
    "                    # Topic-level success\n",
    "                    fut.set_result(None)\n",
    "        except Exception as e:\n",
    "            # Request-level exception, raise the same for all topics\n",
    "            for topic, fut in futmap.items():\n",
    "                fut.set_exception(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_resource_result(f, futmap):\n",
    "        \"\"\"\n",
    "        Map per-resource results to per-resource futures in futmap.\n",
    "        The result value of each (successful) future is a ConfigResource.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result = f.result()\n",
    "            for resource, configs in result.items():\n",
    "                fut = futmap.get(resource, None)\n",
    "                if fut is None:\n",
    "                    raise RuntimeError(\n",
    "                        \"Resource {} not found in future-map: {}\".format(\n",
    "                            resource, futmap\n",
    "                        )\n",
    "                    )\n",
    "                if resource.error is not None:\n",
    "                    # Resource-level exception\n",
    "                    fut.set_exception(KafkaException(resource.error))\n",
    "                else:\n",
    "                    # Resource-level success\n",
    "                    # configs will be a dict for describe_configs()\n",
    "                    # and None for alter_configs()\n",
    "                    fut.set_result(configs)\n",
    "        except Exception as e:\n",
    "            # Request-level exception, raise the same for all resources\n",
    "            for resource, fut in futmap.items():\n",
    "                fut.set_exception(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_list_consumer_groups_result(f, futmap):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_consumer_groups_result(f, futmap):\n",
    "        \"\"\"\n",
    "        Map per-group results to per-group futures in futmap.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = f.result()\n",
    "            futmap_values = list(futmap.values())\n",
    "            len_results = len(results)\n",
    "            len_futures = len(futmap_values)\n",
    "            if len_results != len_futures:\n",
    "                raise RuntimeError(\n",
    "                    \"Results length {} is different from future-map length {}\".format(\n",
    "                        len_results, len_futures\n",
    "                    )\n",
    "                )\n",
    "            for i, result in enumerate(results):\n",
    "                fut = futmap_values[i]\n",
    "                if isinstance(result, KafkaError):\n",
    "                    fut.set_exception(KafkaException(result))\n",
    "                else:\n",
    "                    fut.set_result(result)\n",
    "        except Exception as e:\n",
    "            # Request-level exception, raise the same for all groups\n",
    "            for _, fut in futmap.items():\n",
    "                fut.set_exception(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_consumer_group_offsets_result(f, futmap):\n",
    "        \"\"\"\n",
    "        Map per-group results to per-group futures in futmap.\n",
    "        The result value of each (successful) future is ConsumerGroupTopicPartitions.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = f.result()\n",
    "            futmap_values = list(futmap.values())\n",
    "            len_results = len(results)\n",
    "            len_futures = len(futmap_values)\n",
    "            if len_results != len_futures:\n",
    "                raise RuntimeError(\n",
    "                    \"Results length {} is different from future-map length {}\".format(\n",
    "                        len_results, len_futures\n",
    "                    )\n",
    "                )\n",
    "            for i, result in enumerate(results):\n",
    "                fut = futmap_values[i]\n",
    "                if isinstance(result, KafkaError):\n",
    "                    fut.set_exception(KafkaException(result))\n",
    "                else:\n",
    "                    fut.set_result(result)\n",
    "        except Exception as e:\n",
    "            # Request-level exception, raise the same for all groups\n",
    "            for _, fut in futmap.items():\n",
    "                fut.set_exception(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_acls_result(f, futmap):\n",
    "        \"\"\"\n",
    "        Map create ACL binding results to corresponding futures in futmap.\n",
    "        For create_acls the result value of each (successful) future is None.\n",
    "        For delete_acls the result value of each (successful) future is the list of deleted AclBindings.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            results = f.result()\n",
    "            futmap_values = list(futmap.values())\n",
    "            len_results = len(results)\n",
    "            len_futures = len(futmap_values)\n",
    "            if len_results != len_futures:\n",
    "                raise RuntimeError(\n",
    "                    \"Results length {} is different from future-map length {}\".format(\n",
    "                        len_results, len_futures\n",
    "                    )\n",
    "                )\n",
    "            for i, result in enumerate(results):\n",
    "                fut = futmap_values[i]\n",
    "                if isinstance(result, KafkaError):\n",
    "                    fut.set_exception(KafkaException(result))\n",
    "                else:\n",
    "                    fut.set_result(result)\n",
    "        except Exception as e:\n",
    "            # Request-level exception, raise the same for all the AclBindings or AclBindingFilters\n",
    "            for resource, fut in futmap.items():\n",
    "                fut.set_exception(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_futmap_result_from_list(f, futmap):\n",
    "        try:\n",
    "            results = f.result()\n",
    "            futmap_values = list(futmap.values())\n",
    "            len_results = len(results)\n",
    "            len_futures = len(futmap_values)\n",
    "            if len_results != len_futures:\n",
    "                raise RuntimeError(\n",
    "                    \"Results length {} is different from future-map length {}\".format(\n",
    "                        len_results, len_futures\n",
    "                    )\n",
    "                )\n",
    "            for i, result in enumerate(results):\n",
    "                fut = futmap_values[i]\n",
    "                if isinstance(result, KafkaError):\n",
    "                    fut.set_exception(KafkaException(result))\n",
    "                else:\n",
    "                    fut.set_result(result)\n",
    "        except Exception as e:\n",
    "            # Request-level exception, raise the same for all topics\n",
    "            for _, fut in futmap.items():\n",
    "                fut.set_exception(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_futmap_result(f, futmap):\n",
    "        try:\n",
    "            results = f.result()\n",
    "            len_results = len(results)\n",
    "            len_futures = len(futmap)\n",
    "            if len(results) != len_futures:\n",
    "                raise RuntimeError(\n",
    "                    f\"Results length {len_results} is different from future-map length {len_futures}\"\n",
    "                )\n",
    "            for key, value in results.items():\n",
    "                fut = futmap.get(key, None)\n",
    "                if fut is None:\n",
    "                    raise RuntimeError(f\"Key {key} not found in future-map: {futmap}\")\n",
    "                if isinstance(value, KafkaError):\n",
    "                    fut.set_exception(KafkaException(value))\n",
    "                else:\n",
    "                    fut.set_result(value)\n",
    "        except Exception as e:\n",
    "            for _, fut in futmap.items():\n",
    "                fut.set_exception(e)\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_future():\n",
    "        f = concurrent.futures.Future()\n",
    "        if not f.set_running_or_notify_cancel():\n",
    "            raise RuntimeError(\"Future was cancelled prematurely\")\n",
    "        return f\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_futures(futmap_keys, class_check, make_result_fn):\n",
    "        \"\"\"\n",
    "        Create futures and a futuremap for the keys in futmap_keys,\n",
    "        and create a request-level future to be bassed to the C API.\n",
    "\n",
    "        FIXME: use _make_futures_v2 with TypeError in next major release.\n",
    "        \"\"\"\n",
    "        futmap = {}\n",
    "        for key in futmap_keys:\n",
    "            if class_check is not None and not isinstance(key, class_check):\n",
    "                raise ValueError(\"Expected list of {}\".format(repr(class_check)))\n",
    "            futmap[key] = AdminClient._create_future()\n",
    "\n",
    "        # Create an internal future for the entire request,\n",
    "        # this future will trigger _make_..._result() and set result/exception\n",
    "        # per topic,future in futmap.\n",
    "        f = AdminClient._create_future()\n",
    "        f.add_done_callback(lambda f: make_result_fn(f, futmap))\n",
    "\n",
    "        return f, futmap\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_futures_v2(futmap_keys, class_check, make_result_fn):\n",
    "        \"\"\"\n",
    "        Create futures and a futuremap for the keys in futmap_keys,\n",
    "        and create a request-level future to be bassed to the C API.\n",
    "        \"\"\"\n",
    "        futmap = {}\n",
    "        for key in futmap_keys:\n",
    "            if class_check is not None and not isinstance(key, class_check):\n",
    "                raise TypeError(\"Expected list of {}\".format(repr(class_check)))\n",
    "            futmap[key] = AdminClient._create_future()\n",
    "\n",
    "        # Create an internal future for the entire request,\n",
    "        # this future will trigger _make_..._result() and set result/exception\n",
    "        # per topic,future in futmap.\n",
    "        f = AdminClient._create_future()\n",
    "        f.add_done_callback(lambda f: make_result_fn(f, futmap))\n",
    "\n",
    "        return f, futmap\n",
    "\n",
    "    @staticmethod\n",
    "    def _make_single_future_pair():\n",
    "        \"\"\"\n",
    "        Create an pair of futures, one for internal usage and one\n",
    "        to use externally, the external one throws a KafkaException if\n",
    "        any of the values in the map returned by the first future is\n",
    "        a KafkaError.\n",
    "        \"\"\"\n",
    "\n",
    "        def single_future_result(internal_f, f):\n",
    "            try:\n",
    "                results = internal_f.result()\n",
    "                for _, value in results.items():\n",
    "                    if isinstance(value, KafkaError):\n",
    "                        f.set_exception(KafkaException(value))\n",
    "                        return\n",
    "                f.set_result(results)\n",
    "            except Exception as e:\n",
    "                f.set_exception(e)\n",
    "\n",
    "        f = AdminClient._create_future()\n",
    "        internal_f = AdminClient._create_future()\n",
    "        internal_f.add_done_callback(\n",
    "            lambda internal_f: single_future_result(internal_f, f)\n",
    "        )\n",
    "        return internal_f, f\n",
    "\n",
    "    @staticmethod\n",
    "    def _has_duplicates(items):\n",
    "        return len(set(items)) != len(items)\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_list_consumer_group_offsets_request(request):\n",
    "        if request is None:\n",
    "            raise TypeError(\"request cannot be None\")\n",
    "        if not isinstance(request, list):\n",
    "            raise TypeError(\"request must be a list\")\n",
    "        if len(request) != 1:\n",
    "            raise ValueError(\n",
    "                \"Currently we support listing offsets for a single consumer group only\"\n",
    "            )\n",
    "        for req in request:\n",
    "            if not isinstance(req, _ConsumerGroupTopicPartitions):\n",
    "                raise TypeError(\"Expected list of 'ConsumerGroupTopicPartitions'\")\n",
    "\n",
    "            if req.group_id is None:\n",
    "                raise TypeError(\"'group_id' cannot be None\")\n",
    "            if not isinstance(req.group_id, string_type):\n",
    "                raise TypeError(\"'group_id' must be a string\")\n",
    "            if not req.group_id:\n",
    "                raise ValueError(\"'group_id' cannot be empty\")\n",
    "\n",
    "            if req.topic_partitions is not None:\n",
    "                if not isinstance(req.topic_partitions, list):\n",
    "                    raise TypeError(\"'topic_partitions' must be a list or None\")\n",
    "                if len(req.topic_partitions) == 0:\n",
    "                    raise ValueError(\"'topic_partitions' cannot be empty\")\n",
    "                for topic_partition in req.topic_partitions:\n",
    "                    if topic_partition is None:\n",
    "                        raise ValueError(\"Element of 'topic_partitions' cannot be None\")\n",
    "                    if not isinstance(topic_partition, _TopicPartition):\n",
    "                        raise TypeError(\n",
    "                            \"Element of 'topic_partitions' must be of type TopicPartition\"\n",
    "                        )\n",
    "                    if topic_partition.topic is None:\n",
    "                        raise TypeError(\n",
    "                            \"Element of 'topic_partitions' must not have 'topic' attribute as None\"\n",
    "                        )\n",
    "                    if not topic_partition.topic:\n",
    "                        raise ValueError(\n",
    "                            \"Element of 'topic_partitions' must not have 'topic' attribute as Empty\"\n",
    "                        )\n",
    "                    if topic_partition.partition < 0:\n",
    "                        raise ValueError(\n",
    "                            \"Element of 'topic_partitions' must not have negative 'partition' value\"\n",
    "                        )\n",
    "                    if topic_partition.offset != OFFSET_INVALID:\n",
    "                        raise ValueError(\n",
    "                            \"Element of 'topic_partitions' must not have 'offset' value\"\n",
    "                        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_alter_consumer_group_offsets_request(request):\n",
    "        if request is None:\n",
    "            raise TypeError(\"request cannot be None\")\n",
    "        if not isinstance(request, list):\n",
    "            raise TypeError(\"request must be a list\")\n",
    "        if len(request) != 1:\n",
    "            raise ValueError(\n",
    "                \"Currently we support altering offsets for a single consumer group only\"\n",
    "            )\n",
    "        for req in request:\n",
    "            if not isinstance(req, _ConsumerGroupTopicPartitions):\n",
    "                raise TypeError(\"Expected list of 'ConsumerGroupTopicPartitions'\")\n",
    "            if req.group_id is None:\n",
    "                raise TypeError(\"'group_id' cannot be None\")\n",
    "            if not isinstance(req.group_id, string_type):\n",
    "                raise TypeError(\"'group_id' must be a string\")\n",
    "            if not req.group_id:\n",
    "                raise ValueError(\"'group_id' cannot be empty\")\n",
    "            if req.topic_partitions is None:\n",
    "                raise ValueError(\"'topic_partitions' cannot be null\")\n",
    "            if not isinstance(req.topic_partitions, list):\n",
    "                raise TypeError(\"'topic_partitions' must be a list\")\n",
    "            if len(req.topic_partitions) == 0:\n",
    "                raise ValueError(\"'topic_partitions' cannot be empty\")\n",
    "            for topic_partition in req.topic_partitions:\n",
    "                if topic_partition is None:\n",
    "                    raise ValueError(\"Element of 'topic_partitions' cannot be None\")\n",
    "                if not isinstance(topic_partition, _TopicPartition):\n",
    "                    raise TypeError(\n",
    "                        \"Element of 'topic_partitions' must be of type TopicPartition\"\n",
    "                    )\n",
    "                if topic_partition.topic is None:\n",
    "                    raise TypeError(\n",
    "                        \"Element of 'topic_partitions' must not have 'topic' attribute as None\"\n",
    "                    )\n",
    "                if not topic_partition.topic:\n",
    "                    raise ValueError(\n",
    "                        \"Element of 'topic_partitions' must not have 'topic' attribute as Empty\"\n",
    "                    )\n",
    "                if topic_partition.partition < 0:\n",
    "                    raise ValueError(\n",
    "                        \"Element of 'topic_partitions' must not have negative value for 'partition' field\"\n",
    "                    )\n",
    "                if topic_partition.offset < 0:\n",
    "                    raise ValueError(\n",
    "                        \"Element of 'topic_partitions' must not have negative value for 'offset' field\"\n",
    "                    )\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_describe_user_scram_credentials_request(users):\n",
    "        if users is None:\n",
    "            return\n",
    "        if not isinstance(users, list):\n",
    "            raise TypeError(\"Expected input to be list of String\")\n",
    "        for user in users:\n",
    "            if user is None:\n",
    "                raise TypeError(\"'user' cannot be None\")\n",
    "            if not isinstance(user, string_type):\n",
    "                raise TypeError(\"Each value should be a string\")\n",
    "            if not user:\n",
    "                raise ValueError(\"'user' cannot be empty\")\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_alter_user_scram_credentials_request(alterations):\n",
    "        if not isinstance(alterations, list):\n",
    "            raise TypeError(\"Expected input to be list\")\n",
    "        if len(alterations) == 0:\n",
    "            raise ValueError(\"Expected at least one alteration\")\n",
    "        for alteration in alterations:\n",
    "            if not isinstance(alteration, UserScramCredentialAlteration):\n",
    "                raise TypeError(\n",
    "                    \"Expected each element of list to be subclass of UserScramCredentialAlteration\"\n",
    "                )\n",
    "            if alteration.user is None:\n",
    "                raise TypeError(\"'user' cannot be None\")\n",
    "            if not isinstance(alteration.user, string_type):\n",
    "                raise TypeError(\"'user' must be a string\")\n",
    "            if not alteration.user:\n",
    "                raise ValueError(\"'user' cannot be empty\")\n",
    "\n",
    "            if isinstance(alteration, UserScramCredentialUpsertion):\n",
    "                if alteration.password is None:\n",
    "                    raise TypeError(\"'password' cannot be None\")\n",
    "                if not isinstance(alteration.password, bytes):\n",
    "                    raise TypeError(\"'password' must be bytes\")\n",
    "                if not alteration.password:\n",
    "                    raise ValueError(\"'password' cannot be empty\")\n",
    "\n",
    "                if alteration.salt is not None and not alteration.salt:\n",
    "                    raise ValueError(\"'salt' can be None but cannot be empty\")\n",
    "                if alteration.salt and not isinstance(alteration.salt, bytes):\n",
    "                    raise TypeError(\"'salt' must be bytes\")\n",
    "\n",
    "                if not isinstance(\n",
    "                    alteration.scram_credential_info, ScramCredentialInfo\n",
    "                ):\n",
    "                    raise TypeError(\n",
    "                        \"Expected credential_info to be ScramCredentialInfo Type\"\n",
    "                    )\n",
    "                if alteration.scram_credential_info.iterations < 1:\n",
    "                    raise ValueError(\"Iterations should be positive\")\n",
    "                if not isinstance(\n",
    "                    alteration.scram_credential_info.mechanism, ScramMechanism\n",
    "                ):\n",
    "                    raise TypeError(\"Expected the mechanism to be ScramMechanism Type\")\n",
    "            elif isinstance(alteration, UserScramCredentialDeletion):\n",
    "                if not isinstance(alteration.mechanism, ScramMechanism):\n",
    "                    raise TypeError(\"Expected the mechanism to be ScramMechanism Type\")\n",
    "            else:\n",
    "                raise TypeError(\n",
    "                    \"Expected each element of list 'alterations' \"\n",
    "                    + \"to be either a UserScramCredentialUpsertion or a \"\n",
    "                    + \"UserScramCredentialDeletion\"\n",
    "                )\n",
    "\n",
    "    @staticmethod\n",
    "    def _check_list_offsets_request(topic_partition_offsets, kwargs):\n",
    "        if not isinstance(topic_partition_offsets, dict):\n",
    "            raise TypeError(\n",
    "                \"Expected topic_partition_offsets to be \"\n",
    "                + \"dict of [TopicPartitions,OffsetSpec] for list offsets request\"\n",
    "            )\n",
    "\n",
    "        for topic_partition, offset_spec in topic_partition_offsets.items():\n",
    "            if topic_partition is None:\n",
    "                raise TypeError(\"partition cannot be None\")\n",
    "            if not isinstance(topic_partition, _TopicPartition):\n",
    "                raise TypeError(\"partition must be a TopicPartition\")\n",
    "            if topic_partition.topic is None:\n",
    "                raise TypeError(\"partition topic name cannot be None\")\n",
    "            if not isinstance(topic_partition.topic, string_type):\n",
    "                raise TypeError(\"partition topic name must be string\")\n",
    "            if not topic_partition.topic:\n",
    "                raise ValueError(\"partition topic name cannot be empty\")\n",
    "            if topic_partition.partition < 0:\n",
    "                raise ValueError(\"partition index must be non-negative\")\n",
    "            if offset_spec is None:\n",
    "                raise TypeError(\"OffsetSpec cannot be None\")\n",
    "            if not isinstance(offset_spec, OffsetSpec):\n",
    "                raise TypeError(\"Value must be a OffsetSpec\")\n",
    "\n",
    "        if \"isolation_level\" in kwargs:\n",
    "            if not isinstance(kwargs[\"isolation_level\"], _IsolationLevel):\n",
    "                raise TypeError(\"isolation_level argument should be an IsolationLevel\")\n",
    "\n",
    "    def create_topics(self, new_topics, **kwargs):\n",
    "        \"\"\"\n",
    "        Create one or more new topics.\n",
    "\n",
    "        :param list(NewTopic) new_topics: A list of specifictions (NewTopic) for\n",
    "                  the topics that should be created.\n",
    "        :param float operation_timeout: The operation timeout in seconds,\n",
    "                  controlling how long the CreateTopics request will block\n",
    "                  on the broker waiting for the topic creation to propagate\n",
    "                  in the cluster. A value of 0 returns immediately. Default: 0\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "        :param bool validate_only: If true, the request is only validated\n",
    "                  without creating the topic. Default: False\n",
    "\n",
    "        :returns: A dict of futures for each topic, keyed by the topic name.\n",
    "                  The future result() method returns None.\n",
    "\n",
    "        :rtype: dict(<topic_name, future>)\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            [x.topic for x in new_topics], None, AdminClient._make_topics_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).create_topics(new_topics, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def delete_topics(self, topics, **kwargs):\n",
    "        \"\"\"\n",
    "        Delete one or more topics.\n",
    "\n",
    "        :param list(str) topics: A list of topics to mark for deletion.\n",
    "        :param float operation_timeout: The operation timeout in seconds,\n",
    "                  controlling how long the DeleteTopics request will block\n",
    "                  on the broker waiting for the topic deletion to propagate\n",
    "                  in the cluster. A value of 0 returns immediately. Default: 0\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures for each topic, keyed by the topic name.\n",
    "                  The future result() method returns None.\n",
    "\n",
    "        :rtype: dict(<topic_name, future>)\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            topics, None, AdminClient._make_topics_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).delete_topics(topics, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def list_topics(self, *args, **kwargs):\n",
    "        return super(AdminClient, self).list_topics(*args, **kwargs)\n",
    "\n",
    "    def list_groups(self, *args, **kwargs):\n",
    "        return super(AdminClient, self).list_groups(*args, **kwargs)\n",
    "\n",
    "    def create_partitions(self, new_partitions, **kwargs):\n",
    "        \"\"\"\n",
    "        Create additional partitions for the given topics.\n",
    "\n",
    "        :param list(NewPartitions) new_partitions: New partitions to be created.\n",
    "        :param float operation_timeout: The operation timeout in seconds,\n",
    "                  controlling how long the CreatePartitions request will block\n",
    "                  on the broker waiting for the partition creation to propagate\n",
    "                  in the cluster. A value of 0 returns immediately. Default: 0\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "        :param bool validate_only: If true, the request is only validated\n",
    "                  without creating the partitions. Default: False\n",
    "\n",
    "        :returns: A dict of futures for each topic, keyed by the topic name.\n",
    "                  The future result() method returns None.\n",
    "\n",
    "        :rtype: dict(<topic_name, future>)\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            [x.topic for x in new_partitions], None, AdminClient._make_topics_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).create_partitions(new_partitions, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def describe_configs(self, resources, **kwargs):\n",
    "        \"\"\"\n",
    "        Get the configuration of the specified resources.\n",
    "\n",
    "        :warning: Multiple resources and resource types may be requested,\n",
    "                  but at most one resource of type RESOURCE_BROKER is allowed\n",
    "                  per call since these resource requests must be sent to the\n",
    "                  broker specified in the resource.\n",
    "\n",
    "        :param list(ConfigResource) resources: Resources to get the configuration for.\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures for each resource, keyed by the ConfigResource.\n",
    "                  The type of the value returned by the future result() method is\n",
    "                  dict(<configname, ConfigEntry>).\n",
    "\n",
    "        :rtype: dict(<ConfigResource, future>)\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            resources, ConfigResource, AdminClient._make_resource_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).describe_configs(resources, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def alter_configs(self, resources, **kwargs):\n",
    "        \"\"\"\n",
    "        .. deprecated:: 2.2.0\n",
    "\n",
    "        Update configuration properties for the specified resources.\n",
    "        Updates are not transactional so they may succeed for a subset\n",
    "        of the provided resources while the others fail.\n",
    "        The configuration for a particular resource is updated atomically,\n",
    "        replacing the specified values while reverting unspecified configuration\n",
    "        entries to their default values.\n",
    "\n",
    "        :warning: alter_configs() will replace all existing configuration for\n",
    "                  the provided resources with the new configuration given,\n",
    "                  reverting all other configuration for the resource back\n",
    "                  to their default values.\n",
    "\n",
    "        :warning: Multiple resources and resource types may be specified,\n",
    "                  but at most one resource of type RESOURCE_BROKER is allowed\n",
    "                  per call since these resource requests must be sent to the\n",
    "                  broker specified in the resource.\n",
    "\n",
    "        :param list(ConfigResource) resources: Resources to update configuration of.\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`.\n",
    "        :param bool validate_only: If true, the request is validated only,\n",
    "                  without altering the configuration. Default: False\n",
    "\n",
    "        :returns: A dict of futures for each resource, keyed by the ConfigResource.\n",
    "                  The future result() method returns None or throws a KafkaException.\n",
    "\n",
    "        :rtype: dict(<ConfigResource, future>)\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeError: Invalid type.\n",
    "        :raises ValueError: Invalid value.\n",
    "        \"\"\"\n",
    "        warnings.warn(\n",
    "            \"alter_configs has been deprecated. Use incremental_alter_configs instead.\",\n",
    "            category=DeprecationWarning,\n",
    "            stacklevel=2,\n",
    "        )\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            resources, ConfigResource, AdminClient._make_resource_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).alter_configs(resources, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def incremental_alter_configs(self, resources, **kwargs):\n",
    "        \"\"\"\n",
    "        Update configuration properties for the specified resources.\n",
    "        Updates are incremental, i.e only the values mentioned are changed\n",
    "        and rest remain as is.\n",
    "\n",
    "        :param list(ConfigResource) resources: Resources to update configuration of.\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`.\n",
    "        :param bool validate_only: If true, the request is validated only,\n",
    "                  without altering the configuration. Default: False\n",
    "        :param int broker: Broker id to send the request to. When\n",
    "                  altering broker configurations, it's ignored because\n",
    "                  the request needs to go to that broker only.\n",
    "                  Default: controller broker.\n",
    "\n",
    "        :returns: A dict of futures for each resource, keyed by the ConfigResource.\n",
    "                  The future result() method returns None or throws a KafkaException.\n",
    "\n",
    "        :rtype: dict(<ConfigResource, future>)\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeError: Invalid type.\n",
    "        :raises ValueError: Invalid value.\n",
    "        \"\"\"\n",
    "        f, futmap = AdminClient._make_futures_v2(\n",
    "            resources, ConfigResource, AdminClient._make_resource_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).incremental_alter_configs(resources, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def create_acls(self, acls, **kwargs):\n",
    "        \"\"\"\n",
    "        Create one or more ACL bindings.\n",
    "\n",
    "        :param list(AclBinding) acls: A list of unique ACL binding specifications (:class:`.AclBinding`)\n",
    "                         to create.\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures for each ACL binding, keyed by the :class:`AclBinding` object.\n",
    "                  The future result() method returns None on success.\n",
    "\n",
    "        :rtype: dict[AclBinding, future]\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "        if AdminClient._has_duplicates(acls):\n",
    "            raise ValueError(\"duplicate ACL bindings not allowed\")\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            acls, AclBinding, AdminClient._make_acls_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).create_acls(acls, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def describe_acls(self, acl_binding_filter, **kwargs):\n",
    "        \"\"\"\n",
    "        Match ACL bindings by filter.\n",
    "\n",
    "        :param AclBindingFilter acl_binding_filter: a filter with attributes that\n",
    "                  must match.\n",
    "                  String attributes match exact values or any string if set to None.\n",
    "                  Enums attributes match exact values or any value if equal to `ANY`.\n",
    "                  If :class:`ResourcePatternType` is set to :attr:`ResourcePatternType.MATCH`\n",
    "                  returns ACL bindings with:\n",
    "                  :attr:`ResourcePatternType.LITERAL` pattern type with resource name equal\n",
    "                  to the given resource name;\n",
    "                  :attr:`ResourcePatternType.LITERAL` pattern type with wildcard resource name\n",
    "                  that matches the given resource name;\n",
    "                  :attr:`ResourcePatternType.PREFIXED` pattern type with resource name\n",
    "                  that is a prefix of the given resource name\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A future returning a list(:class:`AclBinding`) as result\n",
    "\n",
    "        :rtype: future\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "\n",
    "        f = AdminClient._create_future()\n",
    "\n",
    "        super(AdminClient, self).describe_acls(acl_binding_filter, f, **kwargs)\n",
    "\n",
    "        return f\n",
    "\n",
    "    def delete_acls(self, acl_binding_filters, **kwargs):\n",
    "        \"\"\"\n",
    "        Delete ACL bindings matching one or more ACL binding filters.\n",
    "\n",
    "        :param list(AclBindingFilter) acl_binding_filters: a list of unique ACL binding filters\n",
    "                  to match ACLs to delete.\n",
    "                  String attributes match exact values or any string if set to None.\n",
    "                  Enums attributes match exact values or any value if equal to `ANY`.\n",
    "                  If :class:`ResourcePatternType` is set to :attr:`ResourcePatternType.MATCH`\n",
    "                  deletes ACL bindings with:\n",
    "                  :attr:`ResourcePatternType.LITERAL` pattern type with resource name\n",
    "                  equal to the given resource name;\n",
    "                  :attr:`ResourcePatternType.LITERAL` pattern type with wildcard resource name\n",
    "                  that matches the given resource name;\n",
    "                  :attr:`ResourcePatternType.PREFIXED` pattern type with resource name\n",
    "                  that is a prefix of the given resource name\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures for each ACL binding filter, keyed by the :class:`AclBindingFilter` object.\n",
    "                  The future result() method returns a list of :class:`AclBinding`.\n",
    "\n",
    "        :rtype: dict[AclBindingFilter, future]\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "        if AdminClient._has_duplicates(acl_binding_filters):\n",
    "            raise ValueError(\"duplicate ACL binding filters not allowed\")\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            acl_binding_filters, AclBindingFilter, AdminClient._make_acls_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).delete_acls(acl_binding_filters, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def list_consumer_groups(self, **kwargs):\n",
    "        \"\"\"\n",
    "        List consumer groups.\n",
    "\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "        :param set(ConsumerGroupState) states: only list consumer groups which are currently in\n",
    "                  these states.\n",
    "\n",
    "        :returns: a future. Result method of the future returns :class:`ListConsumerGroupsResult`.\n",
    "\n",
    "        :rtype: future\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "        if \"states\" in kwargs:\n",
    "            states = kwargs[\"states\"]\n",
    "            if states is not None:\n",
    "                if not isinstance(states, set):\n",
    "                    raise TypeError(\"'states' must be a set\")\n",
    "                for state in states:\n",
    "                    if not isinstance(state, _ConsumerGroupState):\n",
    "                        raise TypeError(\n",
    "                            \"All elements of states must be of type ConsumerGroupState\"\n",
    "                        )\n",
    "                kwargs[\"states_int\"] = [state.value for state in states]\n",
    "            kwargs.pop(\"states\")\n",
    "\n",
    "        f, _ = AdminClient._make_futures(\n",
    "            [], None, AdminClient._make_list_consumer_groups_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).list_consumer_groups(f, **kwargs)\n",
    "\n",
    "        return f\n",
    "\n",
    "    def describe_consumer_groups(self, group_ids, **kwargs):\n",
    "        \"\"\"\n",
    "        Describe consumer groups.\n",
    "\n",
    "        :param list(str) group_ids: List of group_ids which need to be described.\n",
    "        :param bool include_authorized_operations: If True, fetches group AclOperations. Default: False\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures for each group, keyed by the group_id.\n",
    "                  The future result() method returns :class:`ConsumerGroupDescription`.\n",
    "\n",
    "        :rtype: dict[str, future]\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(group_ids, list):\n",
    "            raise TypeError(\"Expected input to be list of group ids to be described\")\n",
    "\n",
    "        if len(group_ids) == 0:\n",
    "            raise ValueError(\"Expected at least one group to be described\")\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            group_ids, None, AdminClient._make_consumer_groups_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).describe_consumer_groups(group_ids, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def describe_topics(self, topics, **kwargs):\n",
    "        \"\"\"\n",
    "        Describe topics.\n",
    "\n",
    "        :param TopicCollection topics: Collection of list of topic names to describe.\n",
    "        :param bool include_authorized_operations: If True, fetches topic AclOperations. Default: False\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures for each topic, keyed by the topic.\n",
    "                  The future result() method returns :class:`TopicDescription`.\n",
    "\n",
    "        :rtype: dict[str, future]\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeError: Invalid input type.\n",
    "        :raises ValueError: Invalid input value.\n",
    "        \"\"\"\n",
    "\n",
    "        if not isinstance(topics, _TopicCollection):\n",
    "            raise TypeError(\"Expected input to be instance of TopicCollection\")\n",
    "\n",
    "        topic_names = topics.topic_names\n",
    "\n",
    "        if not isinstance(topic_names, list):\n",
    "            raise TypeError(\"Expected list of topic names to be described\")\n",
    "\n",
    "        f, futmap = AdminClient._make_futures_v2(\n",
    "            topic_names, None, AdminClient._make_futmap_result_from_list\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).describe_topics(topic_names, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def describe_cluster(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Describe cluster.\n",
    "\n",
    "        :param bool include_authorized_operations: If True, fetches topic AclOperations. Default: False\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A future returning description of the cluster as result\n",
    "\n",
    "        :rtype: future containing the description of the cluster in result.\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeError: Invalid input type.\n",
    "        :raises ValueError: Invalid input value.\n",
    "        \"\"\"\n",
    "\n",
    "        f = AdminClient._create_future()\n",
    "\n",
    "        super(AdminClient, self).describe_cluster(f, **kwargs)\n",
    "\n",
    "        return f\n",
    "\n",
    "    def delete_consumer_groups(self, group_ids, **kwargs):\n",
    "        \"\"\"\n",
    "        Delete the given consumer groups.\n",
    "\n",
    "        :param list(str) group_ids: List of group_ids which need to be deleted.\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures for each group, keyed by the group_id.\n",
    "                  The future result() method returns None.\n",
    "\n",
    "        :rtype: dict[str, future]\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeError: Invalid input type.\n",
    "        :raises ValueError: Invalid input value.\n",
    "        \"\"\"\n",
    "        if not isinstance(group_ids, list):\n",
    "            raise TypeError(\"Expected input to be list of group ids to be deleted\")\n",
    "\n",
    "        if len(group_ids) == 0:\n",
    "            raise ValueError(\"Expected at least one group to be deleted\")\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            group_ids, string_type, AdminClient._make_consumer_groups_result\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).delete_consumer_groups(group_ids, f, **kwargs)\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def list_consumer_group_offsets(\n",
    "        self, list_consumer_group_offsets_request, **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        List offset information for the consumer group and (optional) topic partition provided in the request.\n",
    "\n",
    "        :note: Currently, the API supports only a single group.\n",
    "\n",
    "        :param list(ConsumerGroupTopicPartitions) list_consumer_group_offsets_request: List of\n",
    "                    :class:`ConsumerGroupTopicPartitions` which consist of group name and topic\n",
    "                    partition information for which offset detail is expected. If only group name is\n",
    "                    provided, then offset information of all the topic and partition associated with\n",
    "                    that group is returned.\n",
    "        :param bool require_stable: If True, fetches stable offsets. Default: False\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures for each group, keyed by the group id.\n",
    "                  The future result() method returns :class:`ConsumerGroupTopicPartitions`.\n",
    "\n",
    "        :rtype: dict[str, future]\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "\n",
    "        AdminClient._check_list_consumer_group_offsets_request(\n",
    "            list_consumer_group_offsets_request\n",
    "        )\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            [request.group_id for request in list_consumer_group_offsets_request],\n",
    "            string_type,\n",
    "            AdminClient._make_consumer_group_offsets_result,\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).list_consumer_group_offsets(\n",
    "            list_consumer_group_offsets_request, f, **kwargs\n",
    "        )\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def alter_consumer_group_offsets(\n",
    "        self, alter_consumer_group_offsets_request, **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Alter offset for the consumer group and topic partition provided in the request.\n",
    "\n",
    "        :note: Currently, the API supports only a single group.\n",
    "\n",
    "        :param list(ConsumerGroupTopicPartitions) alter_consumer_group_offsets_request: List of\n",
    "                    :class:`ConsumerGroupTopicPartitions` which consist of group name and topic\n",
    "                    partition; and corresponding offset to be updated.\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "                  including broker lookup, request transmission, operation time\n",
    "                  on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures for each group, keyed by the group id.\n",
    "                  The future result() method returns :class:`ConsumerGroupTopicPartitions`.\n",
    "\n",
    "        :rtype: dict[ConsumerGroupTopicPartitions, future]\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        :raises ValueException: Invalid input.\n",
    "        \"\"\"\n",
    "\n",
    "        AdminClient._check_alter_consumer_group_offsets_request(\n",
    "            alter_consumer_group_offsets_request\n",
    "        )\n",
    "\n",
    "        f, futmap = AdminClient._make_futures(\n",
    "            [request.group_id for request in alter_consumer_group_offsets_request],\n",
    "            string_type,\n",
    "            AdminClient._make_consumer_group_offsets_result,\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).alter_consumer_group_offsets(\n",
    "            alter_consumer_group_offsets_request, f, **kwargs\n",
    "        )\n",
    "\n",
    "        return futmap\n",
    "\n",
    "    def set_sasl_credentials(self, username, password):\n",
    "        \"\"\"\n",
    "        Sets the SASL credentials used for this client.\n",
    "        These credentials will overwrite the old ones, and will be used the\n",
    "        next time the client needs to authenticate.\n",
    "        This method will not disconnect existing broker connections that\n",
    "        have been established with the old credentials.\n",
    "        This method is applicable only to SASL PLAIN and SCRAM mechanisms.\n",
    "\n",
    "        :param str username: The username to set.\n",
    "        :param str password: The password to set.\n",
    "\n",
    "        :rtype: None\n",
    "\n",
    "        :raises KafkaException: Operation failed locally or on broker.\n",
    "        :raises TypeException: Invalid input.\n",
    "        \"\"\"\n",
    "        super(AdminClient, self).set_sasl_credentials(username, password)\n",
    "\n",
    "    def describe_user_scram_credentials(self, users=None, **kwargs):\n",
    "        \"\"\"\n",
    "        Describe user SASL/SCRAM credentials.\n",
    "\n",
    "        :param list(str) users: List of user names to describe.\n",
    "               Duplicate users aren't allowed. Can be None\n",
    "               to describe all user's credentials.\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "               including broker lookup, request transmission, operation time\n",
    "               on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: In case None is passed it returns a single future.\n",
    "                  The future yields a dict[str, UserScramCredentialsDescription]\n",
    "                  or raises a KafkaException\n",
    "\n",
    "                  In case a list of user names is passed, it returns\n",
    "                  a dict[str, future[UserScramCredentialsDescription]].\n",
    "                  The futures yield a :class:`UserScramCredentialsDescription`\n",
    "                  or raise a KafkaException\n",
    "\n",
    "        :rtype: Union[future[dict[str, UserScramCredentialsDescription]],\n",
    "                      dict[str, future[UserScramCredentialsDescription]]]\n",
    "\n",
    "        :raises TypeError: Invalid input type.\n",
    "        :raises ValueError: Invalid input value.\n",
    "        \"\"\"\n",
    "        AdminClient._check_describe_user_scram_credentials_request(users)\n",
    "\n",
    "        if users is None:\n",
    "            internal_f, ret_fut = AdminClient._make_single_future_pair()\n",
    "        else:\n",
    "            internal_f, ret_fut = AdminClient._make_futures_v2(\n",
    "                users, None, AdminClient._make_futmap_result\n",
    "            )\n",
    "        super(AdminClient, self).describe_user_scram_credentials(\n",
    "            users, internal_f, **kwargs\n",
    "        )\n",
    "        return ret_fut\n",
    "\n",
    "    def alter_user_scram_credentials(self, alterations, **kwargs):\n",
    "        \"\"\"\n",
    "        Alter user SASL/SCRAM credentials.\n",
    "\n",
    "        :param list(UserScramCredentialAlteration) alterations: List of\n",
    "               :class:`UserScramCredentialAlteration` to apply.\n",
    "               The pair (user, mechanism) must be unique among alterations.\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "               including broker lookup, request transmission, operation time\n",
    "               on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures keyed by user name.\n",
    "                  The future result() method returns None or\n",
    "                  raises KafkaException\n",
    "\n",
    "        :rtype: dict[str, future]\n",
    "\n",
    "        :raises TypeError: Invalid input type.\n",
    "        :raises ValueError: Invalid input value.\n",
    "        \"\"\"\n",
    "        AdminClient._check_alter_user_scram_credentials_request(alterations)\n",
    "\n",
    "        f, futmap = AdminClient._make_futures_v2(\n",
    "            set([alteration.user for alteration in alterations]),\n",
    "            None,\n",
    "            AdminClient._make_futmap_result,\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).alter_user_scram_credentials(alterations, f, **kwargs)\n",
    "        return futmap\n",
    "\n",
    "    def list_offsets(self, topic_partition_offsets, **kwargs):\n",
    "        \"\"\"\n",
    "        Enables to find the beginning offset,\n",
    "        end offset as well as the offset matching a timestamp\n",
    "        or the offset with max timestamp in partitions.\n",
    "\n",
    "        :param dict([TopicPartition, OffsetSpec]) topic_partition_offsets: Dictionary of\n",
    "               TopicPartition objects associated with the corresponding OffsetSpec to query for.\n",
    "        :param IsolationLevel isolation_level: The isolation level to use when\n",
    "               querying.\n",
    "        :param float request_timeout: The overall request timeout in seconds,\n",
    "               including broker lookup, request transmission, operation time\n",
    "               on broker, and response. Default: `socket.timeout.ms*1000.0`\n",
    "\n",
    "        :returns: A dict of futures keyed by TopicPartition.\n",
    "                  The future result() method returns ListOffsetsResultInfo\n",
    "                  raises KafkaException\n",
    "\n",
    "        :rtype: dict[TopicPartition, future]\n",
    "\n",
    "        :raises TypeError: Invalid input type.\n",
    "        :raises ValueError: Invalid input value.\n",
    "        \"\"\"\n",
    "        AdminClient._check_list_offsets_request(topic_partition_offsets, kwargs)\n",
    "\n",
    "        if \"isolation_level\" in kwargs:\n",
    "            kwargs[\"isolation_level_value\"] = kwargs[\"isolation_level\"].value\n",
    "            del kwargs[\"isolation_level\"]\n",
    "\n",
    "        topic_partition_offsets_list = [\n",
    "            _TopicPartition(\n",
    "                topic_partition.topic,\n",
    "                int(topic_partition.partition),\n",
    "                int(offset_spec._value),\n",
    "            )\n",
    "            for topic_partition, offset_spec in topic_partition_offsets.items()\n",
    "        ]\n",
    "\n",
    "        f, futmap = AdminClient._make_futures_v2(\n",
    "            topic_partition_offsets_list,\n",
    "            _TopicPartition,\n",
    "            AdminClient._make_futmap_result,\n",
    "        )\n",
    "\n",
    "        super(AdminClient, self).list_offsets(topic_partition_offsets_list, f, **kwargs)\n",
    "        return futmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}