{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Copyright 2020 Confluent Inc.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "import struct as _struct\n",
    "\n",
    "from confluent_kafka.error import KafkaException\n",
    "\n",
    "__all__ = [\n",
    "    \"Deserializer\",\n",
    "    \"IntegerDeserializer\",\n",
    "    \"IntegerSerializer\",\n",
    "    \"DoubleDeserializer\",\n",
    "    \"DoubleSerializer\",\n",
    "    \"StringDeserializer\",\n",
    "    \"StringSerializer\",\n",
    "    \"MessageField\",\n",
    "    \"SerializationContext\",\n",
    "    \"SerializationError\",\n",
    "    \"Serializer\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MessageField(object):\n",
    "    \"\"\"\n",
    "    Enum like object for identifying Message fields.\n",
    "\n",
    "    Attributes:\n",
    "        KEY (str): Message key\n",
    "\n",
    "        VALUE (str): Message value\n",
    "    \"\"\"\n",
    "\n",
    "    NONE = \"none\"\n",
    "    KEY = \"key\"\n",
    "    VALUE = \"value\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SerializationContext(object):\n",
    "    \"\"\"\n",
    "    SerializationContext provides additional context to the\n",
    "    serializer/deserializer about the data it's serializing/deserializing.\n",
    "\n",
    "    Args:\n",
    "        topic (str): Topic data is being produce to or consumed from.\n",
    "\n",
    "        field (MessageField): Describes what part of the message is\n",
    "            being serialized.\n",
    "\n",
    "        headers (list): List of message header tuples. Defaults to None.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, topic, field, headers=None):\n",
    "        self.topic = topic\n",
    "        self.field = field\n",
    "        self.headers = headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SerializationError(KafkaException):\n",
    "    \"\"\"Generic error from serializer package\"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Serializer(object):\n",
    "    \"\"\"\n",
    "    Extensible class from which all Serializer implementations derive.\n",
    "    Serializers instruct Kafka clients on how to convert Python objects\n",
    "    to bytes.\n",
    "\n",
    "    See built-in implementations, listed below, for an example of how to\n",
    "    extend this class.\n",
    "\n",
    "    Note:\n",
    "        This class is not directly instantiable. The derived classes must be\n",
    "        used instead.\n",
    "\n",
    "    The following implementations are provided by this module.\n",
    "\n",
    "    Note:\n",
    "        Unless noted elsewhere all numeric types are signed and serialization\n",
    "        is big-endian.\n",
    "\n",
    "    .. list-table::\n",
    "        :header-rows: 1\n",
    "\n",
    "        * - Name\n",
    "          - Type\n",
    "          - Binary Format\n",
    "        * - DoubleSerializer\n",
    "          - float\n",
    "          - IEEE 764 binary64\n",
    "        * - IntegerSerializer\n",
    "          - int\n",
    "          - int32\n",
    "        * - StringSerializer\n",
    "          - unicode\n",
    "          - unicode(encoding)\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = []\n",
    "\n",
    "    def __call__(self, obj, ctx=None):\n",
    "        \"\"\"\n",
    "        Converts obj to bytes.\n",
    "\n",
    "        Args:\n",
    "            obj (object): object to be serialized\n",
    "\n",
    "            ctx (SerializationContext): Metadata pertaining to the serialization\n",
    "                operation\n",
    "\n",
    "        Raises:\n",
    "            SerializerError if an error occurs during serialization\n",
    "\n",
    "        Returns:\n",
    "            bytes if obj is not None, otherwise None\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deserializer(object):\n",
    "    \"\"\"\n",
    "    Extensible class from which all Deserializer implementations derive.\n",
    "    Deserializers instruct Kafka clients on how to convert bytes to objects.\n",
    "\n",
    "    See built-in implementations, listed below, for an example of how to\n",
    "    extend this class.\n",
    "\n",
    "    Note:\n",
    "        This class is not directly instantiable. The derived classes must be\n",
    "        used instead.\n",
    "\n",
    "    The following implementations are provided by this module.\n",
    "\n",
    "    Note:\n",
    "        Unless noted elsewhere all numeric types are signed and\n",
    "        serialization is big-endian.\n",
    "\n",
    "    .. list-table::\n",
    "        :header-rows: 1\n",
    "\n",
    "        * - Name\n",
    "          - Type\n",
    "          - Binary Format\n",
    "        * - DoubleDeserializer\n",
    "          - float\n",
    "          - IEEE 764 binary64\n",
    "        * - IntegerDeserializer\n",
    "          - int\n",
    "          - int32\n",
    "        * - StringDeserializer\n",
    "          - unicode\n",
    "          - unicode(encoding)\n",
    "    \"\"\"\n",
    "\n",
    "    __slots__ = []\n",
    "\n",
    "    def __call__(self, value, ctx=None):\n",
    "        \"\"\"\n",
    "        Convert bytes to object\n",
    "\n",
    "        Args:\n",
    "            value (bytes): bytes to be deserialized\n",
    "\n",
    "            ctx (SerializationContext): Metadata pertaining to the serialization\n",
    "                operation\n",
    "\n",
    "        Raises:\n",
    "            SerializerError if an error occurs during deserialization\n",
    "\n",
    "        Returns:\n",
    "            object if data is not None, otherwise None\n",
    "        \"\"\"\n",
    "\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleSerializer(Serializer):\n",
    "    \"\"\"\n",
    "    Serializes float to IEEE 764 binary64.\n",
    "\n",
    "    See Also:\n",
    "        `DoubleSerializer Javadoc <https://docs.confluent.io/current/clients/javadocs/org/apache/kafka/common/serialization/DoubleSerializer.html>`_\n",
    "\n",
    "    \"\"\"  # noqa: E501\n",
    "\n",
    "    def __call__(self, obj, ctx=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            obj (object): object to be serialized\n",
    "\n",
    "            ctx (SerializationContext): Metadata pertaining to the serialization\n",
    "                operation\n",
    "\n",
    "        Note:\n",
    "            None objects are represented as Kafka Null.\n",
    "\n",
    "        Raises:\n",
    "            SerializerError if an error occurs during serialization.\n",
    "\n",
    "        Returns:\n",
    "            IEEE 764 binary64 bytes if obj is not None, otherwise None\n",
    "        \"\"\"\n",
    "\n",
    "        if obj is None:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            return _struct.pack(\">d\", obj)\n",
    "        except _struct.error as e:\n",
    "            raise SerializationError(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleDeserializer(Deserializer):\n",
    "    \"\"\"\n",
    "    Deserializes float to IEEE 764 binary64.\n",
    "\n",
    "    See Also:\n",
    "        `DoubleDeserializer Javadoc <https://docs.confluent.io/current/clients/javadocs/org/apache/kafka/common/serialization/DoubleDeserializer.html>`_\n",
    "    \"\"\"  # noqa: E501\n",
    "\n",
    "    def __call__(self, value, ctx=None):\n",
    "        \"\"\"\n",
    "        Deserializes float from IEEE 764 binary64 bytes.\n",
    "\n",
    "        Args:\n",
    "            value (bytes): bytes to be deserialized\n",
    "\n",
    "            ctx (SerializationContext): Metadata pertaining to the serialization\n",
    "                operation\n",
    "\n",
    "        Raises:\n",
    "            SerializerError if an error occurs during deserialization.\n",
    "\n",
    "        Returns:\n",
    "            float if data is not None, otherwise None\n",
    "        \"\"\"\n",
    "\n",
    "        if value is None:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            return _struct.unpack(\">d\", value)[0]\n",
    "        except _struct.error as e:\n",
    "            raise SerializationError(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegerSerializer(Serializer):\n",
    "    \"\"\"\n",
    "    Serializes int to int32 bytes.\n",
    "\n",
    "    See Also:\n",
    "        `IntegerSerializer Javadoc <https://docs.confluent.io/current/clients/javadocs/org/apache/kafka/common/serialization/IntegerSerializer.html>`_\n",
    "    \"\"\"  # noqa: E501\n",
    "\n",
    "    def __call__(self, obj, ctx=None):\n",
    "        \"\"\"\n",
    "        Serializes int as int32 bytes.\n",
    "\n",
    "        Args:\n",
    "            obj (object): object to be serialized\n",
    "\n",
    "            ctx (SerializationContext): Metadata pertaining to the serialization\n",
    "                operation\n",
    "\n",
    "        Note:\n",
    "            None objects are represented as Kafka Null.\n",
    "\n",
    "        Raises:\n",
    "            SerializerError if an error occurs during serialization\n",
    "\n",
    "        Returns:\n",
    "            int32 bytes if obj is not None, else None\n",
    "        \"\"\"\n",
    "\n",
    "        if obj is None:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            return _struct.pack(\">i\", obj)\n",
    "        except _struct.error as e:\n",
    "            raise SerializationError(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IntegerDeserializer(Deserializer):\n",
    "    \"\"\"\n",
    "    Deserializes int to int32 bytes.\n",
    "\n",
    "    See Also:\n",
    "        `IntegerDeserializer Javadoc <https://docs.confluent.io/current/clients/javadocs/org/apache/kafka/common/serialization/IntegerDeserializer.html>`_\n",
    "    \"\"\"  # noqa: E501\n",
    "\n",
    "    def __call__(self, value, ctx=None):\n",
    "        \"\"\"\n",
    "        Deserializes int from int32 bytes.\n",
    "\n",
    "        Args:\n",
    "            value (bytes): bytes to be deserialized\n",
    "\n",
    "            ctx (SerializationContext): Metadata pertaining to the serialization\n",
    "                operation\n",
    "\n",
    "        Raises:\n",
    "            SerializerError if an error occurs during deserialization.\n",
    "\n",
    "        Returns:\n",
    "            int if data is not None, otherwise None\n",
    "        \"\"\"\n",
    "\n",
    "        if value is None:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            return _struct.unpack(\">i\", value)[0]\n",
    "        except _struct.error as e:\n",
    "            raise SerializationError(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringSerializer(Serializer):\n",
    "    \"\"\"\n",
    "    Serializes unicode to bytes per the configured codec. Defaults to ``utf_8``.\n",
    "\n",
    "    Note:\n",
    "        None objects are represented as Kafka Null.\n",
    "\n",
    "    Args:\n",
    "        codec (str, optional): encoding scheme. Defaults to utf_8\n",
    "\n",
    "    See Also:\n",
    "        `Supported encodings <https://docs.python.org/3/library/codecs.html#standard-encodings>`_\n",
    "\n",
    "        `StringSerializer Javadoc <https://docs.confluent.io/current/clients/javadocs/org/apache/kafka/common/serialization/StringSerializer.html>`_\n",
    "    \"\"\"  # noqa: E501\n",
    "\n",
    "    def __init__(self, codec=\"utf_8\"):\n",
    "        self.codec = codec\n",
    "\n",
    "    def __call__(self, obj, ctx=None):\n",
    "        \"\"\"\n",
    "        Serializes a str(py2:unicode) to bytes.\n",
    "\n",
    "        Compatibility Note:\n",
    "            Python 2 str objects must be converted to unicode objects.\n",
    "            Python 3 all str objects are already unicode objects.\n",
    "\n",
    "        Args:\n",
    "            obj (object): object to be serialized\n",
    "\n",
    "            ctx (SerializationContext): Metadata pertaining to the serialization\n",
    "                operation\n",
    "\n",
    "        Raises:\n",
    "            SerializerError if an error occurs during serialization.\n",
    "\n",
    "        Returns:\n",
    "            serialized bytes if obj is not None, otherwise None\n",
    "        \"\"\"\n",
    "\n",
    "        if obj is None:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            return obj.encode(self.codec)\n",
    "        except _struct.error as e:\n",
    "            raise SerializationError(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StringDeserializer(Deserializer):\n",
    "    \"\"\"\n",
    "    Deserializes a str(py2:unicode) from bytes.\n",
    "\n",
    "    Args:\n",
    "        codec (str, optional): encoding scheme. Defaults to utf_8\n",
    "\n",
    "    See Also:\n",
    "        `Supported encodings <https://docs.python.org/3/library/codecs.html#standard-encodings>`_\n",
    "\n",
    "        `StringDeserializer Javadoc <https://docs.confluent.io/current/clients/javadocs/org/apache/kafka/common/serialization/StringDeserializer.html>`_\n",
    "    \"\"\"  # noqa: E501\n",
    "\n",
    "    def __init__(self, codec=\"utf_8\"):\n",
    "        self.codec = codec\n",
    "\n",
    "    def __call__(self, value, ctx=None):\n",
    "        \"\"\"\n",
    "        Serializes unicode to bytes per the configured codec. Defaults to ``utf_8``.\n",
    "\n",
    "        Compatibility Note:\n",
    "            Python 2 str objects must be converted to unicode objects by the\n",
    "            application prior to using this serializer.\n",
    "\n",
    "            Python 3 all str objects are already unicode objects.\n",
    "\n",
    "        Args:\n",
    "            value (bytes): bytes to be deserialized\n",
    "\n",
    "            ctx (SerializationContext): Metadata pertaining to the serialization\n",
    "                operation\n",
    "\n",
    "        Raises:\n",
    "            SerializerError if an error occurs during deserialization.\n",
    "\n",
    "        Returns:\n",
    "            unicode if data is not None, otherwise None\n",
    "        \"\"\"\n",
    "\n",
    "        if value is None:\n",
    "            return None\n",
    "\n",
    "        try:\n",
    "            return value.decode(self.codec)\n",
    "        except _struct.error as e:\n",
    "            raise SerializationError(str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}