{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import datetime\n",
                "import decimal\n",
                "import uuid\n",
                "from functools import lru_cache\n",
                "from itertools import chain\n",
                "\n",
                "from django.conf import settings\n",
                "from django.core.exceptions import FieldError\n",
                "from django.db import DatabaseError, NotSupportedError, models\n",
                "from django.db.backends.base.operations import BaseDatabaseOperations\n",
                "from django.db.models.constants import OnConflict\n",
                "from django.db.models.expressions import Col\n",
                "from django.utils import timezone\n",
                "from django.utils.dateparse import parse_date, parse_datetime, parse_time\n",
                "from django.utils.functional import cached_property\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DatabaseOperations(BaseDatabaseOperations):\n",
                "    cast_char_field_without_max_length = \"text\"\n",
                "    cast_data_types = {\n",
                "        \"DateField\": \"TEXT\",\n",
                "        \"DateTimeField\": \"TEXT\",\n",
                "    }\n",
                "    explain_prefix = \"EXPLAIN QUERY PLAN\"\n",
                "    # List of datatypes to that cannot be extracted with JSON_EXTRACT() on\n",
                "    # SQLite. Use JSON_TYPE() instead.\n",
                "    jsonfield_datatype_values = frozenset([\"null\", \"false\", \"true\"])\n",
                "\n",
                "    def bulk_batch_size(self, fields, objs):\n",
                "        \"\"\"\n",
                "        SQLite has a compile-time default (SQLITE_LIMIT_VARIABLE_NUMBER) of\n",
                "        999 variables per query.\n",
                "\n",
                "        If there's only a single field to insert, the limit is 500\n",
                "        (SQLITE_MAX_COMPOUND_SELECT).\n",
                "        \"\"\"\n",
                "        if len(fields) == 1:\n",
                "            return 500\n",
                "        elif len(fields) > 1:\n",
                "            return self.connection.features.max_query_params // len(fields)\n",
                "        else:\n",
                "            return len(objs)\n",
                "\n",
                "    def check_expression_support(self, expression):\n",
                "        bad_fields = (models.DateField, models.DateTimeField, models.TimeField)\n",
                "        bad_aggregates = (models.Sum, models.Avg, models.Variance, models.StdDev)\n",
                "        if isinstance(expression, bad_aggregates):\n",
                "            for expr in expression.get_source_expressions():\n",
                "                try:\n",
                "                    output_field = expr.output_field\n",
                "                except (AttributeError, FieldError):\n",
                "                    # Not every subexpression has an output_field which is fine\n",
                "                    # to ignore.\n",
                "                    pass\n",
                "                else:\n",
                "                    if isinstance(output_field, bad_fields):\n",
                "                        raise NotSupportedError(\n",
                "                            \"You cannot use Sum, Avg, StdDev, and Variance \"\n",
                "                            \"aggregations on date/time fields in sqlite3 \"\n",
                "                            \"since date/time is saved as text.\"\n",
                "                        )\n",
                "        if (\n",
                "            isinstance(expression, models.Aggregate)\n",
                "            and expression.distinct\n",
                "            and len(expression.source_expressions) > 1\n",
                "        ):\n",
                "            raise NotSupportedError(\n",
                "                \"SQLite doesn't support DISTINCT on aggregate functions \"\n",
                "                \"accepting multiple arguments.\"\n",
                "            )\n",
                "\n",
                "    def date_extract_sql(self, lookup_type, sql, params):\n",
                "        \"\"\"\n",
                "        Support EXTRACT with a user-defined function django_date_extract()\n",
                "        that's registered in connect(). Use single quotes because this is a\n",
                "        string and could otherwise cause a collision with a field name.\n",
                "        \"\"\"\n",
                "        return f\"django_date_extract(%s, {sql})\", (lookup_type.lower(), *params)\n",
                "\n",
                "    def fetch_returned_insert_rows(self, cursor):\n",
                "        \"\"\"\n",
                "        Given a cursor object that has just performed an INSERT...RETURNING\n",
                "        statement into a table, return the list of returned data.\n",
                "        \"\"\"\n",
                "        return cursor.fetchall()\n",
                "\n",
                "    def format_for_duration_arithmetic(self, sql):\n",
                "        \"\"\"Do nothing since formatting is handled in the custom function.\"\"\"\n",
                "        return sql\n",
                "\n",
                "    def date_trunc_sql(self, lookup_type, sql, params, tzname=None):\n",
                "        return f\"django_date_trunc(%s, {sql}, %s, %s)\", (\n",
                "            lookup_type.lower(),\n",
                "            *params,\n",
                "            *self._convert_tznames_to_sql(tzname),\n",
                "        )\n",
                "\n",
                "    def time_trunc_sql(self, lookup_type, sql, params, tzname=None):\n",
                "        return f\"django_time_trunc(%s, {sql}, %s, %s)\", (\n",
                "            lookup_type.lower(),\n",
                "            *params,\n",
                "            *self._convert_tznames_to_sql(tzname),\n",
                "        )\n",
                "\n",
                "    def _convert_tznames_to_sql(self, tzname):\n",
                "        if tzname and settings.USE_TZ:\n",
                "            return tzname, self.connection.timezone_name\n",
                "        return None, None\n",
                "\n",
                "    def datetime_cast_date_sql(self, sql, params, tzname):\n",
                "        return f\"django_datetime_cast_date({sql}, %s, %s)\", (\n",
                "            *params,\n",
                "            *self._convert_tznames_to_sql(tzname),\n",
                "        )\n",
                "\n",
                "    def datetime_cast_time_sql(self, sql, params, tzname):\n",
                "        return f\"django_datetime_cast_time({sql}, %s, %s)\", (\n",
                "            *params,\n",
                "            *self._convert_tznames_to_sql(tzname),\n",
                "        )\n",
                "\n",
                "    def datetime_extract_sql(self, lookup_type, sql, params, tzname):\n",
                "        return f\"django_datetime_extract(%s, {sql}, %s, %s)\", (\n",
                "            lookup_type.lower(),\n",
                "            *params,\n",
                "            *self._convert_tznames_to_sql(tzname),\n",
                "        )\n",
                "\n",
                "    def datetime_trunc_sql(self, lookup_type, sql, params, tzname):\n",
                "        return f\"django_datetime_trunc(%s, {sql}, %s, %s)\", (\n",
                "            lookup_type.lower(),\n",
                "            *params,\n",
                "            *self._convert_tznames_to_sql(tzname),\n",
                "        )\n",
                "\n",
                "    def time_extract_sql(self, lookup_type, sql, params):\n",
                "        return f\"django_time_extract(%s, {sql})\", (lookup_type.lower(), *params)\n",
                "\n",
                "    def pk_default_value(self):\n",
                "        return \"NULL\"\n",
                "\n",
                "    def _quote_params_for_last_executed_query(self, params):\n",
                "        \"\"\"\n",
                "        Only for last_executed_query! Don't use this to execute SQL queries!\n",
                "        \"\"\"\n",
                "        # This function is limited both by SQLITE_LIMIT_VARIABLE_NUMBER (the\n",
                "        # number of parameters, default = 999) and SQLITE_MAX_COLUMN (the\n",
                "        # number of return values, default = 2000). Since Python's sqlite3\n",
                "        # module doesn't expose the get_limit() C API, assume the default\n",
                "        # limits are in effect and split the work in batches if needed.\n",
                "        BATCH_SIZE = 999\n",
                "        if len(params) > BATCH_SIZE:\n",
                "            results = ()\n",
                "            for index in range(0, len(params), BATCH_SIZE):\n",
                "                chunk = params[index : index + BATCH_SIZE]\n",
                "                results += self._quote_params_for_last_executed_query(chunk)\n",
                "            return results\n",
                "\n",
                "        sql = \"SELECT \" + \", \".join([\"QUOTE(?)\"] * len(params))\n",
                "        # Bypass Django's wrappers and use the underlying sqlite3 connection\n",
                "        # to avoid logging this query - it would trigger infinite recursion.\n",
                "        cursor = self.connection.connection.cursor()\n",
                "        # Native sqlite3 cursors cannot be used as context managers.\n",
                "        try:\n",
                "            return cursor.execute(sql, params).fetchone()\n",
                "        finally:\n",
                "            cursor.close()\n",
                "\n",
                "    def last_executed_query(self, cursor, sql, params):\n",
                "        # Python substitutes parameters in Modules/_sqlite/cursor.c with:\n",
                "        # bind_parameters(state, self->statement, parameters);\n",
                "        # Unfortunately there is no way to reach self->statement from Python,\n",
                "        # so we quote and substitute parameters manually.\n",
                "        if params:\n",
                "            if isinstance(params, (list, tuple)):\n",
                "                params = self._quote_params_for_last_executed_query(params)\n",
                "            else:\n",
                "                values = tuple(params.values())\n",
                "                values = self._quote_params_for_last_executed_query(values)\n",
                "                params = dict(zip(params, values))\n",
                "            return sql % params\n",
                "        # For consistency with SQLiteCursorWrapper.execute(), just return sql\n",
                "        # when there are no parameters. See #13648 and #17158.\n",
                "        else:\n",
                "            return sql\n",
                "\n",
                "    def quote_name(self, name):\n",
                "        if name.startswith('\"') and name.endswith('\"'):\n",
                "            return name  # Quoting once is enough.\n",
                "        return '\"%s\"' % name\n",
                "\n",
                "    def no_limit_value(self):\n",
                "        return -1\n",
                "\n",
                "    def __references_graph(self, table_name):\n",
                "        query = \"\"\"\n",
                "        WITH tables AS (\n",
                "            SELECT %s name\n",
                "            UNION\n",
                "            SELECT sqlite_master.name\n",
                "            FROM sqlite_master\n",
                "            JOIN tables ON (sql REGEXP %s || tables.name || %s)\n",
                "        ) SELECT name FROM tables;\n",
                "        \"\"\"\n",
                "        params = (\n",
                "            table_name,\n",
                "            r'(?i)\\s+references\\s+(\"|\\')?',\n",
                "            r'(\"|\\')?\\s*\\(',\n",
                "        )\n",
                "        with self.connection.cursor() as cursor:\n",
                "            results = cursor.execute(query, params)\n",
                "            return [row[0] for row in results.fetchall()]\n",
                "\n",
                "    @cached_property\n",
                "    def _references_graph(self):\n",
                "        # 512 is large enough to fit the ~330 tables (as of this writing) in\n",
                "        # Django's test suite.\n",
                "        return lru_cache(maxsize=512)(self.__references_graph)\n",
                "\n",
                "    def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):\n",
                "        if tables and allow_cascade:\n",
                "            # Simulate TRUNCATE CASCADE by recursively collecting the tables\n",
                "            # referencing the tables to be flushed.\n",
                "            tables = set(\n",
                "                chain.from_iterable(self._references_graph(table) for table in tables)\n",
                "            )\n",
                "        sql = [\n",
                "            \"%s %s %s;\"\n",
                "            % (\n",
                "                style.SQL_KEYWORD(\"DELETE\"),\n",
                "                style.SQL_KEYWORD(\"FROM\"),\n",
                "                style.SQL_FIELD(self.quote_name(table)),\n",
                "            )\n",
                "            for table in tables\n",
                "        ]\n",
                "        if reset_sequences:\n",
                "            sequences = [{\"table\": table} for table in tables]\n",
                "            sql.extend(self.sequence_reset_by_name_sql(style, sequences))\n",
                "        return sql\n",
                "\n",
                "    def sequence_reset_by_name_sql(self, style, sequences):\n",
                "        if not sequences:\n",
                "            return []\n",
                "        return [\n",
                "            \"%s %s %s %s = 0 %s %s %s (%s);\"\n",
                "            % (\n",
                "                style.SQL_KEYWORD(\"UPDATE\"),\n",
                "                style.SQL_TABLE(self.quote_name(\"sqlite_sequence\")),\n",
                "                style.SQL_KEYWORD(\"SET\"),\n",
                "                style.SQL_FIELD(self.quote_name(\"seq\")),\n",
                "                style.SQL_KEYWORD(\"WHERE\"),\n",
                "                style.SQL_FIELD(self.quote_name(\"name\")),\n",
                "                style.SQL_KEYWORD(\"IN\"),\n",
                "                \", \".join(\n",
                "                    [\"'%s'\" % sequence_info[\"table\"] for sequence_info in sequences]\n",
                "                ),\n",
                "            ),\n",
                "        ]\n",
                "\n",
                "    def adapt_datetimefield_value(self, value):\n",
                "        if value is None:\n",
                "            return None\n",
                "\n",
                "        # Expression values are adapted by the database.\n",
                "        if hasattr(value, \"resolve_expression\"):\n",
                "            return value\n",
                "\n",
                "        # SQLite doesn't support tz-aware datetimes\n",
                "        if timezone.is_aware(value):\n",
                "            if settings.USE_TZ:\n",
                "                value = timezone.make_naive(value, self.connection.timezone)\n",
                "            else:\n",
                "                raise ValueError(\n",
                "                    \"SQLite backend does not support timezone-aware datetimes when \"\n",
                "                    \"USE_TZ is False.\"\n",
                "                )\n",
                "\n",
                "        return str(value)\n",
                "\n",
                "    def adapt_timefield_value(self, value):\n",
                "        if value is None:\n",
                "            return None\n",
                "\n",
                "        # Expression values are adapted by the database.\n",
                "        if hasattr(value, \"resolve_expression\"):\n",
                "            return value\n",
                "\n",
                "        # SQLite doesn't support tz-aware datetimes\n",
                "        if timezone.is_aware(value):\n",
                "            raise ValueError(\"SQLite backend does not support timezone-aware times.\")\n",
                "\n",
                "        return str(value)\n",
                "\n",
                "    def get_db_converters(self, expression):\n",
                "        converters = super().get_db_converters(expression)\n",
                "        internal_type = expression.output_field.get_internal_type()\n",
                "        if internal_type == \"DateTimeField\":\n",
                "            converters.append(self.convert_datetimefield_value)\n",
                "        elif internal_type == \"DateField\":\n",
                "            converters.append(self.convert_datefield_value)\n",
                "        elif internal_type == \"TimeField\":\n",
                "            converters.append(self.convert_timefield_value)\n",
                "        elif internal_type == \"DecimalField\":\n",
                "            converters.append(self.get_decimalfield_converter(expression))\n",
                "        elif internal_type == \"UUIDField\":\n",
                "            converters.append(self.convert_uuidfield_value)\n",
                "        elif internal_type == \"BooleanField\":\n",
                "            converters.append(self.convert_booleanfield_value)\n",
                "        return converters\n",
                "\n",
                "    def convert_datetimefield_value(self, value, expression, connection):\n",
                "        if value is not None:\n",
                "            if not isinstance(value, datetime.datetime):\n",
                "                value = parse_datetime(value)\n",
                "            if settings.USE_TZ and not timezone.is_aware(value):\n",
                "                value = timezone.make_aware(value, self.connection.timezone)\n",
                "        return value\n",
                "\n",
                "    def convert_datefield_value(self, value, expression, connection):\n",
                "        if value is not None:\n",
                "            if not isinstance(value, datetime.date):\n",
                "                value = parse_date(value)\n",
                "        return value\n",
                "\n",
                "    def convert_timefield_value(self, value, expression, connection):\n",
                "        if value is not None:\n",
                "            if not isinstance(value, datetime.time):\n",
                "                value = parse_time(value)\n",
                "        return value\n",
                "\n",
                "    def get_decimalfield_converter(self, expression):\n",
                "        # SQLite stores only 15 significant digits. Digits coming from\n",
                "        # float inaccuracy must be removed.\n",
                "        create_decimal = decimal.Context(prec=15).create_decimal_from_float\n",
                "        if isinstance(expression, Col):\n",
                "            quantize_value = decimal.Decimal(1).scaleb(\n",
                "                -expression.output_field.decimal_places\n",
                "            )\n",
                "\n",
                "            def converter(value, expression, connection):\n",
                "                if value is not None:\n",
                "                    return create_decimal(value).quantize(\n",
                "                        quantize_value, context=expression.output_field.context\n",
                "                    )\n",
                "\n",
                "        else:\n",
                "\n",
                "            def converter(value, expression, connection):\n",
                "                if value is not None:\n",
                "                    return create_decimal(value)\n",
                "\n",
                "        return converter\n",
                "\n",
                "    def convert_uuidfield_value(self, value, expression, connection):\n",
                "        if value is not None:\n",
                "            value = uuid.UUID(value)\n",
                "        return value\n",
                "\n",
                "    def convert_booleanfield_value(self, value, expression, connection):\n",
                "        return bool(value) if value in (1, 0) else value\n",
                "\n",
                "    def bulk_insert_sql(self, fields, placeholder_rows):\n",
                "        placeholder_rows_sql = (\", \".join(row) for row in placeholder_rows)\n",
                "        values_sql = \", \".join(f\"({sql})\" for sql in placeholder_rows_sql)\n",
                "        return f\"VALUES {values_sql}\"\n",
                "\n",
                "    def combine_expression(self, connector, sub_expressions):\n",
                "        # SQLite doesn't have a ^ operator, so use the user-defined POWER\n",
                "        # function that's registered in connect().\n",
                "        if connector == \"^\":\n",
                "            return \"POWER(%s)\" % \",\".join(sub_expressions)\n",
                "        elif connector == \"#\":\n",
                "            return \"BITXOR(%s)\" % \",\".join(sub_expressions)\n",
                "        return super().combine_expression(connector, sub_expressions)\n",
                "\n",
                "    def combine_duration_expression(self, connector, sub_expressions):\n",
                "        if connector not in [\"+\", \"-\", \"*\", \"/\"]:\n",
                "            raise DatabaseError(\"Invalid connector for timedelta: %s.\" % connector)\n",
                "        fn_params = [\"'%s'\" % connector] + sub_expressions\n",
                "        if len(fn_params) > 3:\n",
                "            raise ValueError(\"Too many params for timedelta operations.\")\n",
                "        return \"django_format_dtdelta(%s)\" % \", \".join(fn_params)\n",
                "\n",
                "    def integer_field_range(self, internal_type):\n",
                "        # SQLite doesn't enforce any integer constraints, but sqlite3 supports\n",
                "        # integers up to 64 bits.\n",
                "        if internal_type in [\n",
                "            \"PositiveBigIntegerField\",\n",
                "            \"PositiveIntegerField\",\n",
                "            \"PositiveSmallIntegerField\",\n",
                "        ]:\n",
                "            return (0, 9223372036854775807)\n",
                "        return (-9223372036854775808, 9223372036854775807)\n",
                "\n",
                "    def subtract_temporals(self, internal_type, lhs, rhs):\n",
                "        lhs_sql, lhs_params = lhs\n",
                "        rhs_sql, rhs_params = rhs\n",
                "        params = (*lhs_params, *rhs_params)\n",
                "        if internal_type == \"TimeField\":\n",
                "            return \"django_time_diff(%s, %s)\" % (lhs_sql, rhs_sql), params\n",
                "        return \"django_timestamp_diff(%s, %s)\" % (lhs_sql, rhs_sql), params\n",
                "\n",
                "    def insert_statement(self, on_conflict=None):\n",
                "        if on_conflict == OnConflict.IGNORE:\n",
                "            return \"INSERT OR IGNORE INTO\"\n",
                "        return super().insert_statement(on_conflict=on_conflict)\n",
                "\n",
                "    def return_insert_columns(self, fields):\n",
                "        # SQLite < 3.35 doesn't support an INSERT...RETURNING statement.\n",
                "        if not fields:\n",
                "            return \"\", ()\n",
                "        columns = [\n",
                "            \"%s.%s\"\n",
                "            % (\n",
                "                self.quote_name(field.model._meta.db_table),\n",
                "                self.quote_name(field.column),\n",
                "            )\n",
                "            for field in fields\n",
                "        ]\n",
                "        return \"RETURNING %s\" % \", \".join(columns), ()\n",
                "\n",
                "    def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):\n",
                "        if (\n",
                "            on_conflict == OnConflict.UPDATE\n",
                "            and self.connection.features.supports_update_conflicts_with_target\n",
                "        ):\n",
                "            return \"ON CONFLICT(%s) DO UPDATE SET %s\" % (\n",
                "                \", \".join(map(self.quote_name, unique_fields)),\n",
                "                \", \".join(\n",
                "                    [\n",
                "                        f\"{field} = EXCLUDED.{field}\"\n",
                "                        for field in map(self.quote_name, update_fields)\n",
                "                    ]\n",
                "                ),\n",
                "            )\n",
                "        return super().on_conflict_suffix_sql(\n",
                "            fields,\n",
                "            on_conflict,\n",
                "            update_fields,\n",
                "            unique_fields,\n",
                "        )\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}