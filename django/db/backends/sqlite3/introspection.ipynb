{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "import sqlparse\n",
    "\n",
    "from django.db import DatabaseError\n",
    "from django.db.backends.base.introspection import BaseDatabaseIntrospection\n",
    "from django.db.backends.base.introspection import FieldInfo as BaseFieldInfo\n",
    "from django.db.backends.base.introspection import TableInfo\n",
    "from django.db.models import Index\n",
    "from django.utils.regex_helper import _lazy_re_compile\n",
    "\n",
    "FieldInfo = namedtuple(\n",
    "    \"FieldInfo\", BaseFieldInfo._fields + (\"pk\", \"has_json_constraint\")\n",
    ")\n",
    "\n",
    "field_size_re = _lazy_re_compile(r\"^\\s*(?:var)?char\\s*\\(\\s*(\\d+)\\s*\\)\\s*$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_field_size(name):\n",
    "    \"\"\"Extract the size number from a \"varchar(11)\" type name\"\"\"\n",
    "    m = field_size_re.search(name)\n",
    "    return int(m[1]) if m else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This light wrapper \"fakes\" a dictionary interface, because some SQLite data\n",
    "# types include variables in them -- e.g. \"varchar(30)\" -- and can't be matched\n",
    "# as a simple dictionary lookup.\n",
    "class FlexibleFieldLookupDict:\n",
    "    # Maps SQL types to Django Field types. Some of the SQL types have multiple\n",
    "    # entries here because SQLite allows for anything and doesn't normalize the\n",
    "    # field type; it uses whatever was given.\n",
    "    base_data_types_reverse = {\n",
    "        \"bool\": \"BooleanField\",\n",
    "        \"boolean\": \"BooleanField\",\n",
    "        \"smallint\": \"SmallIntegerField\",\n",
    "        \"smallint unsigned\": \"PositiveSmallIntegerField\",\n",
    "        \"smallinteger\": \"SmallIntegerField\",\n",
    "        \"int\": \"IntegerField\",\n",
    "        \"integer\": \"IntegerField\",\n",
    "        \"bigint\": \"BigIntegerField\",\n",
    "        \"integer unsigned\": \"PositiveIntegerField\",\n",
    "        \"bigint unsigned\": \"PositiveBigIntegerField\",\n",
    "        \"decimal\": \"DecimalField\",\n",
    "        \"real\": \"FloatField\",\n",
    "        \"text\": \"TextField\",\n",
    "        \"char\": \"CharField\",\n",
    "        \"varchar\": \"CharField\",\n",
    "        \"blob\": \"BinaryField\",\n",
    "        \"date\": \"DateField\",\n",
    "        \"datetime\": \"DateTimeField\",\n",
    "        \"time\": \"TimeField\",\n",
    "    }\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        key = key.lower().split(\"(\", 1)[0].strip()\n",
    "        return self.base_data_types_reverse[key]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseIntrospection(BaseDatabaseIntrospection):\n",
    "    data_types_reverse = FlexibleFieldLookupDict()\n",
    "\n",
    "    def get_field_type(self, data_type, description):\n",
    "        field_type = super().get_field_type(data_type, description)\n",
    "        if description.pk and field_type in {\n",
    "            \"BigIntegerField\",\n",
    "            \"IntegerField\",\n",
    "            \"SmallIntegerField\",\n",
    "        }:\n",
    "            # No support for BigAutoField or SmallAutoField as SQLite treats\n",
    "            # all integer primary keys as signed 64-bit integers.\n",
    "            return \"AutoField\"\n",
    "        if description.has_json_constraint:\n",
    "            return \"JSONField\"\n",
    "        return field_type\n",
    "\n",
    "    def get_table_list(self, cursor):\n",
    "        \"\"\"Return a list of table and view names in the current database.\"\"\"\n",
    "        # Skip the sqlite_sequence system table used for autoincrement key\n",
    "        # generation.\n",
    "        cursor.execute(\n",
    "            \"\"\"\n",
    "            SELECT name, type FROM sqlite_master\n",
    "            WHERE type in ('table', 'view') AND NOT name='sqlite_sequence'\n",
    "            ORDER BY name\"\"\"\n",
    "        )\n",
    "        return [TableInfo(row[0], row[1][0]) for row in cursor.fetchall()]\n",
    "\n",
    "    def get_table_description(self, cursor, table_name):\n",
    "        \"\"\"\n",
    "        Return a description of the table with the DB-API cursor.description\n",
    "        interface.\n",
    "        \"\"\"\n",
    "        cursor.execute(\n",
    "            \"PRAGMA table_xinfo(%s)\" % self.connection.ops.quote_name(table_name)\n",
    "        )\n",
    "        table_info = cursor.fetchall()\n",
    "        if not table_info:\n",
    "            raise DatabaseError(f\"Table {table_name} does not exist (empty pragma).\")\n",
    "        collations = self._get_column_collations(cursor, table_name)\n",
    "        json_columns = set()\n",
    "        if self.connection.features.can_introspect_json_field:\n",
    "            for line in table_info:\n",
    "                column = line[1]\n",
    "                json_constraint_sql = '%%json_valid(\"%s\")%%' % column\n",
    "                has_json_constraint = cursor.execute(\n",
    "                    \"\"\"\n",
    "                    SELECT sql\n",
    "                    FROM sqlite_master\n",
    "                    WHERE\n",
    "                        type = 'table' AND\n",
    "                        name = %s AND\n",
    "                        sql LIKE %s\n",
    "                \"\"\",\n",
    "                    [table_name, json_constraint_sql],\n",
    "                ).fetchone()\n",
    "                if has_json_constraint:\n",
    "                    json_columns.add(column)\n",
    "        return [\n",
    "            FieldInfo(\n",
    "                name,\n",
    "                data_type,\n",
    "                get_field_size(data_type),\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "                not notnull,\n",
    "                default,\n",
    "                collations.get(name),\n",
    "                pk == 1,\n",
    "                name in json_columns,\n",
    "            )\n",
    "            for cid, name, data_type, notnull, default, pk, hidden in table_info\n",
    "            if hidden\n",
    "            in [\n",
    "                0,  # Normal column.\n",
    "                2,  # Virtual generated column.\n",
    "                3,  # Stored generated column.\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    def get_sequences(self, cursor, table_name, table_fields=()):\n",
    "        pk_col = self.get_primary_key_column(cursor, table_name)\n",
    "        return [{\"table\": table_name, \"column\": pk_col}]\n",
    "\n",
    "    def get_relations(self, cursor, table_name):\n",
    "        \"\"\"\n",
    "        Return a dictionary of {column_name: (ref_column_name, ref_table_name)}\n",
    "        representing all foreign keys in the given table.\n",
    "        \"\"\"\n",
    "        cursor.execute(\n",
    "            \"PRAGMA foreign_key_list(%s)\" % self.connection.ops.quote_name(table_name)\n",
    "        )\n",
    "        return {\n",
    "            column_name: (ref_column_name, ref_table_name)\n",
    "            for (\n",
    "                _,\n",
    "                _,\n",
    "                ref_table_name,\n",
    "                column_name,\n",
    "                ref_column_name,\n",
    "                *_,\n",
    "            ) in cursor.fetchall()\n",
    "        }\n",
    "\n",
    "    def get_primary_key_columns(self, cursor, table_name):\n",
    "        cursor.execute(\n",
    "            \"PRAGMA table_info(%s)\" % self.connection.ops.quote_name(table_name)\n",
    "        )\n",
    "        return [name for _, name, *_, pk in cursor.fetchall() if pk]\n",
    "\n",
    "    def _parse_column_or_constraint_definition(self, tokens, columns):\n",
    "        token = None\n",
    "        is_constraint_definition = None\n",
    "        field_name = None\n",
    "        constraint_name = None\n",
    "        unique = False\n",
    "        unique_columns = []\n",
    "        check = False\n",
    "        check_columns = []\n",
    "        braces_deep = 0\n",
    "        for token in tokens:\n",
    "            if token.match(sqlparse.tokens.Punctuation, \"(\"):\n",
    "                braces_deep += 1\n",
    "            elif token.match(sqlparse.tokens.Punctuation, \")\"):\n",
    "                braces_deep -= 1\n",
    "                if braces_deep < 0:\n",
    "                    # End of columns and constraints for table definition.\n",
    "                    break\n",
    "            elif braces_deep == 0 and token.match(sqlparse.tokens.Punctuation, \",\"):\n",
    "                # End of current column or constraint definition.\n",
    "                break\n",
    "            # Detect column or constraint definition by first token.\n",
    "            if is_constraint_definition is None:\n",
    "                is_constraint_definition = token.match(\n",
    "                    sqlparse.tokens.Keyword, \"CONSTRAINT\"\n",
    "                )\n",
    "                if is_constraint_definition:\n",
    "                    continue\n",
    "            if is_constraint_definition:\n",
    "                # Detect constraint name by second token.\n",
    "                if constraint_name is None:\n",
    "                    if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):\n",
    "                        constraint_name = token.value\n",
    "                    elif token.ttype == sqlparse.tokens.Literal.String.Symbol:\n",
    "                        constraint_name = token.value[1:-1]\n",
    "                # Start constraint columns parsing after UNIQUE keyword.\n",
    "                if token.match(sqlparse.tokens.Keyword, \"UNIQUE\"):\n",
    "                    unique = True\n",
    "                    unique_braces_deep = braces_deep\n",
    "                elif unique:\n",
    "                    if unique_braces_deep == braces_deep:\n",
    "                        if unique_columns:\n",
    "                            # Stop constraint parsing.\n",
    "                            unique = False\n",
    "                        continue\n",
    "                    if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):\n",
    "                        unique_columns.append(token.value)\n",
    "                    elif token.ttype == sqlparse.tokens.Literal.String.Symbol:\n",
    "                        unique_columns.append(token.value[1:-1])\n",
    "            else:\n",
    "                # Detect field name by first token.\n",
    "                if field_name is None:\n",
    "                    if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):\n",
    "                        field_name = token.value\n",
    "                    elif token.ttype == sqlparse.tokens.Literal.String.Symbol:\n",
    "                        field_name = token.value[1:-1]\n",
    "                if token.match(sqlparse.tokens.Keyword, \"UNIQUE\"):\n",
    "                    unique_columns = [field_name]\n",
    "            # Start constraint columns parsing after CHECK keyword.\n",
    "            if token.match(sqlparse.tokens.Keyword, \"CHECK\"):\n",
    "                check = True\n",
    "                check_braces_deep = braces_deep\n",
    "            elif check:\n",
    "                if check_braces_deep == braces_deep:\n",
    "                    if check_columns:\n",
    "                        # Stop constraint parsing.\n",
    "                        check = False\n",
    "                    continue\n",
    "                if token.ttype in (sqlparse.tokens.Name, sqlparse.tokens.Keyword):\n",
    "                    if token.value in columns:\n",
    "                        check_columns.append(token.value)\n",
    "                elif token.ttype == sqlparse.tokens.Literal.String.Symbol:\n",
    "                    if token.value[1:-1] in columns:\n",
    "                        check_columns.append(token.value[1:-1])\n",
    "        unique_constraint = (\n",
    "            {\n",
    "                \"unique\": True,\n",
    "                \"columns\": unique_columns,\n",
    "                \"primary_key\": False,\n",
    "                \"foreign_key\": None,\n",
    "                \"check\": False,\n",
    "                \"index\": False,\n",
    "            }\n",
    "            if unique_columns\n",
    "            else None\n",
    "        )\n",
    "        check_constraint = (\n",
    "            {\n",
    "                \"check\": True,\n",
    "                \"columns\": check_columns,\n",
    "                \"primary_key\": False,\n",
    "                \"unique\": False,\n",
    "                \"foreign_key\": None,\n",
    "                \"index\": False,\n",
    "            }\n",
    "            if check_columns\n",
    "            else None\n",
    "        )\n",
    "        return constraint_name, unique_constraint, check_constraint, token\n",
    "\n",
    "    def _parse_table_constraints(self, sql, columns):\n",
    "        # Check constraint parsing is based of SQLite syntax diagram.\n",
    "        # https://www.sqlite.org/syntaxdiagrams.html#table-constraint\n",
    "        statement = sqlparse.parse(sql)[0]\n",
    "        constraints = {}\n",
    "        unnamed_constrains_index = 0\n",
    "        tokens = (token for token in statement.flatten() if not token.is_whitespace)\n",
    "        # Go to columns and constraint definition\n",
    "        for token in tokens:\n",
    "            if token.match(sqlparse.tokens.Punctuation, \"(\"):\n",
    "                break\n",
    "        # Parse columns and constraint definition\n",
    "        while True:\n",
    "            (\n",
    "                constraint_name,\n",
    "                unique,\n",
    "                check,\n",
    "                end_token,\n",
    "            ) = self._parse_column_or_constraint_definition(tokens, columns)\n",
    "            if unique:\n",
    "                if constraint_name:\n",
    "                    constraints[constraint_name] = unique\n",
    "                else:\n",
    "                    unnamed_constrains_index += 1\n",
    "                    constraints[\n",
    "                        \"__unnamed_constraint_%s__\" % unnamed_constrains_index\n",
    "                    ] = unique\n",
    "            if check:\n",
    "                if constraint_name:\n",
    "                    constraints[constraint_name] = check\n",
    "                else:\n",
    "                    unnamed_constrains_index += 1\n",
    "                    constraints[\n",
    "                        \"__unnamed_constraint_%s__\" % unnamed_constrains_index\n",
    "                    ] = check\n",
    "            if end_token.match(sqlparse.tokens.Punctuation, \")\"):\n",
    "                break\n",
    "        return constraints\n",
    "\n",
    "    def get_constraints(self, cursor, table_name):\n",
    "        \"\"\"\n",
    "        Retrieve any constraints or keys (unique, pk, fk, check, index) across\n",
    "        one or more columns.\n",
    "        \"\"\"\n",
    "        constraints = {}\n",
    "        # Find inline check constraints.\n",
    "        try:\n",
    "            table_schema = cursor.execute(\n",
    "                \"SELECT sql FROM sqlite_master WHERE type='table' and name=%s\"\n",
    "                % (self.connection.ops.quote_name(table_name),)\n",
    "            ).fetchone()[0]\n",
    "        except TypeError:\n",
    "            # table_name is a view.\n",
    "            pass\n",
    "        else:\n",
    "            columns = {\n",
    "                info.name for info in self.get_table_description(cursor, table_name)\n",
    "            }\n",
    "            constraints.update(self._parse_table_constraints(table_schema, columns))\n",
    "\n",
    "        # Get the index info\n",
    "        cursor.execute(\n",
    "            \"PRAGMA index_list(%s)\" % self.connection.ops.quote_name(table_name)\n",
    "        )\n",
    "        for row in cursor.fetchall():\n",
    "            # SQLite 3.8.9+ has 5 columns, however older versions only give 3\n",
    "            # columns. Discard last 2 columns if there.\n",
    "            number, index, unique = row[:3]\n",
    "            cursor.execute(\n",
    "                \"SELECT sql FROM sqlite_master \"\n",
    "                \"WHERE type='index' AND name=%s\" % self.connection.ops.quote_name(index)\n",
    "            )\n",
    "            # There's at most one row.\n",
    "            (sql,) = cursor.fetchone() or (None,)\n",
    "            # Inline constraints are already detected in\n",
    "            # _parse_table_constraints(). The reasons to avoid fetching inline\n",
    "            # constraints from `PRAGMA index_list` are:\n",
    "            # - Inline constraints can have a different name and information\n",
    "            #   than what `PRAGMA index_list` gives.\n",
    "            # - Not all inline constraints may appear in `PRAGMA index_list`.\n",
    "            if not sql:\n",
    "                # An inline constraint\n",
    "                continue\n",
    "            # Get the index info for that index\n",
    "            cursor.execute(\n",
    "                \"PRAGMA index_info(%s)\" % self.connection.ops.quote_name(index)\n",
    "            )\n",
    "            for index_rank, column_rank, column in cursor.fetchall():\n",
    "                if index not in constraints:\n",
    "                    constraints[index] = {\n",
    "                        \"columns\": [],\n",
    "                        \"primary_key\": False,\n",
    "                        \"unique\": bool(unique),\n",
    "                        \"foreign_key\": None,\n",
    "                        \"check\": False,\n",
    "                        \"index\": True,\n",
    "                    }\n",
    "                constraints[index][\"columns\"].append(column)\n",
    "            # Add type and column orders for indexes\n",
    "            if constraints[index][\"index\"]:\n",
    "                # SQLite doesn't support any index type other than b-tree\n",
    "                constraints[index][\"type\"] = Index.suffix\n",
    "                orders = self._get_index_columns_orders(sql)\n",
    "                if orders is not None:\n",
    "                    constraints[index][\"orders\"] = orders\n",
    "        # Get the PK\n",
    "        pk_columns = self.get_primary_key_columns(cursor, table_name)\n",
    "        if pk_columns:\n",
    "            # SQLite doesn't actually give a name to the PK constraint,\n",
    "            # so we invent one. This is fine, as the SQLite backend never\n",
    "            # deletes PK constraints by name, as you can't delete constraints\n",
    "            # in SQLite; we remake the table with a new PK instead.\n",
    "            constraints[\"__primary__\"] = {\n",
    "                \"columns\": pk_columns,\n",
    "                \"primary_key\": True,\n",
    "                \"unique\": False,  # It's not actually a unique constraint.\n",
    "                \"foreign_key\": None,\n",
    "                \"check\": False,\n",
    "                \"index\": False,\n",
    "            }\n",
    "        relations = enumerate(self.get_relations(cursor, table_name).items())\n",
    "        constraints.update(\n",
    "            {\n",
    "                f\"fk_{index}\": {\n",
    "                    \"columns\": [column_name],\n",
    "                    \"primary_key\": False,\n",
    "                    \"unique\": False,\n",
    "                    \"foreign_key\": (ref_table_name, ref_column_name),\n",
    "                    \"check\": False,\n",
    "                    \"index\": False,\n",
    "                }\n",
    "                for index, (column_name, (ref_column_name, ref_table_name)) in relations\n",
    "            }\n",
    "        )\n",
    "        return constraints\n",
    "\n",
    "    def _get_index_columns_orders(self, sql):\n",
    "        tokens = sqlparse.parse(sql)[0]\n",
    "        for token in tokens:\n",
    "            if isinstance(token, sqlparse.sql.Parenthesis):\n",
    "                columns = str(token).strip(\"()\").split(\", \")\n",
    "                return [\"DESC\" if info.endswith(\"DESC\") else \"ASC\" for info in columns]\n",
    "        return None\n",
    "\n",
    "    def _get_column_collations(self, cursor, table_name):\n",
    "        row = cursor.execute(\n",
    "            \"\"\"\n",
    "            SELECT sql\n",
    "            FROM sqlite_master\n",
    "            WHERE type = 'table' AND name = %s\n",
    "        \"\"\",\n",
    "            [table_name],\n",
    "        ).fetchone()\n",
    "        if not row:\n",
    "            return {}\n",
    "\n",
    "        sql = row[0]\n",
    "        columns = str(sqlparse.parse(sql)[0][-1]).strip(\"()\").split(\", \")\n",
    "        collations = {}\n",
    "        for column in columns:\n",
    "            tokens = column[1:].split()\n",
    "            column_name = tokens[0].strip('\"')\n",
    "            for index, token in enumerate(tokens):\n",
    "                if token == \"COLLATE\":\n",
    "                    collation = tokens[index + 1]\n",
    "                    break\n",
    "            else:\n",
    "                collation = None\n",
    "            collations[column_name] = collation\n",
    "        return collations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}