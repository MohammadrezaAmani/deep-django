{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "from functools import lru_cache, partial\n",
                "\n",
                "from django.conf import settings\n",
                "from django.db.backends.base.operations import BaseDatabaseOperations\n",
                "from django.db.backends.postgresql.psycopg_any import (\n",
                "    Inet,\n",
                "    Jsonb,\n",
                "    errors,\n",
                "    is_psycopg3,\n",
                "    mogrify,\n",
                ")\n",
                "from django.db.backends.utils import split_tzname_delta\n",
                "from django.db.models.constants import OnConflict\n",
                "from django.db.models.functions import Cast\n",
                "from django.utils.regex_helper import _lazy_re_compile\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "@lru_cache\n",
                "def get_json_dumps(encoder):\n",
                "    if encoder is None:\n",
                "        return json.dumps\n",
                "    return partial(json.dumps, cls=encoder)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class DatabaseOperations(BaseDatabaseOperations):\n",
                "    cast_char_field_without_max_length = \"varchar\"\n",
                "    explain_prefix = \"EXPLAIN\"\n",
                "    explain_options = frozenset(\n",
                "        [\n",
                "            \"ANALYZE\",\n",
                "            \"BUFFERS\",\n",
                "            \"COSTS\",\n",
                "            \"SETTINGS\",\n",
                "            \"SUMMARY\",\n",
                "            \"TIMING\",\n",
                "            \"VERBOSE\",\n",
                "            \"WAL\",\n",
                "        ]\n",
                "    )\n",
                "    cast_data_types = {\n",
                "        \"AutoField\": \"integer\",\n",
                "        \"BigAutoField\": \"bigint\",\n",
                "        \"SmallAutoField\": \"smallint\",\n",
                "    }\n",
                "\n",
                "    if is_psycopg3:\n",
                "        from psycopg.types import numeric\n",
                "\n",
                "        integerfield_type_map = {\n",
                "            \"SmallIntegerField\": numeric.Int2,\n",
                "            \"IntegerField\": numeric.Int4,\n",
                "            \"BigIntegerField\": numeric.Int8,\n",
                "            \"PositiveSmallIntegerField\": numeric.Int2,\n",
                "            \"PositiveIntegerField\": numeric.Int4,\n",
                "            \"PositiveBigIntegerField\": numeric.Int8,\n",
                "        }\n",
                "\n",
                "    def unification_cast_sql(self, output_field):\n",
                "        internal_type = output_field.get_internal_type()\n",
                "        if internal_type in (\n",
                "            \"GenericIPAddressField\",\n",
                "            \"IPAddressField\",\n",
                "            \"TimeField\",\n",
                "            \"UUIDField\",\n",
                "        ):\n",
                "            # PostgreSQL will resolve a union as type 'text' if input types are\n",
                "            # 'unknown'.\n",
                "            # https://www.postgresql.org/docs/current/typeconv-union-case.html\n",
                "            # These fields cannot be implicitly cast back in the default\n",
                "            # PostgreSQL configuration so we need to explicitly cast them.\n",
                "            # We must also remove components of the type within brackets:\n",
                "            # varchar(255) -> varchar.\n",
                "            return (\n",
                "                \"CAST(%%s AS %s)\" % output_field.db_type(self.connection).split(\"(\")[0]\n",
                "            )\n",
                "        return \"%s\"\n",
                "\n",
                "    # EXTRACT format cannot be passed in parameters.\n",
                "    _extract_format_re = _lazy_re_compile(r\"[A-Z_]+\")\n",
                "\n",
                "    def date_extract_sql(self, lookup_type, sql, params):\n",
                "        # https://www.postgresql.org/docs/current/functions-datetime.html#FUNCTIONS-DATETIME-EXTRACT\n",
                "        if lookup_type == \"week_day\":\n",
                "            # For consistency across backends, we return Sunday=1, Saturday=7.\n",
                "            return f\"EXTRACT(DOW FROM {sql}) + 1\", params\n",
                "        elif lookup_type == \"iso_week_day\":\n",
                "            return f\"EXTRACT(ISODOW FROM {sql})\", params\n",
                "        elif lookup_type == \"iso_year\":\n",
                "            return f\"EXTRACT(ISOYEAR FROM {sql})\", params\n",
                "\n",
                "        lookup_type = lookup_type.upper()\n",
                "        if not self._extract_format_re.fullmatch(lookup_type):\n",
                "            raise ValueError(f\"Invalid lookup type: {lookup_type!r}\")\n",
                "        return f\"EXTRACT({lookup_type} FROM {sql})\", params\n",
                "\n",
                "    def date_trunc_sql(self, lookup_type, sql, params, tzname=None):\n",
                "        sql, params = self._convert_sql_to_tz(sql, params, tzname)\n",
                "        # https://www.postgresql.org/docs/current/functions-datetime.html#FUNCTIONS-DATETIME-TRUNC\n",
                "        return f\"DATE_TRUNC(%s, {sql})\", (lookup_type, *params)\n",
                "\n",
                "    def _prepare_tzname_delta(self, tzname):\n",
                "        tzname, sign, offset = split_tzname_delta(tzname)\n",
                "        if offset:\n",
                "            sign = \"-\" if sign == \"+\" else \"+\"\n",
                "            return f\"{tzname}{sign}{offset}\"\n",
                "        return tzname\n",
                "\n",
                "    def _convert_sql_to_tz(self, sql, params, tzname):\n",
                "        if tzname and settings.USE_TZ:\n",
                "            tzname_param = self._prepare_tzname_delta(tzname)\n",
                "            return f\"{sql} AT TIME ZONE %s\", (*params, tzname_param)\n",
                "        return sql, params\n",
                "\n",
                "    def datetime_cast_date_sql(self, sql, params, tzname):\n",
                "        sql, params = self._convert_sql_to_tz(sql, params, tzname)\n",
                "        return f\"({sql})::date\", params\n",
                "\n",
                "    def datetime_cast_time_sql(self, sql, params, tzname):\n",
                "        sql, params = self._convert_sql_to_tz(sql, params, tzname)\n",
                "        return f\"({sql})::time\", params\n",
                "\n",
                "    def datetime_extract_sql(self, lookup_type, sql, params, tzname):\n",
                "        sql, params = self._convert_sql_to_tz(sql, params, tzname)\n",
                "        if lookup_type == \"second\":\n",
                "            # Truncate fractional seconds.\n",
                "            return f\"EXTRACT(SECOND FROM DATE_TRUNC(%s, {sql}))\", (\"second\", *params)\n",
                "        return self.date_extract_sql(lookup_type, sql, params)\n",
                "\n",
                "    def datetime_trunc_sql(self, lookup_type, sql, params, tzname):\n",
                "        sql, params = self._convert_sql_to_tz(sql, params, tzname)\n",
                "        # https://www.postgresql.org/docs/current/functions-datetime.html#FUNCTIONS-DATETIME-TRUNC\n",
                "        return f\"DATE_TRUNC(%s, {sql})\", (lookup_type, *params)\n",
                "\n",
                "    def time_extract_sql(self, lookup_type, sql, params):\n",
                "        if lookup_type == \"second\":\n",
                "            # Truncate fractional seconds.\n",
                "            return f\"EXTRACT(SECOND FROM DATE_TRUNC(%s, {sql}))\", (\"second\", *params)\n",
                "        return self.date_extract_sql(lookup_type, sql, params)\n",
                "\n",
                "    def time_trunc_sql(self, lookup_type, sql, params, tzname=None):\n",
                "        sql, params = self._convert_sql_to_tz(sql, params, tzname)\n",
                "        return f\"DATE_TRUNC(%s, {sql})::time\", (lookup_type, *params)\n",
                "\n",
                "    def deferrable_sql(self):\n",
                "        return \" DEFERRABLE INITIALLY DEFERRED\"\n",
                "\n",
                "    def fetch_returned_insert_rows(self, cursor):\n",
                "        \"\"\"\n",
                "        Given a cursor object that has just performed an INSERT...RETURNING\n",
                "        statement into a table, return the tuple of returned data.\n",
                "        \"\"\"\n",
                "        return cursor.fetchall()\n",
                "\n",
                "    def lookup_cast(self, lookup_type, internal_type=None):\n",
                "        lookup = \"%s\"\n",
                "        # Cast text lookups to text to allow things like filter(x__contains=4)\n",
                "        if lookup_type in (\n",
                "            \"iexact\",\n",
                "            \"contains\",\n",
                "            \"icontains\",\n",
                "            \"startswith\",\n",
                "            \"istartswith\",\n",
                "            \"endswith\",\n",
                "            \"iendswith\",\n",
                "            \"regex\",\n",
                "            \"iregex\",\n",
                "        ):\n",
                "            if internal_type in (\"IPAddressField\", \"GenericIPAddressField\"):\n",
                "                lookup = \"HOST(%s)\"\n",
                "            # RemovedInDjango51Warning.\n",
                "            elif internal_type in (\"CICharField\", \"CIEmailField\", \"CITextField\"):\n",
                "                lookup = \"%s::citext\"\n",
                "            else:\n",
                "                lookup = \"%s::text\"\n",
                "\n",
                "        # Use UPPER(x) for case-insensitive lookups; it's faster.\n",
                "        if lookup_type in (\"iexact\", \"icontains\", \"istartswith\", \"iendswith\"):\n",
                "            lookup = \"UPPER(%s)\" % lookup\n",
                "\n",
                "        return lookup\n",
                "\n",
                "    def no_limit_value(self):\n",
                "        return None\n",
                "\n",
                "    def prepare_sql_script(self, sql):\n",
                "        return [sql]\n",
                "\n",
                "    def quote_name(self, name):\n",
                "        if name.startswith('\"') and name.endswith('\"'):\n",
                "            return name  # Quoting once is enough.\n",
                "        return '\"%s\"' % name\n",
                "\n",
                "    def compose_sql(self, sql, params):\n",
                "        return mogrify(sql, params, self.connection)\n",
                "\n",
                "    def set_time_zone_sql(self):\n",
                "        return \"SELECT set_config('TimeZone', %s, false)\"\n",
                "\n",
                "    def sql_flush(self, style, tables, *, reset_sequences=False, allow_cascade=False):\n",
                "        if not tables:\n",
                "            return []\n",
                "\n",
                "        # Perform a single SQL 'TRUNCATE x, y, z...;' statement. It allows us\n",
                "        # to truncate tables referenced by a foreign key in any other table.\n",
                "        sql_parts = [\n",
                "            style.SQL_KEYWORD(\"TRUNCATE\"),\n",
                "            \", \".join(style.SQL_FIELD(self.quote_name(table)) for table in tables),\n",
                "        ]\n",
                "        if reset_sequences:\n",
                "            sql_parts.append(style.SQL_KEYWORD(\"RESTART IDENTITY\"))\n",
                "        if allow_cascade:\n",
                "            sql_parts.append(style.SQL_KEYWORD(\"CASCADE\"))\n",
                "        return [\"%s;\" % \" \".join(sql_parts)]\n",
                "\n",
                "    def sequence_reset_by_name_sql(self, style, sequences):\n",
                "        # 'ALTER SEQUENCE sequence_name RESTART WITH 1;'... style SQL statements\n",
                "        # to reset sequence indices\n",
                "        sql = []\n",
                "        for sequence_info in sequences:\n",
                "            table_name = sequence_info[\"table\"]\n",
                "            # 'id' will be the case if it's an m2m using an autogenerated\n",
                "            # intermediate table (see BaseDatabaseIntrospection.sequence_list).\n",
                "            column_name = sequence_info[\"column\"] or \"id\"\n",
                "            sql.append(\n",
                "                \"%s setval(pg_get_serial_sequence('%s','%s'), 1, false);\"\n",
                "                % (\n",
                "                    style.SQL_KEYWORD(\"SELECT\"),\n",
                "                    style.SQL_TABLE(self.quote_name(table_name)),\n",
                "                    style.SQL_FIELD(column_name),\n",
                "                )\n",
                "            )\n",
                "        return sql\n",
                "\n",
                "    def tablespace_sql(self, tablespace, inline=False):\n",
                "        if inline:\n",
                "            return \"USING INDEX TABLESPACE %s\" % self.quote_name(tablespace)\n",
                "        else:\n",
                "            return \"TABLESPACE %s\" % self.quote_name(tablespace)\n",
                "\n",
                "    def sequence_reset_sql(self, style, model_list):\n",
                "        from django.db import models\n",
                "\n",
                "        output = []\n",
                "        qn = self.quote_name\n",
                "        for model in model_list:\n",
                "            # Use `coalesce` to set the sequence for each model to the max pk\n",
                "            # value if there are records, or 1 if there are none. Set the\n",
                "            # `is_called` property (the third argument to `setval`) to true if\n",
                "            # there are records (as the max pk value is already in use),\n",
                "            # otherwise set it to false. Use pg_get_serial_sequence to get the\n",
                "            # underlying sequence name from the table name and column name.\n",
                "\n",
                "            for f in model._meta.local_fields:\n",
                "                if isinstance(f, models.AutoField):\n",
                "                    output.append(\n",
                "                        \"%s setval(pg_get_serial_sequence('%s','%s'), \"\n",
                "                        \"coalesce(max(%s), 1), max(%s) %s null) %s %s;\"\n",
                "                        % (\n",
                "                            style.SQL_KEYWORD(\"SELECT\"),\n",
                "                            style.SQL_TABLE(qn(model._meta.db_table)),\n",
                "                            style.SQL_FIELD(f.column),\n",
                "                            style.SQL_FIELD(qn(f.column)),\n",
                "                            style.SQL_FIELD(qn(f.column)),\n",
                "                            style.SQL_KEYWORD(\"IS NOT\"),\n",
                "                            style.SQL_KEYWORD(\"FROM\"),\n",
                "                            style.SQL_TABLE(qn(model._meta.db_table)),\n",
                "                        )\n",
                "                    )\n",
                "                    # Only one AutoField is allowed per model, so don't bother\n",
                "                    # continuing.\n",
                "                    break\n",
                "        return output\n",
                "\n",
                "    def prep_for_iexact_query(self, x):\n",
                "        return x\n",
                "\n",
                "    def max_name_length(self):\n",
                "        \"\"\"\n",
                "        Return the maximum length of an identifier.\n",
                "\n",
                "        The maximum length of an identifier is 63 by default, but can be\n",
                "        changed by recompiling PostgreSQL after editing the NAMEDATALEN\n",
                "        macro in src/include/pg_config_manual.h.\n",
                "\n",
                "        This implementation returns 63, but can be overridden by a custom\n",
                "        database backend that inherits most of its behavior from this one.\n",
                "        \"\"\"\n",
                "        return 63\n",
                "\n",
                "    def distinct_sql(self, fields, params):\n",
                "        if fields:\n",
                "            params = [param for param_list in params for param in param_list]\n",
                "            return ([\"DISTINCT ON (%s)\" % \", \".join(fields)], params)\n",
                "        else:\n",
                "            return [\"DISTINCT\"], []\n",
                "\n",
                "    if is_psycopg3:\n",
                "\n",
                "        def last_executed_query(self, cursor, sql, params):\n",
                "            try:\n",
                "                return self.compose_sql(sql, params)\n",
                "            except errors.DataError:\n",
                "                return None\n",
                "\n",
                "    else:\n",
                "\n",
                "        def last_executed_query(self, cursor, sql, params):\n",
                "            # https://www.psycopg.org/docs/cursor.html#cursor.query\n",
                "            # The query attribute is a Psycopg extension to the DB API 2.0.\n",
                "            if cursor.query is not None:\n",
                "                return cursor.query.decode()\n",
                "            return None\n",
                "\n",
                "    def return_insert_columns(self, fields):\n",
                "        if not fields:\n",
                "            return \"\", ()\n",
                "        columns = [\n",
                "            \"%s.%s\"\n",
                "            % (\n",
                "                self.quote_name(field.model._meta.db_table),\n",
                "                self.quote_name(field.column),\n",
                "            )\n",
                "            for field in fields\n",
                "        ]\n",
                "        return \"RETURNING %s\" % \", \".join(columns), ()\n",
                "\n",
                "    def bulk_insert_sql(self, fields, placeholder_rows):\n",
                "        placeholder_rows_sql = (\", \".join(row) for row in placeholder_rows)\n",
                "        values_sql = \", \".join(\"(%s)\" % sql for sql in placeholder_rows_sql)\n",
                "        return \"VALUES \" + values_sql\n",
                "\n",
                "    if is_psycopg3:\n",
                "\n",
                "        def adapt_integerfield_value(self, value, internal_type):\n",
                "            if value is None or hasattr(value, \"resolve_expression\"):\n",
                "                return value\n",
                "            return self.integerfield_type_map[internal_type](value)\n",
                "\n",
                "    def adapt_datefield_value(self, value):\n",
                "        return value\n",
                "\n",
                "    def adapt_datetimefield_value(self, value):\n",
                "        return value\n",
                "\n",
                "    def adapt_timefield_value(self, value):\n",
                "        return value\n",
                "\n",
                "    def adapt_decimalfield_value(self, value, max_digits=None, decimal_places=None):\n",
                "        return value\n",
                "\n",
                "    def adapt_ipaddressfield_value(self, value):\n",
                "        if value:\n",
                "            return Inet(value)\n",
                "        return None\n",
                "\n",
                "    def adapt_json_value(self, value, encoder):\n",
                "        return Jsonb(value, dumps=get_json_dumps(encoder))\n",
                "\n",
                "    def subtract_temporals(self, internal_type, lhs, rhs):\n",
                "        if internal_type == \"DateField\":\n",
                "            lhs_sql, lhs_params = lhs\n",
                "            rhs_sql, rhs_params = rhs\n",
                "            params = (*lhs_params, *rhs_params)\n",
                "            return \"(interval '1 day' * (%s - %s))\" % (lhs_sql, rhs_sql), params\n",
                "        return super().subtract_temporals(internal_type, lhs, rhs)\n",
                "\n",
                "    def explain_query_prefix(self, format=None, **options):\n",
                "        extra = {}\n",
                "        # Normalize options.\n",
                "        if options:\n",
                "            options = {\n",
                "                name.upper(): \"true\" if value else \"false\"\n",
                "                for name, value in options.items()\n",
                "            }\n",
                "            for valid_option in self.explain_options:\n",
                "                value = options.pop(valid_option, None)\n",
                "                if value is not None:\n",
                "                    extra[valid_option] = value\n",
                "        prefix = super().explain_query_prefix(format, **options)\n",
                "        if format:\n",
                "            extra[\"FORMAT\"] = format\n",
                "        if extra:\n",
                "            prefix += \" (%s)\" % \", \".join(\"%s %s\" % i for i in extra.items())\n",
                "        return prefix\n",
                "\n",
                "    def on_conflict_suffix_sql(self, fields, on_conflict, update_fields, unique_fields):\n",
                "        if on_conflict == OnConflict.IGNORE:\n",
                "            return \"ON CONFLICT DO NOTHING\"\n",
                "        if on_conflict == OnConflict.UPDATE:\n",
                "            return \"ON CONFLICT(%s) DO UPDATE SET %s\" % (\n",
                "                \", \".join(map(self.quote_name, unique_fields)),\n",
                "                \", \".join(\n",
                "                    [\n",
                "                        f\"{field} = EXCLUDED.{field}\"\n",
                "                        for field in map(self.quote_name, update_fields)\n",
                "                    ]\n",
                "                ),\n",
                "            )\n",
                "        return super().on_conflict_suffix_sql(\n",
                "            fields,\n",
                "            on_conflict,\n",
                "            update_fields,\n",
                "            unique_fields,\n",
                "        )\n",
                "\n",
                "    def prepare_join_on_clause(self, lhs_table, lhs_field, rhs_table, rhs_field):\n",
                "        lhs_expr, rhs_expr = super().prepare_join_on_clause(\n",
                "            lhs_table, lhs_field, rhs_table, rhs_field\n",
                "        )\n",
                "\n",
                "        if lhs_field.db_type(self.connection) != rhs_field.db_type(self.connection):\n",
                "            rhs_expr = Cast(rhs_expr, lhs_field)\n",
                "\n",
                "        return lhs_expr, rhs_expr\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}