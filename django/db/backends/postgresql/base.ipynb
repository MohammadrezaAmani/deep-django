{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PostgreSQL database backend for Django.\n",
    "\n",
    "Requires psycopg2 >= 2.8.4 or psycopg >= 3.1.8\n",
    "\"\"\"\n",
    "\n",
    "import asyncio\n",
    "import threading\n",
    "import warnings\n",
    "from contextlib import contextmanager\n",
    "\n",
    "from django.conf import settings\n",
    "from django.core.exceptions import ImproperlyConfigured\n",
    "from django.db import DatabaseError as WrappedDatabaseError\n",
    "from django.db import connections\n",
    "from django.db.backends.base.base import BaseDatabaseWrapper\n",
    "from django.db.backends.utils import CursorDebugWrapper as BaseCursorDebugWrapper\n",
    "from django.utils.asyncio import async_unsafe\n",
    "from django.utils.functional import cached_property\n",
    "from django.utils.safestring import SafeString\n",
    "from django.utils.version import get_version_tuple\n",
    "\n",
    "try:\n",
    "    try:\n",
    "        import psycopg as Database\n",
    "    except ImportError:\n",
    "        import psycopg2 as Database\n",
    "except ImportError:\n",
    "    raise ImproperlyConfigured(\"Error loading psycopg2 or psycopg module\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psycopg_version():\n",
    "    version = Database.__version__.split(\" \", 1)[0]\n",
    "    return get_version_tuple(version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if psycopg_version() < (2, 8, 4):\n",
    "    raise ImproperlyConfigured(\n",
    "        f\"psycopg2 version 2.8.4 or newer is required; you have {Database.__version__}\"\n",
    "    )\n",
    "if (3,) <= psycopg_version() < (3, 1, 8):\n",
    "    raise ImproperlyConfigured(\n",
    "        f\"psycopg version 3.1.8 or newer is required; you have {Database.__version__}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from .psycopg_any import IsolationLevel, is_psycopg3  # NOQA isort:skip\n",
    "\n",
    "if is_psycopg3:\n",
    "    from psycopg import adapters, sql\n",
    "    from psycopg.pq import Format\n",
    "\n",
    "    from .psycopg_any import get_adapters_template, register_tzloader\n",
    "\n",
    "    TIMESTAMPTZ_OID = adapters.types[\"timestamptz\"].oid\n",
    "\n",
    "else:\n",
    "    import psycopg2.extensions\n",
    "    import psycopg2.extras\n",
    "\n",
    "    psycopg2.extensions.register_adapter(SafeString, psycopg2.extensions.QuotedString)\n",
    "    psycopg2.extras.register_uuid()\n",
    "\n",
    "    # Register support for inet[] manually so we don't have to handle the Inet()\n",
    "    # object on load all the time.\n",
    "    INETARRAY_OID = 1041\n",
    "    INETARRAY = psycopg2.extensions.new_array_type(\n",
    "        (INETARRAY_OID,),\n",
    "        \"INETARRAY\",\n",
    "        psycopg2.extensions.UNICODE,\n",
    "    )\n",
    "    psycopg2.extensions.register_type(INETARRAY)\n",
    "\n",
    "# Some of these import psycopg, so import them after checking if it's installed.\n",
    "from .client import DatabaseClient  # NOQA isort:skip\n",
    "from .creation import DatabaseCreation  # NOQA isort:skip\n",
    "from .features import DatabaseFeatures  # NOQA isort:skip\n",
    "from .introspection import DatabaseIntrospection  # NOQA isort:skip\n",
    "from .operations import DatabaseOperations  # NOQA isort:skip\n",
    "from .schema import DatabaseSchemaEditor  # NOQA isort:skip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_varchar_column(data):\n",
    "    if data[\"max_length\"] is None:\n",
    "        return \"varchar\"\n",
    "    return \"varchar(%(max_length)s)\" % data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseWrapper(BaseDatabaseWrapper):\n",
    "    vendor = \"postgresql\"\n",
    "    display_name = \"PostgreSQL\"\n",
    "    # This dictionary maps Field objects to their associated PostgreSQL column\n",
    "    # types, as strings. Column-type strings can contain format strings; they'll\n",
    "    # be interpolated against the values of Field.__dict__ before being output.\n",
    "    # If a column type is set to None, it won't be included in the output.\n",
    "    data_types = {\n",
    "        \"AutoField\": \"integer\",\n",
    "        \"BigAutoField\": \"bigint\",\n",
    "        \"BinaryField\": \"bytea\",\n",
    "        \"BooleanField\": \"boolean\",\n",
    "        \"CharField\": _get_varchar_column,\n",
    "        \"DateField\": \"date\",\n",
    "        \"DateTimeField\": \"timestamp with time zone\",\n",
    "        \"DecimalField\": \"numeric(%(max_digits)s, %(decimal_places)s)\",\n",
    "        \"DurationField\": \"interval\",\n",
    "        \"FileField\": \"varchar(%(max_length)s)\",\n",
    "        \"FilePathField\": \"varchar(%(max_length)s)\",\n",
    "        \"FloatField\": \"double precision\",\n",
    "        \"IntegerField\": \"integer\",\n",
    "        \"BigIntegerField\": \"bigint\",\n",
    "        \"IPAddressField\": \"inet\",\n",
    "        \"GenericIPAddressField\": \"inet\",\n",
    "        \"JSONField\": \"jsonb\",\n",
    "        \"OneToOneField\": \"integer\",\n",
    "        \"PositiveBigIntegerField\": \"bigint\",\n",
    "        \"PositiveIntegerField\": \"integer\",\n",
    "        \"PositiveSmallIntegerField\": \"smallint\",\n",
    "        \"SlugField\": \"varchar(%(max_length)s)\",\n",
    "        \"SmallAutoField\": \"smallint\",\n",
    "        \"SmallIntegerField\": \"smallint\",\n",
    "        \"TextField\": \"text\",\n",
    "        \"TimeField\": \"time\",\n",
    "        \"UUIDField\": \"uuid\",\n",
    "    }\n",
    "    data_type_check_constraints = {\n",
    "        \"PositiveBigIntegerField\": '\"%(column)s\" >= 0',\n",
    "        \"PositiveIntegerField\": '\"%(column)s\" >= 0',\n",
    "        \"PositiveSmallIntegerField\": '\"%(column)s\" >= 0',\n",
    "    }\n",
    "    data_types_suffix = {\n",
    "        \"AutoField\": \"GENERATED BY DEFAULT AS IDENTITY\",\n",
    "        \"BigAutoField\": \"GENERATED BY DEFAULT AS IDENTITY\",\n",
    "        \"SmallAutoField\": \"GENERATED BY DEFAULT AS IDENTITY\",\n",
    "    }\n",
    "    operators = {\n",
    "        \"exact\": \"= %s\",\n",
    "        \"iexact\": \"= UPPER(%s)\",\n",
    "        \"contains\": \"LIKE %s\",\n",
    "        \"icontains\": \"LIKE UPPER(%s)\",\n",
    "        \"regex\": \"~ %s\",\n",
    "        \"iregex\": \"~* %s\",\n",
    "        \"gt\": \"> %s\",\n",
    "        \"gte\": \">= %s\",\n",
    "        \"lt\": \"< %s\",\n",
    "        \"lte\": \"<= %s\",\n",
    "        \"startswith\": \"LIKE %s\",\n",
    "        \"endswith\": \"LIKE %s\",\n",
    "        \"istartswith\": \"LIKE UPPER(%s)\",\n",
    "        \"iendswith\": \"LIKE UPPER(%s)\",\n",
    "    }\n",
    "\n",
    "    # The patterns below are used to generate SQL pattern lookup clauses when\n",
    "    # the right-hand side of the lookup isn't a raw string (it might be an expression\n",
    "    # or the result of a bilateral transformation).\n",
    "    # In those cases, special characters for LIKE operators (e.g. \\, *, _) should be\n",
    "    # escaped on database side.\n",
    "    #\n",
    "    # Note: we use str.format() here for readability as '%' is used as a wildcard for\n",
    "    # the LIKE operator.\n",
    "    pattern_esc = (\n",
    "        r\"REPLACE(REPLACE(REPLACE({}, E'\\\\', E'\\\\\\\\'), E'%%', E'\\\\%%'), E'_', E'\\\\_')\"\n",
    "    )\n",
    "    pattern_ops = {\n",
    "        \"contains\": \"LIKE '%%' || {} || '%%'\",\n",
    "        \"icontains\": \"LIKE '%%' || UPPER({}) || '%%'\",\n",
    "        \"startswith\": \"LIKE {} || '%%'\",\n",
    "        \"istartswith\": \"LIKE UPPER({}) || '%%'\",\n",
    "        \"endswith\": \"LIKE '%%' || {}\",\n",
    "        \"iendswith\": \"LIKE '%%' || UPPER({})\",\n",
    "    }\n",
    "\n",
    "    Database = Database\n",
    "    SchemaEditorClass = DatabaseSchemaEditor\n",
    "    # Classes instantiated in __init__().\n",
    "    client_class = DatabaseClient\n",
    "    creation_class = DatabaseCreation\n",
    "    features_class = DatabaseFeatures\n",
    "    introspection_class = DatabaseIntrospection\n",
    "    ops_class = DatabaseOperations\n",
    "    # PostgreSQL backend-specific attributes.\n",
    "    _named_cursor_idx = 0\n",
    "\n",
    "    def get_database_version(self):\n",
    "        \"\"\"\n",
    "        Return a tuple of the database's version.\n",
    "        E.g. for pg_version 120004, return (12, 4).\n",
    "        \"\"\"\n",
    "        return divmod(self.pg_version, 10000)\n",
    "\n",
    "    def get_connection_params(self):\n",
    "        settings_dict = self.settings_dict\n",
    "        # None may be used to connect to the default 'postgres' db\n",
    "        if settings_dict[\"NAME\"] == \"\" and not settings_dict.get(\"OPTIONS\", {}).get(\n",
    "            \"service\"\n",
    "        ):\n",
    "            raise ImproperlyConfigured(\n",
    "                \"settings.DATABASES is improperly configured. \"\n",
    "                \"Please supply the NAME or OPTIONS['service'] value.\"\n",
    "            )\n",
    "        if len(settings_dict[\"NAME\"] or \"\") > self.ops.max_name_length():\n",
    "            raise ImproperlyConfigured(\n",
    "                \"The database name '%s' (%d characters) is longer than \"\n",
    "                \"PostgreSQL's limit of %d characters. Supply a shorter NAME \"\n",
    "                \"in settings.DATABASES.\"\n",
    "                % (\n",
    "                    settings_dict[\"NAME\"],\n",
    "                    len(settings_dict[\"NAME\"]),\n",
    "                    self.ops.max_name_length(),\n",
    "                )\n",
    "            )\n",
    "        if settings_dict[\"NAME\"]:\n",
    "            conn_params = {\n",
    "                \"dbname\": settings_dict[\"NAME\"],\n",
    "                **settings_dict[\"OPTIONS\"],\n",
    "            }\n",
    "        elif settings_dict[\"NAME\"] is None:\n",
    "            # Connect to the default 'postgres' db.\n",
    "            settings_dict.get(\"OPTIONS\", {}).pop(\"service\", None)\n",
    "            conn_params = {\"dbname\": \"postgres\", **settings_dict[\"OPTIONS\"]}\n",
    "        else:\n",
    "            conn_params = {**settings_dict[\"OPTIONS\"]}\n",
    "        conn_params[\"client_encoding\"] = \"UTF8\"\n",
    "\n",
    "        conn_params.pop(\"assume_role\", None)\n",
    "        conn_params.pop(\"isolation_level\", None)\n",
    "        server_side_binding = conn_params.pop(\"server_side_binding\", None)\n",
    "        conn_params.setdefault(\n",
    "            \"cursor_factory\",\n",
    "            (\n",
    "                ServerBindingCursor\n",
    "                if is_psycopg3 and server_side_binding is True\n",
    "                else Cursor\n",
    "            ),\n",
    "        )\n",
    "        if settings_dict[\"USER\"]:\n",
    "            conn_params[\"user\"] = settings_dict[\"USER\"]\n",
    "        if settings_dict[\"PASSWORD\"]:\n",
    "            conn_params[\"password\"] = settings_dict[\"PASSWORD\"]\n",
    "        if settings_dict[\"HOST\"]:\n",
    "            conn_params[\"host\"] = settings_dict[\"HOST\"]\n",
    "        if settings_dict[\"PORT\"]:\n",
    "            conn_params[\"port\"] = settings_dict[\"PORT\"]\n",
    "        if is_psycopg3:\n",
    "            conn_params[\"context\"] = get_adapters_template(\n",
    "                settings.USE_TZ, self.timezone\n",
    "            )\n",
    "            # Disable prepared statements by default to keep connection poolers\n",
    "            # working. Can be reenabled via OPTIONS in the settings dict.\n",
    "            conn_params[\"prepare_threshold\"] = conn_params.pop(\n",
    "                \"prepare_threshold\", None\n",
    "            )\n",
    "        return conn_params\n",
    "\n",
    "    @async_unsafe\n",
    "    def get_new_connection(self, conn_params):\n",
    "        # self.isolation_level must be set:\n",
    "        # - after connecting to the database in order to obtain the database's\n",
    "        #   default when no value is explicitly specified in options.\n",
    "        # - before calling _set_autocommit() because if autocommit is on, that\n",
    "        #   will set connection.isolation_level to ISOLATION_LEVEL_AUTOCOMMIT.\n",
    "        options = self.settings_dict[\"OPTIONS\"]\n",
    "        set_isolation_level = False\n",
    "        try:\n",
    "            isolation_level_value = options[\"isolation_level\"]\n",
    "        except KeyError:\n",
    "            self.isolation_level = IsolationLevel.READ_COMMITTED\n",
    "        else:\n",
    "            # Set the isolation level to the value from OPTIONS.\n",
    "            try:\n",
    "                self.isolation_level = IsolationLevel(isolation_level_value)\n",
    "                set_isolation_level = True\n",
    "            except ValueError:\n",
    "                raise ImproperlyConfigured(\n",
    "                    f\"Invalid transaction isolation level {isolation_level_value} \"\n",
    "                    f\"specified. Use one of the psycopg.IsolationLevel values.\"\n",
    "                )\n",
    "        connection = self.Database.connect(**conn_params)\n",
    "        if set_isolation_level:\n",
    "            connection.isolation_level = self.isolation_level\n",
    "        if not is_psycopg3:\n",
    "            # Register dummy loads() to avoid a round trip from psycopg2's\n",
    "            # decode to json.dumps() to json.loads(), when using a custom\n",
    "            # decoder in JSONField.\n",
    "            psycopg2.extras.register_default_jsonb(\n",
    "                conn_or_curs=connection, loads=lambda x: x\n",
    "            )\n",
    "        return connection\n",
    "\n",
    "    def ensure_timezone(self):\n",
    "        if self.connection is None:\n",
    "            return False\n",
    "        conn_timezone_name = self.connection.info.parameter_status(\"TimeZone\")\n",
    "        timezone_name = self.timezone_name\n",
    "        if timezone_name and conn_timezone_name != timezone_name:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(self.ops.set_time_zone_sql(), [timezone_name])\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def ensure_role(self):\n",
    "        if self.connection is None:\n",
    "            return False\n",
    "        if new_role := self.settings_dict.get(\"OPTIONS\", {}).get(\"assume_role\"):\n",
    "            with self.connection.cursor() as cursor:\n",
    "                sql = self.ops.compose_sql(\"SET ROLE %s\", [new_role])\n",
    "                cursor.execute(sql)\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def init_connection_state(self):\n",
    "        super().init_connection_state()\n",
    "\n",
    "        # Commit after setting the time zone.\n",
    "        commit_tz = self.ensure_timezone()\n",
    "        # Set the role on the connection. This is useful if the credential used\n",
    "        # to login is not the same as the role that owns database resources. As\n",
    "        # can be the case when using temporary or ephemeral credentials.\n",
    "        commit_role = self.ensure_role()\n",
    "\n",
    "        if (commit_role or commit_tz) and not self.get_autocommit():\n",
    "            self.connection.commit()\n",
    "\n",
    "    @async_unsafe\n",
    "    def create_cursor(self, name=None):\n",
    "        if name:\n",
    "            # In autocommit mode, the cursor will be used outside of a\n",
    "            # transaction, hence use a holdable cursor.\n",
    "            cursor = self.connection.cursor(\n",
    "                name, scrollable=False, withhold=self.connection.autocommit\n",
    "            )\n",
    "        else:\n",
    "            cursor = self.connection.cursor()\n",
    "\n",
    "        if is_psycopg3:\n",
    "            # Register the cursor timezone only if the connection disagrees, to\n",
    "            # avoid copying the adapter map.\n",
    "            tzloader = self.connection.adapters.get_loader(TIMESTAMPTZ_OID, Format.TEXT)\n",
    "            if self.timezone != tzloader.timezone:\n",
    "                register_tzloader(self.timezone, cursor)\n",
    "        else:\n",
    "            cursor.tzinfo_factory = self.tzinfo_factory if settings.USE_TZ else None\n",
    "        return cursor\n",
    "\n",
    "    def tzinfo_factory(self, offset):\n",
    "        return self.timezone\n",
    "\n",
    "    @async_unsafe\n",
    "    def chunked_cursor(self):\n",
    "        self._named_cursor_idx += 1\n",
    "        # Get the current async task\n",
    "        # Note that right now this is behind @async_unsafe, so this is\n",
    "        # unreachable, but in future we'll start loosening this restriction.\n",
    "        # For now, it's here so that every use of \"threading\" is\n",
    "        # also async-compatible.\n",
    "        try:\n",
    "            current_task = asyncio.current_task()\n",
    "        except RuntimeError:\n",
    "            current_task = None\n",
    "        # Current task can be none even if the current_task call didn't error\n",
    "        if current_task:\n",
    "            task_ident = str(id(current_task))\n",
    "        else:\n",
    "            task_ident = \"sync\"\n",
    "        # Use that and the thread ident to get a unique name\n",
    "        return self._cursor(\n",
    "            name=\"_django_curs_%d_%s_%d\"\n",
    "            % (\n",
    "                # Avoid reusing name in other threads / tasks\n",
    "                threading.current_thread().ident,\n",
    "                task_ident,\n",
    "                self._named_cursor_idx,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _set_autocommit(self, autocommit):\n",
    "        with self.wrap_database_errors:\n",
    "            self.connection.autocommit = autocommit\n",
    "\n",
    "    def check_constraints(self, table_names=None):\n",
    "        \"\"\"\n",
    "        Check constraints by setting them to immediate. Return them to deferred\n",
    "        afterward.\n",
    "        \"\"\"\n",
    "        with self.cursor() as cursor:\n",
    "            cursor.execute(\"SET CONSTRAINTS ALL IMMEDIATE\")\n",
    "            cursor.execute(\"SET CONSTRAINTS ALL DEFERRED\")\n",
    "\n",
    "    def is_usable(self):\n",
    "        try:\n",
    "            # Use a psycopg cursor directly, bypassing Django's utilities.\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(\"SELECT 1\")\n",
    "        except Database.Error:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    @contextmanager\n",
    "    def _nodb_cursor(self):\n",
    "        cursor = None\n",
    "        try:\n",
    "            with super()._nodb_cursor() as cursor:\n",
    "                yield cursor\n",
    "        except (Database.DatabaseError, WrappedDatabaseError):\n",
    "            if cursor is not None:\n",
    "                raise\n",
    "            warnings.warn(\n",
    "                \"Normally Django will use a connection to the 'postgres' database \"\n",
    "                \"to avoid running initialization queries against the production \"\n",
    "                \"database when it's not needed (for example, when running tests). \"\n",
    "                \"Django was unable to create a connection to the 'postgres' database \"\n",
    "                \"and will use the first PostgreSQL database instead.\",\n",
    "                RuntimeWarning,\n",
    "            )\n",
    "            for connection in connections.all():\n",
    "                if (\n",
    "                    connection.vendor == \"postgresql\"\n",
    "                    and connection.settings_dict[\"NAME\"] != \"postgres\"\n",
    "                ):\n",
    "                    conn = self.__class__(\n",
    "                        {\n",
    "                            **self.settings_dict,\n",
    "                            \"NAME\": connection.settings_dict[\"NAME\"],\n",
    "                        },\n",
    "                        alias=self.alias,\n",
    "                    )\n",
    "                    try:\n",
    "                        with conn.cursor() as cursor:\n",
    "                            yield cursor\n",
    "                    finally:\n",
    "                        conn.close()\n",
    "                    break\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "    @cached_property\n",
    "    def pg_version(self):\n",
    "        with self.temporary_connection():\n",
    "            return self.connection.info.server_version\n",
    "\n",
    "    def make_debug_cursor(self, cursor):\n",
    "        return CursorDebugWrapper(cursor, self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_psycopg3:\n",
    "\n",
    "    class CursorMixin:\n",
    "        \"\"\"\n",
    "        A subclass of psycopg cursor implementing callproc.\n",
    "        \"\"\"\n",
    "\n",
    "        def callproc(self, name, args=None):\n",
    "            if not isinstance(name, sql.Identifier):\n",
    "                name = sql.Identifier(name)\n",
    "\n",
    "            qparts = [sql.SQL(\"SELECT * FROM \"), name, sql.SQL(\"(\")]\n",
    "            if args:\n",
    "                for item in args:\n",
    "                    qparts.append(sql.Literal(item))\n",
    "                    qparts.append(sql.SQL(\",\"))\n",
    "                del qparts[-1]\n",
    "\n",
    "            qparts.append(sql.SQL(\")\"))\n",
    "            stmt = sql.Composed(qparts)\n",
    "            self.execute(stmt)\n",
    "            return args\n",
    "\n",
    "    class ServerBindingCursor(CursorMixin, Database.Cursor):\n",
    "        pass\n",
    "\n",
    "    class Cursor(CursorMixin, Database.ClientCursor):\n",
    "        pass\n",
    "\n",
    "    class CursorDebugWrapper(BaseCursorDebugWrapper):\n",
    "        def copy(self, statement):\n",
    "            with self.debug_sql(statement):\n",
    "                return self.cursor.copy(statement)\n",
    "\n",
    "else:\n",
    "    Cursor = psycopg2.extensions.cursor\n",
    "\n",
    "    class CursorDebugWrapper(BaseCursorDebugWrapper):\n",
    "        def copy_expert(self, sql, file, *args):\n",
    "            with self.debug_sql(sql):\n",
    "                return self.cursor.copy_expert(sql, file, *args)\n",
    "\n",
    "        def copy_to(self, file, table, *args, **kwargs):\n",
    "            with self.debug_sql(sql=\"COPY %s TO STDOUT\" % table):\n",
    "                return self.cursor.copy_to(file, table, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}