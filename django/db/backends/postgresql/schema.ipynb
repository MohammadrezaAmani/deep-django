{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from django.db.backends.base.schema import BaseDatabaseSchemaEditor\n",
    "from django.db.backends.ddl_references import IndexColumns\n",
    "from django.db.backends.postgresql.psycopg_any import sql\n",
    "from django.db.backends.utils import strip_quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatabaseSchemaEditor(BaseDatabaseSchemaEditor):\n",
    "    # Setting all constraints to IMMEDIATE to allow changing data in the same\n",
    "    # transaction.\n",
    "    sql_update_with_default = (\n",
    "        \"UPDATE %(table)s SET %(column)s = %(default)s WHERE %(column)s IS NULL\"\n",
    "        \"; SET CONSTRAINTS ALL IMMEDIATE\"\n",
    "    )\n",
    "    sql_alter_sequence_type = \"ALTER SEQUENCE IF EXISTS %(sequence)s AS %(type)s\"\n",
    "    sql_delete_sequence = \"DROP SEQUENCE IF EXISTS %(sequence)s CASCADE\"\n",
    "\n",
    "    sql_create_index = (\n",
    "        \"CREATE INDEX %(name)s ON %(table)s%(using)s \"\n",
    "        \"(%(columns)s)%(include)s%(extra)s%(condition)s\"\n",
    "    )\n",
    "    sql_create_index_concurrently = (\n",
    "        \"CREATE INDEX CONCURRENTLY %(name)s ON %(table)s%(using)s \"\n",
    "        \"(%(columns)s)%(include)s%(extra)s%(condition)s\"\n",
    "    )\n",
    "    sql_delete_index = \"DROP INDEX IF EXISTS %(name)s\"\n",
    "    sql_delete_index_concurrently = \"DROP INDEX CONCURRENTLY IF EXISTS %(name)s\"\n",
    "\n",
    "    # Setting the constraint to IMMEDIATE to allow changing data in the same\n",
    "    # transaction.\n",
    "    sql_create_column_inline_fk = (\n",
    "        \"CONSTRAINT %(name)s REFERENCES %(to_table)s(%(to_column)s)%(deferrable)s\"\n",
    "        \"; SET CONSTRAINTS %(namespace)s%(name)s IMMEDIATE\"\n",
    "    )\n",
    "    # Setting the constraint to IMMEDIATE runs any deferred checks to allow\n",
    "    # dropping it in the same transaction.\n",
    "    sql_delete_fk = (\n",
    "        \"SET CONSTRAINTS %(name)s IMMEDIATE; \"\n",
    "        \"ALTER TABLE %(table)s DROP CONSTRAINT %(name)s\"\n",
    "    )\n",
    "    sql_delete_procedure = \"DROP FUNCTION %(procedure)s(%(param_types)s)\"\n",
    "\n",
    "    def execute(self, sql, params=()):\n",
    "        # Merge the query client-side, as PostgreSQL won't do it server-side.\n",
    "        if params is None:\n",
    "            return super().execute(sql, params)\n",
    "        sql = self.connection.ops.compose_sql(str(sql), params)\n",
    "        # Don't let the superclass touch anything.\n",
    "        return super().execute(sql, None)\n",
    "\n",
    "    sql_add_identity = (\n",
    "        \"ALTER TABLE %(table)s ALTER COLUMN %(column)s ADD \"\n",
    "        \"GENERATED BY DEFAULT AS IDENTITY\"\n",
    "    )\n",
    "    sql_drop_indentity = (\n",
    "        \"ALTER TABLE %(table)s ALTER COLUMN %(column)s DROP IDENTITY IF EXISTS\"\n",
    "    )\n",
    "\n",
    "    def quote_value(self, value):\n",
    "        return sql.quote(value, self.connection.connection)\n",
    "\n",
    "    def _field_indexes_sql(self, model, field):\n",
    "        output = super()._field_indexes_sql(model, field)\n",
    "        like_index_statement = self._create_like_index_sql(model, field)\n",
    "        if like_index_statement is not None:\n",
    "            output.append(like_index_statement)\n",
    "        return output\n",
    "\n",
    "    def _field_data_type(self, field):\n",
    "        if field.is_relation:\n",
    "            return field.rel_db_type(self.connection)\n",
    "        return self.connection.data_types.get(\n",
    "            field.get_internal_type(),\n",
    "            field.db_type(self.connection),\n",
    "        )\n",
    "\n",
    "    def _field_base_data_types(self, field):\n",
    "        # Yield base data types for array fields.\n",
    "        if field.base_field.get_internal_type() == \"ArrayField\":\n",
    "            yield from self._field_base_data_types(field.base_field)\n",
    "        else:\n",
    "            yield self._field_data_type(field.base_field)\n",
    "\n",
    "    def _create_like_index_sql(self, model, field):\n",
    "        \"\"\"\n",
    "        Return the statement to create an index with varchar operator pattern\n",
    "        when the column type is 'varchar' or 'text', otherwise return None.\n",
    "        \"\"\"\n",
    "        db_type = field.db_type(connection=self.connection)\n",
    "        if db_type is not None and (field.db_index or field.unique):\n",
    "            # Fields with database column types of `varchar` and `text` need\n",
    "            # a second index that specifies their operator class, which is\n",
    "            # needed when performing correct LIKE queries outside the\n",
    "            # C locale. See #12234.\n",
    "            #\n",
    "            # The same doesn't apply to array fields such as varchar[size]\n",
    "            # and text[size], so skip them.\n",
    "            if \"[\" in db_type:\n",
    "                return None\n",
    "            # Non-deterministic collations on Postgresql don't support indexes\n",
    "            # for operator classes varchar_pattern_ops/text_pattern_ops.\n",
    "            collation_name = getattr(field, \"db_collation\", None)\n",
    "            if not collation_name and field.is_relation:\n",
    "                collation_name = getattr(field.target_field, \"db_collation\", None)\n",
    "            if collation_name and not self._is_collation_deterministic(collation_name):\n",
    "                return None\n",
    "            if db_type.startswith(\"varchar\"):\n",
    "                return self._create_index_sql(\n",
    "                    model,\n",
    "                    fields=[field],\n",
    "                    suffix=\"_like\",\n",
    "                    opclasses=[\"varchar_pattern_ops\"],\n",
    "                )\n",
    "            elif db_type.startswith(\"text\"):\n",
    "                return self._create_index_sql(\n",
    "                    model,\n",
    "                    fields=[field],\n",
    "                    suffix=\"_like\",\n",
    "                    opclasses=[\"text_pattern_ops\"],\n",
    "                )\n",
    "        return None\n",
    "\n",
    "    def _using_sql(self, new_field, old_field):\n",
    "        using_sql = \" USING %(column)s::%(type)s\"\n",
    "        new_internal_type = new_field.get_internal_type()\n",
    "        old_internal_type = old_field.get_internal_type()\n",
    "        if new_internal_type == \"ArrayField\" and new_internal_type == old_internal_type:\n",
    "            # Compare base data types for array fields.\n",
    "            if list(self._field_base_data_types(old_field)) != list(\n",
    "                self._field_base_data_types(new_field)\n",
    "            ):\n",
    "                return using_sql\n",
    "        elif self._field_data_type(old_field) != self._field_data_type(new_field):\n",
    "            return using_sql\n",
    "        return \"\"\n",
    "\n",
    "    def _get_sequence_name(self, table, column):\n",
    "        with self.connection.cursor() as cursor:\n",
    "            for sequence in self.connection.introspection.get_sequences(cursor, table):\n",
    "                if sequence[\"column\"] == column:\n",
    "                    return sequence[\"name\"]\n",
    "        return None\n",
    "\n",
    "    def _alter_column_type_sql(\n",
    "        self, model, old_field, new_field, new_type, old_collation, new_collation\n",
    "    ):\n",
    "        # Drop indexes on varchar/text/citext columns that are changing to a\n",
    "        # different type.\n",
    "        old_db_params = old_field.db_parameters(connection=self.connection)\n",
    "        old_type = old_db_params[\"type\"]\n",
    "        if (old_field.db_index or old_field.unique) and (\n",
    "            (old_type.startswith(\"varchar\") and not new_type.startswith(\"varchar\"))\n",
    "            or (old_type.startswith(\"text\") and not new_type.startswith(\"text\"))\n",
    "            or (old_type.startswith(\"citext\") and not new_type.startswith(\"citext\"))\n",
    "        ):\n",
    "            index_name = self._create_index_name(\n",
    "                model._meta.db_table, [old_field.column], suffix=\"_like\"\n",
    "            )\n",
    "            self.execute(self._delete_index_sql(model, index_name))\n",
    "\n",
    "        self.sql_alter_column_type = (\n",
    "            \"ALTER COLUMN %(column)s TYPE %(type)s%(collation)s\"\n",
    "        )\n",
    "        # Cast when data type changed.\n",
    "        if using_sql := self._using_sql(new_field, old_field):\n",
    "            self.sql_alter_column_type += using_sql\n",
    "        new_internal_type = new_field.get_internal_type()\n",
    "        old_internal_type = old_field.get_internal_type()\n",
    "        # Make ALTER TYPE with IDENTITY make sense.\n",
    "        table = strip_quotes(model._meta.db_table)\n",
    "        auto_field_types = {\n",
    "            \"AutoField\",\n",
    "            \"BigAutoField\",\n",
    "            \"SmallAutoField\",\n",
    "        }\n",
    "        old_is_auto = old_internal_type in auto_field_types\n",
    "        new_is_auto = new_internal_type in auto_field_types\n",
    "        if new_is_auto and not old_is_auto:\n",
    "            column = strip_quotes(new_field.column)\n",
    "            return (\n",
    "                (\n",
    "                    self.sql_alter_column_type\n",
    "                    % {\n",
    "                        \"column\": self.quote_name(column),\n",
    "                        \"type\": new_type,\n",
    "                        \"collation\": \"\",\n",
    "                    },\n",
    "                    [],\n",
    "                ),\n",
    "                [\n",
    "                    (\n",
    "                        self.sql_add_identity\n",
    "                        % {\n",
    "                            \"table\": self.quote_name(table),\n",
    "                            \"column\": self.quote_name(column),\n",
    "                        },\n",
    "                        [],\n",
    "                    ),\n",
    "                ],\n",
    "            )\n",
    "        elif old_is_auto and not new_is_auto:\n",
    "            # Drop IDENTITY if exists (pre-Django 4.1 serial columns don't have\n",
    "            # it).\n",
    "            self.execute(\n",
    "                self.sql_drop_indentity\n",
    "                % {\n",
    "                    \"table\": self.quote_name(table),\n",
    "                    \"column\": self.quote_name(strip_quotes(new_field.column)),\n",
    "                }\n",
    "            )\n",
    "            column = strip_quotes(new_field.column)\n",
    "            fragment, _ = super()._alter_column_type_sql(\n",
    "                model, old_field, new_field, new_type, old_collation, new_collation\n",
    "            )\n",
    "            # Drop the sequence if exists (Django 4.1+ identity columns don't\n",
    "            # have it).\n",
    "            other_actions = []\n",
    "            if sequence_name := self._get_sequence_name(table, column):\n",
    "                other_actions = [\n",
    "                    (\n",
    "                        self.sql_delete_sequence\n",
    "                        % {\n",
    "                            \"sequence\": self.quote_name(sequence_name),\n",
    "                        },\n",
    "                        [],\n",
    "                    )\n",
    "                ]\n",
    "            return fragment, other_actions\n",
    "        elif new_is_auto and old_is_auto and old_internal_type != new_internal_type:\n",
    "            fragment, _ = super()._alter_column_type_sql(\n",
    "                model, old_field, new_field, new_type, old_collation, new_collation\n",
    "            )\n",
    "            column = strip_quotes(new_field.column)\n",
    "            db_types = {\n",
    "                \"AutoField\": \"integer\",\n",
    "                \"BigAutoField\": \"bigint\",\n",
    "                \"SmallAutoField\": \"smallint\",\n",
    "            }\n",
    "            # Alter the sequence type if exists (Django 4.1+ identity columns\n",
    "            # don't have it).\n",
    "            other_actions = []\n",
    "            if sequence_name := self._get_sequence_name(table, column):\n",
    "                other_actions = [\n",
    "                    (\n",
    "                        self.sql_alter_sequence_type\n",
    "                        % {\n",
    "                            \"sequence\": self.quote_name(sequence_name),\n",
    "                            \"type\": db_types[new_internal_type],\n",
    "                        },\n",
    "                        [],\n",
    "                    ),\n",
    "                ]\n",
    "            return fragment, other_actions\n",
    "        else:\n",
    "            return super()._alter_column_type_sql(\n",
    "                model, old_field, new_field, new_type, old_collation, new_collation\n",
    "            )\n",
    "\n",
    "    def _alter_column_collation_sql(\n",
    "        self, model, new_field, new_type, new_collation, old_field\n",
    "    ):\n",
    "        sql = self.sql_alter_column_collate\n",
    "        # Cast when data type changed.\n",
    "        if using_sql := self._using_sql(new_field, old_field):\n",
    "            sql += using_sql\n",
    "        return (\n",
    "            sql\n",
    "            % {\n",
    "                \"column\": self.quote_name(new_field.column),\n",
    "                \"type\": new_type,\n",
    "                \"collation\": (\n",
    "                    \" \" + self._collate_sql(new_collation) if new_collation else \"\"\n",
    "                ),\n",
    "            },\n",
    "            [],\n",
    "        )\n",
    "\n",
    "    def _alter_field(\n",
    "        self,\n",
    "        model,\n",
    "        old_field,\n",
    "        new_field,\n",
    "        old_type,\n",
    "        new_type,\n",
    "        old_db_params,\n",
    "        new_db_params,\n",
    "        strict=False,\n",
    "    ):\n",
    "        super()._alter_field(\n",
    "            model,\n",
    "            old_field,\n",
    "            new_field,\n",
    "            old_type,\n",
    "            new_type,\n",
    "            old_db_params,\n",
    "            new_db_params,\n",
    "            strict,\n",
    "        )\n",
    "        # Added an index? Create any PostgreSQL-specific indexes.\n",
    "        if (not (old_field.db_index or old_field.unique) and new_field.db_index) or (\n",
    "            not old_field.unique and new_field.unique\n",
    "        ):\n",
    "            like_index_statement = self._create_like_index_sql(model, new_field)\n",
    "            if like_index_statement is not None:\n",
    "                self.execute(like_index_statement)\n",
    "\n",
    "        # Removed an index? Drop any PostgreSQL-specific indexes.\n",
    "        if old_field.unique and not (new_field.db_index or new_field.unique):\n",
    "            index_to_remove = self._create_index_name(\n",
    "                model._meta.db_table, [old_field.column], suffix=\"_like\"\n",
    "            )\n",
    "            self.execute(self._delete_index_sql(model, index_to_remove))\n",
    "\n",
    "    def _index_columns(self, table, columns, col_suffixes, opclasses):\n",
    "        if opclasses:\n",
    "            return IndexColumns(\n",
    "                table,\n",
    "                columns,\n",
    "                self.quote_name,\n",
    "                col_suffixes=col_suffixes,\n",
    "                opclasses=opclasses,\n",
    "            )\n",
    "        return super()._index_columns(table, columns, col_suffixes, opclasses)\n",
    "\n",
    "    def add_index(self, model, index, concurrently=False):\n",
    "        self.execute(\n",
    "            index.create_sql(model, self, concurrently=concurrently), params=None\n",
    "        )\n",
    "\n",
    "    def remove_index(self, model, index, concurrently=False):\n",
    "        self.execute(index.remove_sql(model, self, concurrently=concurrently))\n",
    "\n",
    "    def _delete_index_sql(self, model, name, sql=None, concurrently=False):\n",
    "        sql = (\n",
    "            self.sql_delete_index_concurrently\n",
    "            if concurrently\n",
    "            else self.sql_delete_index\n",
    "        )\n",
    "        return super()._delete_index_sql(model, name, sql)\n",
    "\n",
    "    def _create_index_sql(\n",
    "        self,\n",
    "        model,\n",
    "        *,\n",
    "        fields=None,\n",
    "        name=None,\n",
    "        suffix=\"\",\n",
    "        using=\"\",\n",
    "        db_tablespace=None,\n",
    "        col_suffixes=(),\n",
    "        sql=None,\n",
    "        opclasses=(),\n",
    "        condition=None,\n",
    "        concurrently=False,\n",
    "        include=None,\n",
    "        expressions=None,\n",
    "    ):\n",
    "        sql = sql or (\n",
    "            self.sql_create_index\n",
    "            if not concurrently\n",
    "            else self.sql_create_index_concurrently\n",
    "        )\n",
    "        return super()._create_index_sql(\n",
    "            model,\n",
    "            fields=fields,\n",
    "            name=name,\n",
    "            suffix=suffix,\n",
    "            using=using,\n",
    "            db_tablespace=db_tablespace,\n",
    "            col_suffixes=col_suffixes,\n",
    "            sql=sql,\n",
    "            opclasses=opclasses,\n",
    "            condition=condition,\n",
    "            include=include,\n",
    "            expressions=expressions,\n",
    "        )\n",
    "\n",
    "    def _is_collation_deterministic(self, collation_name):\n",
    "        with self.connection.cursor() as cursor:\n",
    "            cursor.execute(\n",
    "                \"\"\"\n",
    "                SELECT collisdeterministic\n",
    "                FROM pg_collation\n",
    "                WHERE collname = %s\n",
    "                \"\"\",\n",
    "                [collation_name],\n",
    "            )\n",
    "            row = cursor.fetchone()\n",
    "            return row[0] if row else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}