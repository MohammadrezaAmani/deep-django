{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "\n",
    "from django import forms\n",
    "from django.core import checks, exceptions\n",
    "from django.db import NotSupportedError, connections, router\n",
    "from django.db.models import expressions, lookups\n",
    "from django.db.models.constants import LOOKUP_SEP\n",
    "from django.db.models.fields import TextField\n",
    "from django.db.models.lookups import (\n",
    "    FieldGetDbPrepValueMixin,\n",
    "    PostgresOperatorLookup,\n",
    "    Transform,\n",
    ")\n",
    "from django.utils.deprecation import RemovedInDjango51Warning\n",
    "from django.utils.translation import gettext_lazy as _\n",
    "\n",
    "from . import Field\n",
    "from .mixins import CheckFieldDefaultMixin\n",
    "\n",
    "__all__ = [\"JSONField\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONField(CheckFieldDefaultMixin, Field):\n",
    "    empty_strings_allowed = False\n",
    "    description = _(\"A JSON object\")\n",
    "    default_error_messages = {\n",
    "        \"invalid\": _(\"Value must be valid JSON.\"),\n",
    "    }\n",
    "    _default_hint = (\"dict\", \"{}\")\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        verbose_name=None,\n",
    "        name=None,\n",
    "        encoder=None,\n",
    "        decoder=None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if encoder and not callable(encoder):\n",
    "            raise ValueError(\"The encoder parameter must be a callable object.\")\n",
    "        if decoder and not callable(decoder):\n",
    "            raise ValueError(\"The decoder parameter must be a callable object.\")\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        super().__init__(verbose_name, name, **kwargs)\n",
    "\n",
    "    def check(self, **kwargs):\n",
    "        errors = super().check(**kwargs)\n",
    "        databases = kwargs.get(\"databases\") or []\n",
    "        errors.extend(self._check_supported(databases))\n",
    "        return errors\n",
    "\n",
    "    def _check_supported(self, databases):\n",
    "        errors = []\n",
    "        for db in databases:\n",
    "            if not router.allow_migrate_model(db, self.model):\n",
    "                continue\n",
    "            connection = connections[db]\n",
    "            if (\n",
    "                self.model._meta.required_db_vendor\n",
    "                and self.model._meta.required_db_vendor != connection.vendor\n",
    "            ):\n",
    "                continue\n",
    "            if not (\n",
    "                \"supports_json_field\" in self.model._meta.required_db_features\n",
    "                or connection.features.supports_json_field\n",
    "            ):\n",
    "                errors.append(\n",
    "                    checks.Error(\n",
    "                        \"%s does not support JSONFields.\" % connection.display_name,\n",
    "                        obj=self.model,\n",
    "                        id=\"fields.E180\",\n",
    "                    )\n",
    "                )\n",
    "        return errors\n",
    "\n",
    "    def deconstruct(self):\n",
    "        name, path, args, kwargs = super().deconstruct()\n",
    "        if self.encoder is not None:\n",
    "            kwargs[\"encoder\"] = self.encoder\n",
    "        if self.decoder is not None:\n",
    "            kwargs[\"decoder\"] = self.decoder\n",
    "        return name, path, args, kwargs\n",
    "\n",
    "    def from_db_value(self, value, expression, connection):\n",
    "        if value is None:\n",
    "            return value\n",
    "        # Some backends (SQLite at least) extract non-string values in their\n",
    "        # SQL datatypes.\n",
    "        if isinstance(expression, KeyTransform) and not isinstance(value, str):\n",
    "            return value\n",
    "        try:\n",
    "            return json.loads(value, cls=self.decoder)\n",
    "        except json.JSONDecodeError:\n",
    "            return value\n",
    "\n",
    "    def get_internal_type(self):\n",
    "        return \"JSONField\"\n",
    "\n",
    "    def get_db_prep_value(self, value, connection, prepared=False):\n",
    "        if not prepared:\n",
    "            value = self.get_prep_value(value)\n",
    "        # RemovedInDjango51Warning: When the deprecation ends, replace with:\n",
    "        # if (\n",
    "        #     isinstance(value, expressions.Value)\n",
    "        #     and isinstance(value.output_field, JSONField)\n",
    "        # ):\n",
    "        #     value = value.value\n",
    "        # elif hasattr(value, \"as_sql\"): ...\n",
    "        if isinstance(value, expressions.Value):\n",
    "            if isinstance(value.value, str) and not isinstance(\n",
    "                value.output_field, JSONField\n",
    "            ):\n",
    "                try:\n",
    "                    value = json.loads(value.value, cls=self.decoder)\n",
    "                except json.JSONDecodeError:\n",
    "                    value = value.value\n",
    "                else:\n",
    "                    warnings.warn(\n",
    "                        \"Providing an encoded JSON string via Value() is deprecated. \"\n",
    "                        f\"Use Value({value!r}, output_field=JSONField()) instead.\",\n",
    "                        category=RemovedInDjango51Warning,\n",
    "                    )\n",
    "            elif isinstance(value.output_field, JSONField):\n",
    "                value = value.value\n",
    "            else:\n",
    "                return value\n",
    "        elif hasattr(value, \"as_sql\"):\n",
    "            return value\n",
    "        return connection.ops.adapt_json_value(value, self.encoder)\n",
    "\n",
    "    def get_db_prep_save(self, value, connection):\n",
    "        if value is None:\n",
    "            return value\n",
    "        return self.get_db_prep_value(value, connection)\n",
    "\n",
    "    def get_transform(self, name):\n",
    "        transform = super().get_transform(name)\n",
    "        if transform:\n",
    "            return transform\n",
    "        return KeyTransformFactory(name)\n",
    "\n",
    "    def validate(self, value, model_instance):\n",
    "        super().validate(value, model_instance)\n",
    "        try:\n",
    "            json.dumps(value, cls=self.encoder)\n",
    "        except TypeError:\n",
    "            raise exceptions.ValidationError(\n",
    "                self.error_messages[\"invalid\"],\n",
    "                code=\"invalid\",\n",
    "                params={\"value\": value},\n",
    "            )\n",
    "\n",
    "    def value_to_string(self, obj):\n",
    "        return self.value_from_object(obj)\n",
    "\n",
    "    def formfield(self, **kwargs):\n",
    "        return super().formfield(\n",
    "            **{\n",
    "                \"form_class\": forms.JSONField,\n",
    "                \"encoder\": self.encoder,\n",
    "                \"decoder\": self.decoder,\n",
    "                **kwargs,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_json_path(key_transforms, include_root=True):\n",
    "    path = [\"$\"] if include_root else []\n",
    "    for key_transform in key_transforms:\n",
    "        try:\n",
    "            num = int(key_transform)\n",
    "        except ValueError:  # non-integer\n",
    "            path.append(\".\")\n",
    "            path.append(json.dumps(key_transform))\n",
    "        else:\n",
    "            path.append(\"[%s]\" % num)\n",
    "    return \"\".join(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataContains(FieldGetDbPrepValueMixin, PostgresOperatorLookup):\n",
    "    lookup_name = \"contains\"\n",
    "    postgres_operator = \"@>\"\n",
    "\n",
    "    def as_sql(self, compiler, connection):\n",
    "        if not connection.features.supports_json_field_contains:\n",
    "            raise NotSupportedError(\n",
    "                \"contains lookup is not supported on this database backend.\"\n",
    "            )\n",
    "        lhs, lhs_params = self.process_lhs(compiler, connection)\n",
    "        rhs, rhs_params = self.process_rhs(compiler, connection)\n",
    "        params = tuple(lhs_params) + tuple(rhs_params)\n",
    "        return \"JSON_CONTAINS(%s, %s)\" % (lhs, rhs), params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContainedBy(FieldGetDbPrepValueMixin, PostgresOperatorLookup):\n",
    "    lookup_name = \"contained_by\"\n",
    "    postgres_operator = \"<@\"\n",
    "\n",
    "    def as_sql(self, compiler, connection):\n",
    "        if not connection.features.supports_json_field_contains:\n",
    "            raise NotSupportedError(\n",
    "                \"contained_by lookup is not supported on this database backend.\"\n",
    "            )\n",
    "        lhs, lhs_params = self.process_lhs(compiler, connection)\n",
    "        rhs, rhs_params = self.process_rhs(compiler, connection)\n",
    "        params = tuple(rhs_params) + tuple(lhs_params)\n",
    "        return \"JSON_CONTAINS(%s, %s)\" % (rhs, lhs), params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HasKeyLookup(PostgresOperatorLookup):\n",
    "    logical_operator = None\n",
    "\n",
    "    def compile_json_path_final_key(self, key_transform):\n",
    "        # Compile the final key without interpreting ints as array elements.\n",
    "        return \".%s\" % json.dumps(key_transform)\n",
    "\n",
    "    def as_sql(self, compiler, connection, template=None):\n",
    "        # Process JSON path from the left-hand side.\n",
    "        if isinstance(self.lhs, KeyTransform):\n",
    "            lhs, lhs_params, lhs_key_transforms = self.lhs.preprocess_lhs(\n",
    "                compiler, connection\n",
    "            )\n",
    "            lhs_json_path = compile_json_path(lhs_key_transforms)\n",
    "        else:\n",
    "            lhs, lhs_params = self.process_lhs(compiler, connection)\n",
    "            lhs_json_path = \"$\"\n",
    "        sql = template % lhs\n",
    "        # Process JSON path from the right-hand side.\n",
    "        rhs = self.rhs\n",
    "        rhs_params = []\n",
    "        if not isinstance(rhs, (list, tuple)):\n",
    "            rhs = [rhs]\n",
    "        for key in rhs:\n",
    "            if isinstance(key, KeyTransform):\n",
    "                *_, rhs_key_transforms = key.preprocess_lhs(compiler, connection)\n",
    "            else:\n",
    "                rhs_key_transforms = [key]\n",
    "            *rhs_key_transforms, final_key = rhs_key_transforms\n",
    "            rhs_json_path = compile_json_path(rhs_key_transforms, include_root=False)\n",
    "            rhs_json_path += self.compile_json_path_final_key(final_key)\n",
    "            rhs_params.append(lhs_json_path + rhs_json_path)\n",
    "        # Add condition for each key.\n",
    "        if self.logical_operator:\n",
    "            sql = \"(%s)\" % self.logical_operator.join([sql] * len(rhs_params))\n",
    "        return sql, tuple(lhs_params) + tuple(rhs_params)\n",
    "\n",
    "    def as_mysql(self, compiler, connection):\n",
    "        return self.as_sql(\n",
    "            compiler, connection, template=\"JSON_CONTAINS_PATH(%s, 'one', %%s)\"\n",
    "        )\n",
    "\n",
    "    def as_oracle(self, compiler, connection):\n",
    "        sql, params = self.as_sql(\n",
    "            compiler, connection, template=\"JSON_EXISTS(%s, '%%s')\"\n",
    "        )\n",
    "        # Add paths directly into SQL because path expressions cannot be passed\n",
    "        # as bind variables on Oracle.\n",
    "        return sql % tuple(params), []\n",
    "\n",
    "    def as_postgresql(self, compiler, connection):\n",
    "        if isinstance(self.rhs, KeyTransform):\n",
    "            *_, rhs_key_transforms = self.rhs.preprocess_lhs(compiler, connection)\n",
    "            for key in rhs_key_transforms[:-1]:\n",
    "                self.lhs = KeyTransform(key, self.lhs)\n",
    "            self.rhs = rhs_key_transforms[-1]\n",
    "        return super().as_postgresql(compiler, connection)\n",
    "\n",
    "    def as_sqlite(self, compiler, connection):\n",
    "        return self.as_sql(\n",
    "            compiler, connection, template=\"JSON_TYPE(%s, %%s) IS NOT NULL\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HasKey(HasKeyLookup):\n",
    "    lookup_name = \"has_key\"\n",
    "    postgres_operator = \"?\"\n",
    "    prepare_rhs = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HasKeys(HasKeyLookup):\n",
    "    lookup_name = \"has_keys\"\n",
    "    postgres_operator = \"?&\"\n",
    "    logical_operator = \" AND \"\n",
    "\n",
    "    def get_prep_lookup(self):\n",
    "        return [str(item) for item in self.rhs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HasAnyKeys(HasKeys):\n",
    "    lookup_name = \"has_any_keys\"\n",
    "    postgres_operator = \"?|\"\n",
    "    logical_operator = \" OR \""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HasKeyOrArrayIndex(HasKey):\n",
    "    def compile_json_path_final_key(self, key_transform):\n",
    "        return compile_json_path([key_transform], include_root=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CaseInsensitiveMixin:\n",
    "    \"\"\"\n",
    "    Mixin to allow case-insensitive comparison of JSON values on MySQL.\n",
    "    MySQL handles strings used in JSON context using the utf8mb4_bin collation.\n",
    "    Because utf8mb4_bin is a binary collation, comparison of JSON values is\n",
    "    case-sensitive.\n",
    "    \"\"\"\n",
    "\n",
    "    def process_lhs(self, compiler, connection):\n",
    "        lhs, lhs_params = super().process_lhs(compiler, connection)\n",
    "        if connection.vendor == \"mysql\":\n",
    "            return \"LOWER(%s)\" % lhs, lhs_params\n",
    "        return lhs, lhs_params\n",
    "\n",
    "    def process_rhs(self, compiler, connection):\n",
    "        rhs, rhs_params = super().process_rhs(compiler, connection)\n",
    "        if connection.vendor == \"mysql\":\n",
    "            return \"LOWER(%s)\" % rhs, rhs_params\n",
    "        return rhs, rhs_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONExact(lookups.Exact):\n",
    "    can_use_none_as_rhs = True\n",
    "\n",
    "    def process_rhs(self, compiler, connection):\n",
    "        rhs, rhs_params = super().process_rhs(compiler, connection)\n",
    "        # Treat None lookup values as null.\n",
    "        if rhs == \"%s\" and rhs_params == [None]:\n",
    "            rhs_params = [\"null\"]\n",
    "        if connection.vendor == \"mysql\":\n",
    "            func = [\"JSON_EXTRACT(%s, '$')\"] * len(rhs_params)\n",
    "            rhs %= tuple(func)\n",
    "        return rhs, rhs_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JSONIContains(CaseInsensitiveMixin, lookups.IContains):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSONField.register_lookup(DataContains)\n",
    "JSONField.register_lookup(ContainedBy)\n",
    "JSONField.register_lookup(HasKey)\n",
    "JSONField.register_lookup(HasKeys)\n",
    "JSONField.register_lookup(HasAnyKeys)\n",
    "JSONField.register_lookup(JSONExact)\n",
    "JSONField.register_lookup(JSONIContains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransform(Transform):\n",
    "    postgres_operator = \"->\"\n",
    "    postgres_nested_operator = \"#>\"\n",
    "\n",
    "    def __init__(self, key_name, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.key_name = str(key_name)\n",
    "\n",
    "    def preprocess_lhs(self, compiler, connection):\n",
    "        key_transforms = [self.key_name]\n",
    "        previous = self.lhs\n",
    "        while isinstance(previous, KeyTransform):\n",
    "            key_transforms.insert(0, previous.key_name)\n",
    "            previous = previous.lhs\n",
    "        lhs, params = compiler.compile(previous)\n",
    "        if connection.vendor == \"oracle\":\n",
    "            # Escape string-formatting.\n",
    "            key_transforms = [key.replace(\"%\", \"%%\") for key in key_transforms]\n",
    "        return lhs, params, key_transforms\n",
    "\n",
    "    def as_mysql(self, compiler, connection):\n",
    "        lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n",
    "        json_path = compile_json_path(key_transforms)\n",
    "        return \"JSON_EXTRACT(%s, %%s)\" % lhs, tuple(params) + (json_path,)\n",
    "\n",
    "    def as_oracle(self, compiler, connection):\n",
    "        lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n",
    "        json_path = compile_json_path(key_transforms)\n",
    "        return (\n",
    "            \"COALESCE(JSON_QUERY(%s, '%s'), JSON_VALUE(%s, '%s'))\"\n",
    "            % ((lhs, json_path) * 2)\n",
    "        ), tuple(params) * 2\n",
    "\n",
    "    def as_postgresql(self, compiler, connection):\n",
    "        lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n",
    "        if len(key_transforms) > 1:\n",
    "            sql = \"(%s %s %%s)\" % (lhs, self.postgres_nested_operator)\n",
    "            return sql, tuple(params) + (key_transforms,)\n",
    "        try:\n",
    "            lookup = int(self.key_name)\n",
    "        except ValueError:\n",
    "            lookup = self.key_name\n",
    "        return \"(%s %s %%s)\" % (lhs, self.postgres_operator), tuple(params) + (lookup,)\n",
    "\n",
    "    def as_sqlite(self, compiler, connection):\n",
    "        lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n",
    "        json_path = compile_json_path(key_transforms)\n",
    "        datatype_values = \",\".join(\n",
    "            [repr(datatype) for datatype in connection.ops.jsonfield_datatype_values]\n",
    "        )\n",
    "        return (\n",
    "            \"(CASE WHEN JSON_TYPE(%s, %%s) IN (%s) \"\n",
    "            \"THEN JSON_TYPE(%s, %%s) ELSE JSON_EXTRACT(%s, %%s) END)\"\n",
    "        ) % (lhs, datatype_values, lhs, lhs), (tuple(params) + (json_path,)) * 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTextTransform(KeyTransform):\n",
    "    postgres_operator = \"->>\"\n",
    "    postgres_nested_operator = \"#>>\"\n",
    "    output_field = TextField()\n",
    "\n",
    "    def as_mysql(self, compiler, connection):\n",
    "        if connection.mysql_is_mariadb:\n",
    "            # MariaDB doesn't support -> and ->> operators (see MDEV-13594).\n",
    "            sql, params = super().as_mysql(compiler, connection)\n",
    "            return \"JSON_UNQUOTE(%s)\" % sql, params\n",
    "        else:\n",
    "            lhs, params, key_transforms = self.preprocess_lhs(compiler, connection)\n",
    "            json_path = compile_json_path(key_transforms)\n",
    "            return \"(%s ->> %%s)\" % lhs, tuple(params) + (json_path,)\n",
    "\n",
    "    @classmethod\n",
    "    def from_lookup(cls, lookup):\n",
    "        transform, *keys = lookup.split(LOOKUP_SEP)\n",
    "        if not keys:\n",
    "            raise ValueError(\"Lookup must contain key or index transforms.\")\n",
    "        for key in keys:\n",
    "            transform = cls(key, transform)\n",
    "        return transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KT = KeyTextTransform.from_lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformTextLookupMixin:\n",
    "    \"\"\"\n",
    "    Mixin for combining with a lookup expecting a text lhs from a JSONField\n",
    "    key lookup. On PostgreSQL, make use of the ->> operator instead of casting\n",
    "    key values to text and performing the lookup on the resulting\n",
    "    representation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, key_transform, *args, **kwargs):\n",
    "        if not isinstance(key_transform, KeyTransform):\n",
    "            raise TypeError(\n",
    "                \"Transform should be an instance of KeyTransform in order to \"\n",
    "                \"use this lookup.\"\n",
    "            )\n",
    "        key_text_transform = KeyTextTransform(\n",
    "            key_transform.key_name,\n",
    "            *key_transform.source_expressions,\n",
    "            **key_transform.extra,\n",
    "        )\n",
    "        super().__init__(key_text_transform, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformIsNull(lookups.IsNull):\n",
    "    # key__isnull=False is the same as has_key='key'\n",
    "    def as_oracle(self, compiler, connection):\n",
    "        sql, params = HasKeyOrArrayIndex(\n",
    "            self.lhs.lhs,\n",
    "            self.lhs.key_name,\n",
    "        ).as_oracle(compiler, connection)\n",
    "        if not self.rhs:\n",
    "            return sql, params\n",
    "        # Column doesn't have a key or IS NULL.\n",
    "        lhs, lhs_params, _ = self.lhs.preprocess_lhs(compiler, connection)\n",
    "        return \"(NOT %s OR %s IS NULL)\" % (sql, lhs), tuple(params) + tuple(lhs_params)\n",
    "\n",
    "    def as_sqlite(self, compiler, connection):\n",
    "        template = \"JSON_TYPE(%s, %%s) IS NULL\"\n",
    "        if not self.rhs:\n",
    "            template = \"JSON_TYPE(%s, %%s) IS NOT NULL\"\n",
    "        return HasKeyOrArrayIndex(self.lhs.lhs, self.lhs.key_name).as_sql(\n",
    "            compiler,\n",
    "            connection,\n",
    "            template=template,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformIn(lookups.In):\n",
    "    def resolve_expression_parameter(self, compiler, connection, sql, param):\n",
    "        sql, params = super().resolve_expression_parameter(\n",
    "            compiler,\n",
    "            connection,\n",
    "            sql,\n",
    "            param,\n",
    "        )\n",
    "        if (\n",
    "            not hasattr(param, \"as_sql\")\n",
    "            and not connection.features.has_native_json_field\n",
    "        ):\n",
    "            if connection.vendor == \"oracle\":\n",
    "                value = json.loads(param)\n",
    "                sql = \"%s(JSON_OBJECT('value' VALUE %%s FORMAT JSON), '$.value')\"\n",
    "                if isinstance(value, (list, dict)):\n",
    "                    sql %= \"JSON_QUERY\"\n",
    "                else:\n",
    "                    sql %= \"JSON_VALUE\"\n",
    "            elif connection.vendor == \"mysql\" or (\n",
    "                connection.vendor == \"sqlite\"\n",
    "                and params[0] not in connection.ops.jsonfield_datatype_values\n",
    "            ):\n",
    "                sql = \"JSON_EXTRACT(%s, '$')\"\n",
    "        if connection.vendor == \"mysql\" and connection.mysql_is_mariadb:\n",
    "            sql = \"JSON_UNQUOTE(%s)\" % sql\n",
    "        return sql, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformExact(JSONExact):\n",
    "    def process_rhs(self, compiler, connection):\n",
    "        if isinstance(self.rhs, KeyTransform):\n",
    "            return super(lookups.Exact, self).process_rhs(compiler, connection)\n",
    "        rhs, rhs_params = super().process_rhs(compiler, connection)\n",
    "        if connection.vendor == \"oracle\":\n",
    "            func = []\n",
    "            sql = \"%s(JSON_OBJECT('value' VALUE %%s FORMAT JSON), '$.value')\"\n",
    "            for value in rhs_params:\n",
    "                value = json.loads(value)\n",
    "                if isinstance(value, (list, dict)):\n",
    "                    func.append(sql % \"JSON_QUERY\")\n",
    "                else:\n",
    "                    func.append(sql % \"JSON_VALUE\")\n",
    "            rhs %= tuple(func)\n",
    "        elif connection.vendor == \"sqlite\":\n",
    "            func = []\n",
    "            for value in rhs_params:\n",
    "                if value in connection.ops.jsonfield_datatype_values:\n",
    "                    func.append(\"%s\")\n",
    "                else:\n",
    "                    func.append(\"JSON_EXTRACT(%s, '$')\")\n",
    "            rhs %= tuple(func)\n",
    "        return rhs, rhs_params\n",
    "\n",
    "    def as_oracle(self, compiler, connection):\n",
    "        rhs, rhs_params = super().process_rhs(compiler, connection)\n",
    "        if rhs_params == [\"null\"]:\n",
    "            # Field has key and it's NULL.\n",
    "            has_key_expr = HasKeyOrArrayIndex(self.lhs.lhs, self.lhs.key_name)\n",
    "            has_key_sql, has_key_params = has_key_expr.as_oracle(compiler, connection)\n",
    "            is_null_expr = self.lhs.get_lookup(\"isnull\")(self.lhs, True)\n",
    "            is_null_sql, is_null_params = is_null_expr.as_sql(compiler, connection)\n",
    "            return (\n",
    "                \"%s AND %s\" % (has_key_sql, is_null_sql),\n",
    "                tuple(has_key_params) + tuple(is_null_params),\n",
    "            )\n",
    "        return super().as_sql(compiler, connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformIExact(\n",
    "    CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IExact\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformIContains(\n",
    "    CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IContains\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformStartsWith(KeyTransformTextLookupMixin, lookups.StartsWith):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformIStartsWith(\n",
    "    CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IStartsWith\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformEndsWith(KeyTransformTextLookupMixin, lookups.EndsWith):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformIEndsWith(\n",
    "    CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IEndsWith\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformRegex(KeyTransformTextLookupMixin, lookups.Regex):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformIRegex(\n",
    "    CaseInsensitiveMixin, KeyTransformTextLookupMixin, lookups.IRegex\n",
    "):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformNumericLookupMixin:\n",
    "    def process_rhs(self, compiler, connection):\n",
    "        rhs, rhs_params = super().process_rhs(compiler, connection)\n",
    "        if not connection.features.has_native_json_field:\n",
    "            rhs_params = [json.loads(value) for value in rhs_params]\n",
    "        return rhs, rhs_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformLt(KeyTransformNumericLookupMixin, lookups.LessThan):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformLte(KeyTransformNumericLookupMixin, lookups.LessThanOrEqual):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformGt(KeyTransformNumericLookupMixin, lookups.GreaterThan):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformGte(KeyTransformNumericLookupMixin, lookups.GreaterThanOrEqual):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KeyTransform.register_lookup(KeyTransformIn)\n",
    "KeyTransform.register_lookup(KeyTransformExact)\n",
    "KeyTransform.register_lookup(KeyTransformIExact)\n",
    "KeyTransform.register_lookup(KeyTransformIsNull)\n",
    "KeyTransform.register_lookup(KeyTransformIContains)\n",
    "KeyTransform.register_lookup(KeyTransformStartsWith)\n",
    "KeyTransform.register_lookup(KeyTransformIStartsWith)\n",
    "KeyTransform.register_lookup(KeyTransformEndsWith)\n",
    "KeyTransform.register_lookup(KeyTransformIEndsWith)\n",
    "KeyTransform.register_lookup(KeyTransformRegex)\n",
    "KeyTransform.register_lookup(KeyTransformIRegex)\n",
    "\n",
    "KeyTransform.register_lookup(KeyTransformLt)\n",
    "KeyTransform.register_lookup(KeyTransformLte)\n",
    "KeyTransform.register_lookup(KeyTransformGt)\n",
    "KeyTransform.register_lookup(KeyTransformGte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyTransformFactory:\n",
    "    def __init__(self, key_name):\n",
    "        self.key_name = key_name\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return KeyTransform(self.key_name, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}