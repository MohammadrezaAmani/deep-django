{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"JsLex: a lexer for JavaScript\"\"\"\n",
    "\n",
    "# Originally from https://bitbucket.org/ned/jslex\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tok:\n",
    "    \"\"\"\n",
    "    A specification for a token class.\n",
    "    \"\"\"\n",
    "\n",
    "    num = 0\n",
    "\n",
    "    def __init__(self, name, regex, next=None):\n",
    "        self.id = Tok.num\n",
    "        Tok.num += 1\n",
    "        self.name = name\n",
    "        self.regex = regex\n",
    "        self.next = next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def literals(choices, prefix=\"\", suffix=\"\"):\n",
    "    \"\"\"\n",
    "    Create a regex from a space-separated list of literal `choices`.\n",
    "\n",
    "    If provided, `prefix` and `suffix` will be attached to each choice\n",
    "    individually.\n",
    "    \"\"\"\n",
    "    return \"|\".join(prefix + re.escape(c) + suffix for c in choices.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lexer:\n",
    "    \"\"\"\n",
    "    A generic multi-state regex-based lexer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, states, first):\n",
    "        self.regexes = {}\n",
    "        self.toks = {}\n",
    "\n",
    "        for state, rules in states.items():\n",
    "            parts = []\n",
    "            for tok in rules:\n",
    "                groupid = \"t%d\" % tok.id\n",
    "                self.toks[groupid] = tok\n",
    "                parts.append(\"(?P<%s>%s)\" % (groupid, tok.regex))\n",
    "            self.regexes[state] = re.compile(\"|\".join(parts), re.MULTILINE | re.VERBOSE)\n",
    "\n",
    "        self.state = first\n",
    "\n",
    "    def lex(self, text):\n",
    "        \"\"\"\n",
    "        Lexically analyze `text`.\n",
    "\n",
    "        Yield pairs (`name`, `tokentext`).\n",
    "        \"\"\"\n",
    "        end = len(text)\n",
    "        state = self.state\n",
    "        regexes = self.regexes\n",
    "        toks = self.toks\n",
    "        start = 0\n",
    "\n",
    "        while start < end:\n",
    "            for match in regexes[state].finditer(text, start):\n",
    "                name = match.lastgroup\n",
    "                tok = toks[name]\n",
    "                toktext = match[name]\n",
    "                start += len(toktext)\n",
    "                yield (tok.name, toktext)\n",
    "\n",
    "                if tok.next:\n",
    "                    state = tok.next\n",
    "                    break\n",
    "\n",
    "        self.state = state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsLexer(Lexer):\n",
    "    \"\"\"\n",
    "    A JavaScript lexer\n",
    "\n",
    "    >>> lexer = JsLexer()\n",
    "    >>> list(lexer.lex(\"a = 1\"))\n",
    "    [('id', 'a'), ('ws', ' '), ('punct', '='), ('ws', ' '), ('dnum', '1')]\n",
    "\n",
    "    This doesn't properly handle non-ASCII characters in the JavaScript source.\n",
    "    \"\"\"\n",
    "\n",
    "    # Because these tokens are matched as alternatives in a regex, longer\n",
    "    # possibilities must appear in the list before shorter ones, for example,\n",
    "    # '>>' before '>'.\n",
    "    #\n",
    "    # Note that we don't have to detect malformed JavaScript, only properly\n",
    "    # lex correct JavaScript, so much of this is simplified.\n",
    "\n",
    "    # Details of JavaScript lexical structure are taken from\n",
    "    # https://www.ecma-international.org/publications-and-standards/standards/ecma-262/\n",
    "\n",
    "    # A useful explanation of automatic semicolon insertion is at\n",
    "    # http://inimino.org/~inimino/blog/javascript_semicolons\n",
    "\n",
    "    both_before = [\n",
    "        Tok(\"comment\", r\"/\\*(.|\\n)*?\\*/\"),\n",
    "        Tok(\"linecomment\", r\"//.*?$\"),\n",
    "        Tok(\"ws\", r\"\\s+\"),\n",
    "        Tok(\n",
    "            \"keyword\",\n",
    "            literals(\n",
    "                \"\"\"\n",
    "                           break case catch class const continue debugger\n",
    "                           default delete do else enum export extends\n",
    "                           finally for function if import in instanceof\n",
    "                           new return super switch this throw try typeof\n",
    "                           var void while with\n",
    "                           \"\"\",\n",
    "                suffix=r\"\\b\",\n",
    "            ),\n",
    "            next=\"reg\",\n",
    "        ),\n",
    "        Tok(\"reserved\", literals(\"null true false\", suffix=r\"\\b\"), next=\"div\"),\n",
    "        Tok(\n",
    "            \"id\",\n",
    "            r\"\"\"\n",
    "                  ([a-zA-Z_$   ]|\\\\u[0-9a-fA-Z]{4})   # first char\n",
    "                  ([a-zA-Z_$0-9]|\\\\u[0-9a-fA-F]{4})*  # rest chars\n",
    "                  \"\"\",\n",
    "            next=\"div\",\n",
    "        ),\n",
    "        Tok(\"hnum\", r\"0[xX][0-9a-fA-F]+\", next=\"div\"),\n",
    "        Tok(\"onum\", r\"0[0-7]+\"),\n",
    "        Tok(\n",
    "            \"dnum\",\n",
    "            r\"\"\"\n",
    "                    (   (0|[1-9][0-9]*)     # DecimalIntegerLiteral\n",
    "                        \\.                  # dot\n",
    "                        [0-9]*              # DecimalDigits-opt\n",
    "                        ([eE][-+]?[0-9]+)?  # ExponentPart-opt\n",
    "                    |\n",
    "                        \\.                  # dot\n",
    "                        [0-9]+              # DecimalDigits\n",
    "                        ([eE][-+]?[0-9]+)?  # ExponentPart-opt\n",
    "                    |\n",
    "                        (0|[1-9][0-9]*)     # DecimalIntegerLiteral\n",
    "                        ([eE][-+]?[0-9]+)?  # ExponentPart-opt\n",
    "                    )\n",
    "                    \"\"\",\n",
    "            next=\"div\",\n",
    "        ),\n",
    "        Tok(\n",
    "            \"punct\",\n",
    "            literals(\n",
    "                \"\"\"\n",
    "                         >>>= === !== >>> <<= >>= <= >= == != << >> &&\n",
    "                         || += -= *= %= &= |= ^=\n",
    "                         \"\"\"\n",
    "            ),\n",
    "            next=\"reg\",\n",
    "        ),\n",
    "        Tok(\"punct\", literals(\"++ -- ) ]\"), next=\"div\"),\n",
    "        Tok(\"punct\", literals(\"{ } ( [ . ; , < > + - * % & | ^ ! ~ ? : =\"), next=\"reg\"),\n",
    "        Tok(\"string\", r'\"([^\"\\\\]|(\\\\(.|\\n)))*?\"', next=\"div\"),\n",
    "        Tok(\"string\", r\"'([^'\\\\]|(\\\\(.|\\n)))*?'\", next=\"div\"),\n",
    "    ]\n",
    "\n",
    "    both_after = [\n",
    "        Tok(\"other\", r\".\"),\n",
    "    ]\n",
    "\n",
    "    states = {\n",
    "        # slash will mean division\n",
    "        \"div\": both_before\n",
    "        + [\n",
    "            Tok(\"punct\", literals(\"/= /\"), next=\"reg\"),\n",
    "        ]\n",
    "        + both_after,\n",
    "        # slash will mean regex\n",
    "        \"reg\": both_before\n",
    "        + [\n",
    "            Tok(\n",
    "                \"regex\",\n",
    "                r\"\"\"\n",
    "                    /                       # opening slash\n",
    "                    # First character is..\n",
    "                    (   [^*\\\\/[]            # anything but * \\ / or [\n",
    "                    |   \\\\.                 # or an escape sequence\n",
    "                    |   \\[                  # or a class, which has\n",
    "                            (   [^\\]\\\\]     #   anything but \\ or ]\n",
    "                            |   \\\\.         #   or an escape sequence\n",
    "                            )*              #   many times\n",
    "                        \\]\n",
    "                    )\n",
    "                    # Following characters are same, except for excluding a star\n",
    "                    (   [^\\\\/[]             # anything but \\ / or [\n",
    "                    |   \\\\.                 # or an escape sequence\n",
    "                    |   \\[                  # or a class, which has\n",
    "                            (   [^\\]\\\\]     #   anything but \\ or ]\n",
    "                            |   \\\\.         #   or an escape sequence\n",
    "                            )*              #   many times\n",
    "                        \\]\n",
    "                    )*                      # many times\n",
    "                    /                       # closing slash\n",
    "                    [a-zA-Z0-9]*            # trailing flags\n",
    "                \"\"\",\n",
    "                next=\"div\",\n",
    "            ),\n",
    "        ]\n",
    "        + both_after,\n",
    "    }\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__(self.states, \"reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_js_for_gettext(js):\n",
    "    \"\"\"\n",
    "    Convert the JavaScript source `js` into something resembling C for\n",
    "    xgettext.\n",
    "\n",
    "    What actually happens is that all the regex literals are replaced with\n",
    "    \"REGEX\".\n",
    "    \"\"\"\n",
    "\n",
    "    def escape_quotes(m):\n",
    "        \"\"\"Used in a regex to properly escape double quotes.\"\"\"\n",
    "        s = m[0]\n",
    "        if s == '\"':\n",
    "            return r\"\\\"\"\n",
    "        else:\n",
    "            return s\n",
    "\n",
    "    lexer = JsLexer()\n",
    "    c = []\n",
    "    for name, tok in lexer.lex(js):\n",
    "        if name == \"regex\":\n",
    "            # C doesn't grok regexes, and they aren't needed for gettext,\n",
    "            # so just output a string instead.\n",
    "            tok = '\"REGEX\"'\n",
    "        elif name == \"string\":\n",
    "            # C doesn't have single-quoted strings, so make all strings\n",
    "            # double-quoted.\n",
    "            if tok.startswith(\"'\"):\n",
    "                guts = re.sub(r\"\\\\.|.\", escape_quotes, tok[1:-1])\n",
    "                tok = '\"' + guts + '\"'\n",
    "        elif name == \"id\":\n",
    "            # C can't deal with Unicode escapes in identifiers.  We don't\n",
    "            # need them for gettext anyway, so replace them with something\n",
    "            # innocuous\n",
    "            tok = tok.replace(\"\\\\\", \"U\")\n",
    "        c.append(tok)\n",
    "    return \"\".join(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}