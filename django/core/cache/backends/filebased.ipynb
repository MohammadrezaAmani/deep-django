{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\"File-based cache backend\"\n",
                "import glob\n",
                "import os\n",
                "import pickle\n",
                "import random\n",
                "import tempfile\n",
                "import time\n",
                "import zlib\n",
                "from hashlib import md5\n",
                "\n",
                "from django.core.cache.backends.base import DEFAULT_TIMEOUT, BaseCache\n",
                "from django.core.files import locks\n",
                "from django.core.files.move import file_move_safe\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class FileBasedCache(BaseCache):\n",
                "    cache_suffix = \".djcache\"\n",
                "    pickle_protocol = pickle.HIGHEST_PROTOCOL\n",
                "\n",
                "    def __init__(self, dir, params):\n",
                "        super().__init__(params)\n",
                "        self._dir = os.path.abspath(dir)\n",
                "        self._createdir()\n",
                "\n",
                "    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n",
                "        if self.has_key(key, version):\n",
                "            return False\n",
                "        self.set(key, value, timeout, version)\n",
                "        return True\n",
                "\n",
                "    def get(self, key, default=None, version=None):\n",
                "        fname = self._key_to_file(key, version)\n",
                "        try:\n",
                "            with open(fname, \"rb\") as f:\n",
                "                if not self._is_expired(f):\n",
                "                    return pickle.loads(zlib.decompress(f.read()))\n",
                "        except FileNotFoundError:\n",
                "            pass\n",
                "        return default\n",
                "\n",
                "    def _write_content(self, file, timeout, value):\n",
                "        expiry = self.get_backend_timeout(timeout)\n",
                "        file.write(pickle.dumps(expiry, self.pickle_protocol))\n",
                "        file.write(zlib.compress(pickle.dumps(value, self.pickle_protocol)))\n",
                "\n",
                "    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n",
                "        self._createdir()  # Cache dir can be deleted at any time.\n",
                "        fname = self._key_to_file(key, version)\n",
                "        self._cull()  # make some room if necessary\n",
                "        fd, tmp_path = tempfile.mkstemp(dir=self._dir)\n",
                "        renamed = False\n",
                "        try:\n",
                "            with open(fd, \"wb\") as f:\n",
                "                self._write_content(f, timeout, value)\n",
                "            file_move_safe(tmp_path, fname, allow_overwrite=True)\n",
                "            renamed = True\n",
                "        finally:\n",
                "            if not renamed:\n",
                "                os.remove(tmp_path)\n",
                "\n",
                "    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):\n",
                "        try:\n",
                "            with open(self._key_to_file(key, version), \"r+b\") as f:\n",
                "                try:\n",
                "                    locks.lock(f, locks.LOCK_EX)\n",
                "                    if self._is_expired(f):\n",
                "                        return False\n",
                "                    else:\n",
                "                        previous_value = pickle.loads(zlib.decompress(f.read()))\n",
                "                        f.seek(0)\n",
                "                        self._write_content(f, timeout, previous_value)\n",
                "                        return True\n",
                "                finally:\n",
                "                    locks.unlock(f)\n",
                "        except FileNotFoundError:\n",
                "            return False\n",
                "\n",
                "    def delete(self, key, version=None):\n",
                "        return self._delete(self._key_to_file(key, version))\n",
                "\n",
                "    def _delete(self, fname):\n",
                "        if not fname.startswith(self._dir) or not os.path.exists(fname):\n",
                "            return False\n",
                "        try:\n",
                "            os.remove(fname)\n",
                "        except FileNotFoundError:\n",
                "            # The file may have been removed by another process.\n",
                "            return False\n",
                "        return True\n",
                "\n",
                "    def has_key(self, key, version=None):\n",
                "        fname = self._key_to_file(key, version)\n",
                "        try:\n",
                "            with open(fname, \"rb\") as f:\n",
                "                return not self._is_expired(f)\n",
                "        except FileNotFoundError:\n",
                "            return False\n",
                "\n",
                "    def _cull(self):\n",
                "        \"\"\"\n",
                "        Remove random cache entries if max_entries is reached at a ratio\n",
                "        of num_entries / cull_frequency. A value of 0 for CULL_FREQUENCY means\n",
                "        that the entire cache will be purged.\n",
                "        \"\"\"\n",
                "        filelist = self._list_cache_files()\n",
                "        num_entries = len(filelist)\n",
                "        if num_entries < self._max_entries:\n",
                "            return  # return early if no culling is required\n",
                "        if self._cull_frequency == 0:\n",
                "            return self.clear()  # Clear the cache when CULL_FREQUENCY = 0\n",
                "        # Delete a random selection of entries\n",
                "        filelist = random.sample(filelist, int(num_entries / self._cull_frequency))\n",
                "        for fname in filelist:\n",
                "            self._delete(fname)\n",
                "\n",
                "    def _createdir(self):\n",
                "        # Set the umask because os.makedirs() doesn't apply the \"mode\" argument\n",
                "        # to intermediate-level directories.\n",
                "        old_umask = os.umask(0o077)\n",
                "        try:\n",
                "            os.makedirs(self._dir, 0o700, exist_ok=True)\n",
                "        finally:\n",
                "            os.umask(old_umask)\n",
                "\n",
                "    def _key_to_file(self, key, version=None):\n",
                "        \"\"\"\n",
                "        Convert a key into a cache file path. Basically this is the\n",
                "        root cache path joined with the md5sum of the key and a suffix.\n",
                "        \"\"\"\n",
                "        key = self.make_and_validate_key(key, version=version)\n",
                "        return os.path.join(\n",
                "            self._dir,\n",
                "            \"\".join(\n",
                "                [\n",
                "                    md5(key.encode(), usedforsecurity=False).hexdigest(),\n",
                "                    self.cache_suffix,\n",
                "                ]\n",
                "            ),\n",
                "        )\n",
                "\n",
                "    def clear(self):\n",
                "        \"\"\"\n",
                "        Remove all the cache files.\n",
                "        \"\"\"\n",
                "        for fname in self._list_cache_files():\n",
                "            self._delete(fname)\n",
                "\n",
                "    def _is_expired(self, f):\n",
                "        \"\"\"\n",
                "        Take an open cache file `f` and delete it if it's expired.\n",
                "        \"\"\"\n",
                "        try:\n",
                "            exp = pickle.load(f)\n",
                "        except EOFError:\n",
                "            exp = 0  # An empty file is considered expired.\n",
                "        if exp is not None and exp < time.time():\n",
                "            f.close()  # On Windows a file has to be closed before deleting\n",
                "            self._delete(f.name)\n",
                "            return True\n",
                "        return False\n",
                "\n",
                "    def _list_cache_files(self):\n",
                "        \"\"\"\n",
                "        Get a list of paths to all the cache files. These are all the files\n",
                "        in the root cache dir that end on the cache_suffix.\n",
                "        \"\"\"\n",
                "        return [\n",
                "            os.path.join(self._dir, fname)\n",
                "            for fname in glob.glob1(self._dir, \"*%s\" % self.cache_suffix)\n",
                "        ]\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": []
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}