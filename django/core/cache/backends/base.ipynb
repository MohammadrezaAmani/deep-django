{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Base Cache class.\"\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from asgiref.sync import sync_to_async\n",
    "\n",
    "from django.core.exceptions import ImproperlyConfigured\n",
    "from django.utils.module_loading import import_string\n",
    "from django.utils.regex_helper import _lazy_re_compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvalidCacheBackendError(ImproperlyConfigured):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheKeyWarning(RuntimeWarning):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvalidCacheKey(ValueError):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stub class to ensure not passing in a `timeout` argument results in\n",
    "# the default timeout\n",
    "DEFAULT_TIMEOUT = object()\n",
    "\n",
    "# Memcached does not accept keys longer than this.\n",
    "MEMCACHE_MAX_KEY_LENGTH = 250"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_key_func(key, key_prefix, version):\n",
    "    \"\"\"\n",
    "    Default function to generate keys.\n",
    "\n",
    "    Construct the key used by all other methods. By default, prepend\n",
    "    the `key_prefix`. KEY_FUNCTION can be used to specify an alternate\n",
    "    function with custom key making behavior.\n",
    "    \"\"\"\n",
    "    return \"%s:%s:%s\" % (key_prefix, version, key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key_func(key_func):\n",
    "    \"\"\"\n",
    "    Function to decide which key function to use.\n",
    "\n",
    "    Default to ``default_key_func``.\n",
    "    \"\"\"\n",
    "    if key_func is not None:\n",
    "        if callable(key_func):\n",
    "            return key_func\n",
    "        else:\n",
    "            return import_string(key_func)\n",
    "    return default_key_func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseCache:\n",
    "    _missing_key = object()\n",
    "\n",
    "    def __init__(self, params):\n",
    "        timeout = params.get(\"timeout\", params.get(\"TIMEOUT\", 300))\n",
    "        if timeout is not None:\n",
    "            try:\n",
    "                timeout = int(timeout)\n",
    "            except (ValueError, TypeError):\n",
    "                timeout = 300\n",
    "        self.default_timeout = timeout\n",
    "\n",
    "        options = params.get(\"OPTIONS\", {})\n",
    "        max_entries = params.get(\"max_entries\", options.get(\"MAX_ENTRIES\", 300))\n",
    "        try:\n",
    "            self._max_entries = int(max_entries)\n",
    "        except (ValueError, TypeError):\n",
    "            self._max_entries = 300\n",
    "\n",
    "        cull_frequency = params.get(\"cull_frequency\", options.get(\"CULL_FREQUENCY\", 3))\n",
    "        try:\n",
    "            self._cull_frequency = int(cull_frequency)\n",
    "        except (ValueError, TypeError):\n",
    "            self._cull_frequency = 3\n",
    "\n",
    "        self.key_prefix = params.get(\"KEY_PREFIX\", \"\")\n",
    "        self.version = params.get(\"VERSION\", 1)\n",
    "        self.key_func = get_key_func(params.get(\"KEY_FUNCTION\"))\n",
    "\n",
    "    def get_backend_timeout(self, timeout=DEFAULT_TIMEOUT):\n",
    "        \"\"\"\n",
    "        Return the timeout value usable by this backend based upon the provided\n",
    "        timeout.\n",
    "        \"\"\"\n",
    "        if timeout == DEFAULT_TIMEOUT:\n",
    "            timeout = self.default_timeout\n",
    "        elif timeout == 0:\n",
    "            # ticket 21147 - avoid time.time() related precision issues\n",
    "            timeout = -1\n",
    "        return None if timeout is None else time.time() + timeout\n",
    "\n",
    "    def make_key(self, key, version=None):\n",
    "        \"\"\"\n",
    "        Construct the key used by all other methods. By default, use the\n",
    "        key_func to generate a key (which, by default, prepends the\n",
    "        `key_prefix' and 'version'). A different key function can be provided\n",
    "        at the time of cache construction; alternatively, you can subclass the\n",
    "        cache backend to provide custom key making behavior.\n",
    "        \"\"\"\n",
    "        if version is None:\n",
    "            version = self.version\n",
    "\n",
    "        return self.key_func(key, self.key_prefix, version)\n",
    "\n",
    "    def validate_key(self, key):\n",
    "        \"\"\"\n",
    "        Warn about keys that would not be portable to the memcached\n",
    "        backend. This encourages (but does not force) writing backend-portable\n",
    "        cache code.\n",
    "        \"\"\"\n",
    "        for warning in memcache_key_warnings(key):\n",
    "            warnings.warn(warning, CacheKeyWarning)\n",
    "\n",
    "    def make_and_validate_key(self, key, version=None):\n",
    "        \"\"\"Helper to make and validate keys.\"\"\"\n",
    "        key = self.make_key(key, version=version)\n",
    "        self.validate_key(key)\n",
    "        return key\n",
    "\n",
    "    def add(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n",
    "        \"\"\"\n",
    "        Set a value in the cache if the key does not already exist. If\n",
    "        timeout is given, use that timeout for the key; otherwise use the\n",
    "        default cache timeout.\n",
    "\n",
    "        Return True if the value was stored, False otherwise.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"subclasses of BaseCache must provide an add() method\"\n",
    "        )\n",
    "\n",
    "    async def aadd(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n",
    "        return await sync_to_async(self.add, thread_sensitive=True)(\n",
    "            key, value, timeout, version\n",
    "        )\n",
    "\n",
    "    def get(self, key, default=None, version=None):\n",
    "        \"\"\"\n",
    "        Fetch a given key from the cache. If the key does not exist, return\n",
    "        default, which itself defaults to None.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"subclasses of BaseCache must provide a get() method\")\n",
    "\n",
    "    async def aget(self, key, default=None, version=None):\n",
    "        return await sync_to_async(self.get, thread_sensitive=True)(\n",
    "            key, default, version\n",
    "        )\n",
    "\n",
    "    def set(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n",
    "        \"\"\"\n",
    "        Set a value in the cache. If timeout is given, use that timeout for the\n",
    "        key; otherwise use the default cache timeout.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"subclasses of BaseCache must provide a set() method\")\n",
    "\n",
    "    async def aset(self, key, value, timeout=DEFAULT_TIMEOUT, version=None):\n",
    "        return await sync_to_async(self.set, thread_sensitive=True)(\n",
    "            key, value, timeout, version\n",
    "        )\n",
    "\n",
    "    def touch(self, key, timeout=DEFAULT_TIMEOUT, version=None):\n",
    "        \"\"\"\n",
    "        Update the key's expiry time using timeout. Return True if successful\n",
    "        or False if the key does not exist.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"subclasses of BaseCache must provide a touch() method\"\n",
    "        )\n",
    "\n",
    "    async def atouch(self, key, timeout=DEFAULT_TIMEOUT, version=None):\n",
    "        return await sync_to_async(self.touch, thread_sensitive=True)(\n",
    "            key, timeout, version\n",
    "        )\n",
    "\n",
    "    def delete(self, key, version=None):\n",
    "        \"\"\"\n",
    "        Delete a key from the cache and return whether it succeeded, failing\n",
    "        silently.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"subclasses of BaseCache must provide a delete() method\"\n",
    "        )\n",
    "\n",
    "    async def adelete(self, key, version=None):\n",
    "        return await sync_to_async(self.delete, thread_sensitive=True)(key, version)\n",
    "\n",
    "    def get_many(self, keys, version=None):\n",
    "        \"\"\"\n",
    "        Fetch a bunch of keys from the cache. For certain backends (memcached,\n",
    "        pgsql) this can be *much* faster when fetching multiple values.\n",
    "\n",
    "        Return a dict mapping each key in keys to its value. If the given\n",
    "        key is missing, it will be missing from the response dict.\n",
    "        \"\"\"\n",
    "        d = {}\n",
    "        for k in keys:\n",
    "            val = self.get(k, self._missing_key, version=version)\n",
    "            if val is not self._missing_key:\n",
    "                d[k] = val\n",
    "        return d\n",
    "\n",
    "    async def aget_many(self, keys, version=None):\n",
    "        \"\"\"See get_many().\"\"\"\n",
    "        d = {}\n",
    "        for k in keys:\n",
    "            val = await self.aget(k, self._missing_key, version=version)\n",
    "            if val is not self._missing_key:\n",
    "                d[k] = val\n",
    "        return d\n",
    "\n",
    "    def get_or_set(self, key, default, timeout=DEFAULT_TIMEOUT, version=None):\n",
    "        \"\"\"\n",
    "        Fetch a given key from the cache. If the key does not exist,\n",
    "        add the key and set it to the default value. The default value can\n",
    "        also be any callable. If timeout is given, use that timeout for the\n",
    "        key; otherwise use the default cache timeout.\n",
    "\n",
    "        Return the value of the key stored or retrieved.\n",
    "        \"\"\"\n",
    "        val = self.get(key, self._missing_key, version=version)\n",
    "        if val is self._missing_key:\n",
    "            if callable(default):\n",
    "                default = default()\n",
    "            self.add(key, default, timeout=timeout, version=version)\n",
    "            # Fetch the value again to avoid a race condition if another caller\n",
    "            # added a value between the first get() and the add() above.\n",
    "            return self.get(key, default, version=version)\n",
    "        return val\n",
    "\n",
    "    async def aget_or_set(self, key, default, timeout=DEFAULT_TIMEOUT, version=None):\n",
    "        \"\"\"See get_or_set().\"\"\"\n",
    "        val = await self.aget(key, self._missing_key, version=version)\n",
    "        if val is self._missing_key:\n",
    "            if callable(default):\n",
    "                default = default()\n",
    "            await self.aadd(key, default, timeout=timeout, version=version)\n",
    "            # Fetch the value again to avoid a race condition if another caller\n",
    "            # added a value between the first aget() and the aadd() above.\n",
    "            return await self.aget(key, default, version=version)\n",
    "        return val\n",
    "\n",
    "    def has_key(self, key, version=None):\n",
    "        \"\"\"\n",
    "        Return True if the key is in the cache and has not expired.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            self.get(key, self._missing_key, version=version) is not self._missing_key\n",
    "        )\n",
    "\n",
    "    async def ahas_key(self, key, version=None):\n",
    "        return (\n",
    "            await self.aget(key, self._missing_key, version=version)\n",
    "            is not self._missing_key\n",
    "        )\n",
    "\n",
    "    def incr(self, key, delta=1, version=None):\n",
    "        \"\"\"\n",
    "        Add delta to value in the cache. If the key does not exist, raise a\n",
    "        ValueError exception.\n",
    "        \"\"\"\n",
    "        value = self.get(key, self._missing_key, version=version)\n",
    "        if value is self._missing_key:\n",
    "            raise ValueError(\"Key '%s' not found\" % key)\n",
    "        new_value = value + delta\n",
    "        self.set(key, new_value, version=version)\n",
    "        return new_value\n",
    "\n",
    "    async def aincr(self, key, delta=1, version=None):\n",
    "        \"\"\"See incr().\"\"\"\n",
    "        value = await self.aget(key, self._missing_key, version=version)\n",
    "        if value is self._missing_key:\n",
    "            raise ValueError(\"Key '%s' not found\" % key)\n",
    "        new_value = value + delta\n",
    "        await self.aset(key, new_value, version=version)\n",
    "        return new_value\n",
    "\n",
    "    def decr(self, key, delta=1, version=None):\n",
    "        \"\"\"\n",
    "        Subtract delta from value in the cache. If the key does not exist, raise\n",
    "        a ValueError exception.\n",
    "        \"\"\"\n",
    "        return self.incr(key, -delta, version=version)\n",
    "\n",
    "    async def adecr(self, key, delta=1, version=None):\n",
    "        return await self.aincr(key, -delta, version=version)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        \"\"\"\n",
    "        Return True if the key is in the cache and has not expired.\n",
    "        \"\"\"\n",
    "        # This is a separate method, rather than just a copy of has_key(),\n",
    "        # so that it always has the same functionality as has_key(), even\n",
    "        # if a subclass overrides it.\n",
    "        return self.has_key(key)\n",
    "\n",
    "    def set_many(self, data, timeout=DEFAULT_TIMEOUT, version=None):\n",
    "        \"\"\"\n",
    "        Set a bunch of values in the cache at once from a dict of key/value\n",
    "        pairs.  For certain backends (memcached), this is much more efficient\n",
    "        than calling set() multiple times.\n",
    "\n",
    "        If timeout is given, use that timeout for the key; otherwise use the\n",
    "        default cache timeout.\n",
    "\n",
    "        On backends that support it, return a list of keys that failed\n",
    "        insertion, or an empty list if all keys were inserted successfully.\n",
    "        \"\"\"\n",
    "        for key, value in data.items():\n",
    "            self.set(key, value, timeout=timeout, version=version)\n",
    "        return []\n",
    "\n",
    "    async def aset_many(self, data, timeout=DEFAULT_TIMEOUT, version=None):\n",
    "        for key, value in data.items():\n",
    "            await self.aset(key, value, timeout=timeout, version=version)\n",
    "        return []\n",
    "\n",
    "    def delete_many(self, keys, version=None):\n",
    "        \"\"\"\n",
    "        Delete a bunch of values in the cache at once. For certain backends\n",
    "        (memcached), this is much more efficient than calling delete() multiple\n",
    "        times.\n",
    "        \"\"\"\n",
    "        for key in keys:\n",
    "            self.delete(key, version=version)\n",
    "\n",
    "    async def adelete_many(self, keys, version=None):\n",
    "        for key in keys:\n",
    "            await self.adelete(key, version=version)\n",
    "\n",
    "    def clear(self):\n",
    "        \"\"\"Remove *all* values from the cache at once.\"\"\"\n",
    "        raise NotImplementedError(\n",
    "            \"subclasses of BaseCache must provide a clear() method\"\n",
    "        )\n",
    "\n",
    "    async def aclear(self):\n",
    "        return await sync_to_async(self.clear, thread_sensitive=True)()\n",
    "\n",
    "    def incr_version(self, key, delta=1, version=None):\n",
    "        \"\"\"\n",
    "        Add delta to the cache version for the supplied key. Return the new\n",
    "        version.\n",
    "        \"\"\"\n",
    "        if version is None:\n",
    "            version = self.version\n",
    "\n",
    "        value = self.get(key, self._missing_key, version=version)\n",
    "        if value is self._missing_key:\n",
    "            raise ValueError(\"Key '%s' not found\" % key)\n",
    "\n",
    "        self.set(key, value, version=version + delta)\n",
    "        self.delete(key, version=version)\n",
    "        return version + delta\n",
    "\n",
    "    async def aincr_version(self, key, delta=1, version=None):\n",
    "        \"\"\"See incr_version().\"\"\"\n",
    "        if version is None:\n",
    "            version = self.version\n",
    "\n",
    "        value = await self.aget(key, self._missing_key, version=version)\n",
    "        if value is self._missing_key:\n",
    "            raise ValueError(\"Key '%s' not found\" % key)\n",
    "\n",
    "        await self.aset(key, value, version=version + delta)\n",
    "        await self.adelete(key, version=version)\n",
    "        return version + delta\n",
    "\n",
    "    def decr_version(self, key, delta=1, version=None):\n",
    "        \"\"\"\n",
    "        Subtract delta from the cache version for the supplied key. Return the\n",
    "        new version.\n",
    "        \"\"\"\n",
    "        return self.incr_version(key, -delta, version)\n",
    "\n",
    "    async def adecr_version(self, key, delta=1, version=None):\n",
    "        return await self.aincr_version(key, -delta, version)\n",
    "\n",
    "    def close(self, **kwargs):\n",
    "        \"\"\"Close the cache connection\"\"\"\n",
    "        pass\n",
    "\n",
    "    async def aclose(self, **kwargs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memcached_error_chars_re = _lazy_re_compile(r\"[\\x00-\\x20\\x7f]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memcache_key_warnings(key):\n",
    "    if len(key) > MEMCACHE_MAX_KEY_LENGTH:\n",
    "        yield (\n",
    "            \"Cache key will cause errors if used with memcached: %r \"\n",
    "            \"(longer than %s)\" % (key, MEMCACHE_MAX_KEY_LENGTH)\n",
    "        )\n",
    "    if memcached_error_chars_re.search(key):\n",
    "        yield (\n",
    "            \"Cache key contains characters that will cause errors if used with \"\n",
    "            f\"memcached: {key!r}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}