{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from django.contrib.postgres import lookups\n",
    "from django.contrib.postgres.forms import SimpleArrayField\n",
    "from django.contrib.postgres.validators import ArrayMaxLengthValidator\n",
    "from django.core import checks, exceptions\n",
    "from django.db.models import Field, Func, IntegerField, Transform, Value\n",
    "from django.db.models.fields.mixins import CheckFieldDefaultMixin\n",
    "from django.db.models.lookups import Exact, In\n",
    "from django.utils.translation import gettext_lazy as _\n",
    "\n",
    "from ..utils import prefix_validation_error\n",
    "from .utils import AttributeSetter\n",
    "\n",
    "__all__ = [\"ArrayField\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayField(CheckFieldDefaultMixin, Field):\n",
    "    empty_strings_allowed = False\n",
    "    default_error_messages = {\n",
    "        \"item_invalid\": _(\"Item %(nth)s in the array did not validate:\"),\n",
    "        \"nested_array_mismatch\": _(\"Nested arrays must have the same length.\"),\n",
    "    }\n",
    "    _default_hint = (\"list\", \"[]\")\n",
    "\n",
    "    def __init__(self, base_field, size=None, **kwargs):\n",
    "        self.base_field = base_field\n",
    "        self.db_collation = getattr(self.base_field, \"db_collation\", None)\n",
    "        self.size = size\n",
    "        if self.size:\n",
    "            self.default_validators = [\n",
    "                *self.default_validators,\n",
    "                ArrayMaxLengthValidator(self.size),\n",
    "            ]\n",
    "        # For performance, only add a from_db_value() method if the base field\n",
    "        # implements it.\n",
    "        if hasattr(self.base_field, \"from_db_value\"):\n",
    "            self.from_db_value = self._from_db_value\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    @property\n",
    "    def model(self):\n",
    "        try:\n",
    "            return self.__dict__[\"model\"]\n",
    "        except KeyError:\n",
    "            raise AttributeError(\n",
    "                \"'%s' object has no attribute 'model'\" % self.__class__.__name__\n",
    "            )\n",
    "\n",
    "    @model.setter\n",
    "    def model(self, model):\n",
    "        self.__dict__[\"model\"] = model\n",
    "        self.base_field.model = model\n",
    "\n",
    "    @classmethod\n",
    "    def _choices_is_value(cls, value):\n",
    "        return isinstance(value, (list, tuple)) or super()._choices_is_value(value)\n",
    "\n",
    "    def check(self, **kwargs):\n",
    "        errors = super().check(**kwargs)\n",
    "        if self.base_field.remote_field:\n",
    "            errors.append(\n",
    "                checks.Error(\n",
    "                    \"Base field for array cannot be a related field.\",\n",
    "                    obj=self,\n",
    "                    id=\"postgres.E002\",\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            # Remove the field name checks as they are not needed here.\n",
    "            base_checks = self.base_field.check()\n",
    "            if base_checks:\n",
    "                error_messages = \"\\n    \".join(\n",
    "                    \"%s (%s)\" % (base_check.msg, base_check.id)\n",
    "                    for base_check in base_checks\n",
    "                    if isinstance(base_check, checks.Error)\n",
    "                )\n",
    "                if error_messages:\n",
    "                    errors.append(\n",
    "                        checks.Error(\n",
    "                            \"Base field for array has errors:\\n    %s\" % error_messages,\n",
    "                            obj=self,\n",
    "                            id=\"postgres.E001\",\n",
    "                        )\n",
    "                    )\n",
    "                warning_messages = \"\\n    \".join(\n",
    "                    \"%s (%s)\" % (base_check.msg, base_check.id)\n",
    "                    for base_check in base_checks\n",
    "                    if isinstance(base_check, checks.Warning)\n",
    "                )\n",
    "                if warning_messages:\n",
    "                    errors.append(\n",
    "                        checks.Warning(\n",
    "                            \"Base field for array has warnings:\\n    %s\"\n",
    "                            % warning_messages,\n",
    "                            obj=self,\n",
    "                            id=\"postgres.W004\",\n",
    "                        )\n",
    "                    )\n",
    "        return errors\n",
    "\n",
    "    def set_attributes_from_name(self, name):\n",
    "        super().set_attributes_from_name(name)\n",
    "        self.base_field.set_attributes_from_name(name)\n",
    "\n",
    "    @property\n",
    "    def description(self):\n",
    "        return \"Array of %s\" % self.base_field.description\n",
    "\n",
    "    def db_type(self, connection):\n",
    "        size = self.size or \"\"\n",
    "        return \"%s[%s]\" % (self.base_field.db_type(connection), size)\n",
    "\n",
    "    def cast_db_type(self, connection):\n",
    "        size = self.size or \"\"\n",
    "        return \"%s[%s]\" % (self.base_field.cast_db_type(connection), size)\n",
    "\n",
    "    def db_parameters(self, connection):\n",
    "        db_params = super().db_parameters(connection)\n",
    "        db_params[\"collation\"] = self.db_collation\n",
    "        return db_params\n",
    "\n",
    "    def get_placeholder(self, value, compiler, connection):\n",
    "        return \"%s::{}\".format(self.db_type(connection))\n",
    "\n",
    "    def get_db_prep_value(self, value, connection, prepared=False):\n",
    "        if isinstance(value, (list, tuple)):\n",
    "            return [\n",
    "                self.base_field.get_db_prep_value(i, connection, prepared=False)\n",
    "                for i in value\n",
    "            ]\n",
    "        return value\n",
    "\n",
    "    def deconstruct(self):\n",
    "        name, path, args, kwargs = super().deconstruct()\n",
    "        if path == \"django.contrib.postgres.fields.array.ArrayField\":\n",
    "            path = \"django.contrib.postgres.fields.ArrayField\"\n",
    "        kwargs.update(\n",
    "            {\n",
    "                \"base_field\": self.base_field.clone(),\n",
    "                \"size\": self.size,\n",
    "            }\n",
    "        )\n",
    "        return name, path, args, kwargs\n",
    "\n",
    "    def to_python(self, value):\n",
    "        if isinstance(value, str):\n",
    "            # Assume we're deserializing\n",
    "            vals = json.loads(value)\n",
    "            value = [self.base_field.to_python(val) for val in vals]\n",
    "        return value\n",
    "\n",
    "    def _from_db_value(self, value, expression, connection):\n",
    "        if value is None:\n",
    "            return value\n",
    "        return [\n",
    "            self.base_field.from_db_value(item, expression, connection)\n",
    "            for item in value\n",
    "        ]\n",
    "\n",
    "    def value_to_string(self, obj):\n",
    "        values = []\n",
    "        vals = self.value_from_object(obj)\n",
    "        base_field = self.base_field\n",
    "\n",
    "        for val in vals:\n",
    "            if val is None:\n",
    "                values.append(None)\n",
    "            else:\n",
    "                obj = AttributeSetter(base_field.attname, val)\n",
    "                values.append(base_field.value_to_string(obj))\n",
    "        return json.dumps(values)\n",
    "\n",
    "    def get_transform(self, name):\n",
    "        transform = super().get_transform(name)\n",
    "        if transform:\n",
    "            return transform\n",
    "        if \"_\" not in name:\n",
    "            try:\n",
    "                index = int(name)\n",
    "            except ValueError:\n",
    "                pass\n",
    "            else:\n",
    "                index += 1  # postgres uses 1-indexing\n",
    "                return IndexTransformFactory(index, self.base_field)\n",
    "        try:\n",
    "            start, end = name.split(\"_\")\n",
    "            start = int(start) + 1\n",
    "            end = int(end)  # don't add one here because postgres slices are weird\n",
    "        except ValueError:\n",
    "            pass\n",
    "        else:\n",
    "            return SliceTransformFactory(start, end)\n",
    "\n",
    "    def validate(self, value, model_instance):\n",
    "        super().validate(value, model_instance)\n",
    "        for index, part in enumerate(value):\n",
    "            try:\n",
    "                self.base_field.validate(part, model_instance)\n",
    "            except exceptions.ValidationError as error:\n",
    "                raise prefix_validation_error(\n",
    "                    error,\n",
    "                    prefix=self.error_messages[\"item_invalid\"],\n",
    "                    code=\"item_invalid\",\n",
    "                    params={\"nth\": index + 1},\n",
    "                )\n",
    "        if isinstance(self.base_field, ArrayField):\n",
    "            if len({len(i) for i in value}) > 1:\n",
    "                raise exceptions.ValidationError(\n",
    "                    self.error_messages[\"nested_array_mismatch\"],\n",
    "                    code=\"nested_array_mismatch\",\n",
    "                )\n",
    "\n",
    "    def run_validators(self, value):\n",
    "        super().run_validators(value)\n",
    "        for index, part in enumerate(value):\n",
    "            try:\n",
    "                self.base_field.run_validators(part)\n",
    "            except exceptions.ValidationError as error:\n",
    "                raise prefix_validation_error(\n",
    "                    error,\n",
    "                    prefix=self.error_messages[\"item_invalid\"],\n",
    "                    code=\"item_invalid\",\n",
    "                    params={\"nth\": index + 1},\n",
    "                )\n",
    "\n",
    "    def formfield(self, **kwargs):\n",
    "        return super().formfield(\n",
    "            **{\n",
    "                \"form_class\": SimpleArrayField,\n",
    "                \"base_field\": self.base_field.formfield(),\n",
    "                \"max_length\": self.size,\n",
    "                **kwargs,\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArrayRHSMixin:\n",
    "    def __init__(self, lhs, rhs):\n",
    "        # Don't wrap arrays that contains only None values, psycopg doesn't\n",
    "        # allow this.\n",
    "        if isinstance(rhs, (tuple, list)) and any(self._rhs_not_none_values(rhs)):\n",
    "            expressions = []\n",
    "            for value in rhs:\n",
    "                if not hasattr(value, \"resolve_expression\"):\n",
    "                    field = lhs.output_field\n",
    "                    value = Value(field.base_field.get_prep_value(value))\n",
    "                expressions.append(value)\n",
    "            rhs = Func(\n",
    "                *expressions,\n",
    "                function=\"ARRAY\",\n",
    "                template=\"%(function)s[%(expressions)s]\",\n",
    "            )\n",
    "        super().__init__(lhs, rhs)\n",
    "\n",
    "    def process_rhs(self, compiler, connection):\n",
    "        rhs, rhs_params = super().process_rhs(compiler, connection)\n",
    "        cast_type = self.lhs.output_field.cast_db_type(connection)\n",
    "        return \"%s::%s\" % (rhs, cast_type), rhs_params\n",
    "\n",
    "    def _rhs_not_none_values(self, rhs):\n",
    "        for x in rhs:\n",
    "            if isinstance(x, (list, tuple)):\n",
    "                yield from self._rhs_not_none_values(x)\n",
    "            elif x is not None:\n",
    "                yield True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ArrayField.register_lookup\n",
    "class ArrayContains(ArrayRHSMixin, lookups.DataContains):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ArrayField.register_lookup\n",
    "class ArrayContainedBy(ArrayRHSMixin, lookups.ContainedBy):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ArrayField.register_lookup\n",
    "class ArrayExact(ArrayRHSMixin, Exact):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ArrayField.register_lookup\n",
    "class ArrayOverlap(ArrayRHSMixin, lookups.Overlap):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ArrayField.register_lookup\n",
    "class ArrayLenTransform(Transform):\n",
    "    lookup_name = \"len\"\n",
    "    output_field = IntegerField()\n",
    "\n",
    "    def as_sql(self, compiler, connection):\n",
    "        lhs, params = compiler.compile(self.lhs)\n",
    "        # Distinguish NULL and empty arrays\n",
    "        return (\n",
    "            \"CASE WHEN %(lhs)s IS NULL THEN NULL ELSE \"\n",
    "            \"coalesce(array_length(%(lhs)s, 1), 0) END\"\n",
    "        ) % {\"lhs\": lhs}, params * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ArrayField.register_lookup\n",
    "class ArrayInLookup(In):\n",
    "    def get_prep_lookup(self):\n",
    "        values = super().get_prep_lookup()\n",
    "        if hasattr(values, \"resolve_expression\"):\n",
    "            return values\n",
    "        # In.process_rhs() expects values to be hashable, so convert lists\n",
    "        # to tuples.\n",
    "        prepared_values = []\n",
    "        for value in values:\n",
    "            if hasattr(value, \"resolve_expression\"):\n",
    "                prepared_values.append(value)\n",
    "            else:\n",
    "                prepared_values.append(tuple(value))\n",
    "        return prepared_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexTransform(Transform):\n",
    "    def __init__(self, index, base_field, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.index = index\n",
    "        self.base_field = base_field\n",
    "\n",
    "    def as_sql(self, compiler, connection):\n",
    "        lhs, params = compiler.compile(self.lhs)\n",
    "        if not lhs.endswith(\"]\"):\n",
    "            lhs = \"(%s)\" % lhs\n",
    "        return \"%s[%%s]\" % lhs, (*params, self.index)\n",
    "\n",
    "    @property\n",
    "    def output_field(self):\n",
    "        return self.base_field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexTransformFactory:\n",
    "    def __init__(self, index, base_field):\n",
    "        self.index = index\n",
    "        self.base_field = base_field\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return IndexTransform(self.index, self.base_field, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceTransform(Transform):\n",
    "    def __init__(self, start, end, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "    def as_sql(self, compiler, connection):\n",
    "        lhs, params = compiler.compile(self.lhs)\n",
    "        if not lhs.endswith(\"]\"):\n",
    "            lhs = \"(%s)\" % lhs\n",
    "        return \"%s[%%s:%%s]\" % lhs, (*params, self.start, self.end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SliceTransformFactory:\n",
    "    def __init__(self, start, end):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return SliceTransform(self.start, self.end, *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}