{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"WorkController can be used to instantiate in-process workers.\n",
    "\n",
    "The command-line interface for the worker is in :mod:`celery.bin.worker`,\n",
    "while the worker program is in :mod:`celery.apps.worker`.\n",
    "\n",
    "The worker program is responsible for adding signal handlers,\n",
    "setting up logging, etc.  This is a bare-bones worker without\n",
    "global side-effects (i.e., except for the global state stored in\n",
    ":mod:`celery.worker.state`).\n",
    "\n",
    "The worker consists of several components, all managed by bootsteps\n",
    "(mod:`celery.bootsteps`).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "from billiard import cpu_count\n",
    "from kombu.utils.compat import detect_environment\n",
    "\n",
    "from celery import bootsteps\n",
    "from celery import concurrency as _concurrency\n",
    "from celery import signals\n",
    "from celery.bootsteps import RUN, TERMINATE\n",
    "from celery.exceptions import ImproperlyConfigured, TaskRevokedError, WorkerTerminate\n",
    "from celery.platforms import EX_FAILURE, create_pidlock\n",
    "from celery.utils.imports import reload_from_cwd\n",
    "from celery.utils.log import mlevel\n",
    "from celery.utils.log import worker_logger as logger\n",
    "from celery.utils.nodenames import default_nodename, worker_direct\n",
    "from celery.utils.text import str_to_list\n",
    "from celery.utils.threads import default_socket_timeout\n",
    "\n",
    "from . import state\n",
    "\n",
    "try:\n",
    "    import resource\n",
    "except ImportError:\n",
    "    resource = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = (\"WorkController\",)\n",
    "\n",
    "#: Default socket timeout at shutdown.\n",
    "SHUTDOWN_SOCKET_TIMEOUT = 5.0\n",
    "\n",
    "SELECT_UNKNOWN_QUEUE = \"\"\"\n",
    "Trying to select queue subset of {0!r}, but queue {1} isn't\n",
    "defined in the `task_queues` setting.\n",
    "\n",
    "If you want to automatically declare unknown queues you can\n",
    "enable the `task_create_missing_queues` setting.\n",
    "\"\"\"\n",
    "\n",
    "DESELECT_UNKNOWN_QUEUE = \"\"\"\n",
    "Trying to deselect queue subset of {0!r}, but queue {1} isn't\n",
    "defined in the `task_queues` setting.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkController:\n",
    "    \"\"\"Unmanaged worker instance.\"\"\"\n",
    "\n",
    "    app = None\n",
    "\n",
    "    pidlock = None\n",
    "    blueprint = None\n",
    "    pool = None\n",
    "    semaphore = None\n",
    "\n",
    "    #: contains the exit code if a :exc:`SystemExit` event is handled.\n",
    "    exitcode = None\n",
    "\n",
    "    class Blueprint(bootsteps.Blueprint):\n",
    "        \"\"\"Worker bootstep blueprint.\"\"\"\n",
    "\n",
    "        name = \"Worker\"\n",
    "        default_steps = {\n",
    "            \"celery.worker.components:Hub\",\n",
    "            \"celery.worker.components:Pool\",\n",
    "            \"celery.worker.components:Beat\",\n",
    "            \"celery.worker.components:Timer\",\n",
    "            \"celery.worker.components:StateDB\",\n",
    "            \"celery.worker.components:Consumer\",\n",
    "            \"celery.worker.autoscale:WorkerComponent\",\n",
    "        }\n",
    "\n",
    "    def __init__(self, app=None, hostname=None, **kwargs):\n",
    "        self.app = app or self.app\n",
    "        self.hostname = default_nodename(hostname)\n",
    "        self.startup_time = datetime.now(timezone.utc)\n",
    "        self.app.loader.init_worker()\n",
    "        self.on_before_init(**kwargs)\n",
    "        self.setup_defaults(**kwargs)\n",
    "        self.on_after_init(**kwargs)\n",
    "\n",
    "        self.setup_instance(**self.prepare_args(**kwargs))\n",
    "\n",
    "    def setup_instance(\n",
    "        self,\n",
    "        queues=None,\n",
    "        ready_callback=None,\n",
    "        pidfile=None,\n",
    "        include=None,\n",
    "        use_eventloop=None,\n",
    "        exclude_queues=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        self.pidfile = pidfile\n",
    "        self.setup_queues(queues, exclude_queues)\n",
    "        self.setup_includes(str_to_list(include))\n",
    "\n",
    "        # Set default concurrency\n",
    "        if not self.concurrency:\n",
    "            try:\n",
    "                self.concurrency = cpu_count()\n",
    "            except NotImplementedError:\n",
    "                self.concurrency = 2\n",
    "\n",
    "        # Options\n",
    "        self.loglevel = mlevel(self.loglevel)\n",
    "        self.ready_callback = ready_callback or self.on_consumer_ready\n",
    "\n",
    "        # this connection won't establish, only used for params\n",
    "        self._conninfo = self.app.connection_for_read()\n",
    "        self.use_eventloop = (\n",
    "            self.should_use_eventloop() if use_eventloop is None else use_eventloop\n",
    "        )\n",
    "        self.options = kwargs\n",
    "\n",
    "        signals.worker_init.send(sender=self)\n",
    "\n",
    "        # Initialize bootsteps\n",
    "        self.pool_cls = _concurrency.get_implementation(self.pool_cls)\n",
    "        self.steps = []\n",
    "        self.on_init_blueprint()\n",
    "        self.blueprint = self.Blueprint(\n",
    "            steps=self.app.steps[\"worker\"],\n",
    "            on_start=self.on_start,\n",
    "            on_close=self.on_close,\n",
    "            on_stopped=self.on_stopped,\n",
    "        )\n",
    "        self.blueprint.apply(self, **kwargs)\n",
    "\n",
    "    def on_init_blueprint(self):\n",
    "        pass\n",
    "\n",
    "    def on_before_init(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def on_after_init(self, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def on_start(self):\n",
    "        if self.pidfile:\n",
    "            self.pidlock = create_pidlock(self.pidfile)\n",
    "\n",
    "    def on_consumer_ready(self, consumer):\n",
    "        pass\n",
    "\n",
    "    def on_close(self):\n",
    "        self.app.loader.shutdown_worker()\n",
    "\n",
    "    def on_stopped(self):\n",
    "        self.timer.stop()\n",
    "        self.consumer.shutdown()\n",
    "\n",
    "        if self.pidlock:\n",
    "            self.pidlock.release()\n",
    "\n",
    "    def setup_queues(self, include, exclude=None):\n",
    "        include = str_to_list(include)\n",
    "        exclude = str_to_list(exclude)\n",
    "        try:\n",
    "            self.app.amqp.queues.select(include)\n",
    "        except KeyError as exc:\n",
    "            raise ImproperlyConfigured(\n",
    "                SELECT_UNKNOWN_QUEUE.strip().format(include, exc)\n",
    "            )\n",
    "        try:\n",
    "            self.app.amqp.queues.deselect(exclude)\n",
    "        except KeyError as exc:\n",
    "            raise ImproperlyConfigured(\n",
    "                DESELECT_UNKNOWN_QUEUE.strip().format(exclude, exc)\n",
    "            )\n",
    "        if self.app.conf.worker_direct:\n",
    "            self.app.amqp.queues.select_add(worker_direct(self.hostname))\n",
    "\n",
    "    def setup_includes(self, includes):\n",
    "        # Update celery_include to have all known task modules, so that we\n",
    "        # ensure all task modules are imported in case an execv happens.\n",
    "        prev = tuple(self.app.conf.include)\n",
    "        if includes:\n",
    "            prev += tuple(includes)\n",
    "            [self.app.loader.import_task_module(m) for m in includes]\n",
    "        self.include = includes\n",
    "        task_modules = {task.__class__.__module__ for task in self.app.tasks.values()}\n",
    "        self.app.conf.include = tuple(set(prev) | task_modules)\n",
    "\n",
    "    def prepare_args(self, **kwargs):\n",
    "        return kwargs\n",
    "\n",
    "    def _send_worker_shutdown(self):\n",
    "        signals.worker_shutdown.send(sender=self)\n",
    "\n",
    "    def start(self):\n",
    "        try:\n",
    "            self.blueprint.start(self)\n",
    "        except WorkerTerminate:\n",
    "            self.terminate()\n",
    "        except Exception as exc:\n",
    "            logger.critical(\"Unrecoverable error: %r\", exc, exc_info=True)\n",
    "            self.stop(exitcode=EX_FAILURE)\n",
    "        except SystemExit as exc:\n",
    "            self.stop(exitcode=exc.code)\n",
    "        except KeyboardInterrupt:\n",
    "            self.stop(exitcode=EX_FAILURE)\n",
    "\n",
    "    def register_with_event_loop(self, hub):\n",
    "        self.blueprint.send_all(\n",
    "            self,\n",
    "            \"register_with_event_loop\",\n",
    "            args=(hub,),\n",
    "            description=\"hub.register\",\n",
    "        )\n",
    "\n",
    "    def _process_task_sem(self, req):\n",
    "        return self._quick_acquire(self._process_task, req)\n",
    "\n",
    "    def _process_task(self, req):\n",
    "        \"\"\"Process task by sending it to the pool of workers.\"\"\"\n",
    "        try:\n",
    "            req.execute_using_pool(self.pool)\n",
    "        except TaskRevokedError:\n",
    "            try:\n",
    "                self._quick_release()  # Issue 877\n",
    "            except AttributeError:\n",
    "                pass\n",
    "\n",
    "    def signal_consumer_close(self):\n",
    "        try:\n",
    "            self.consumer.close()\n",
    "        except AttributeError:\n",
    "            pass\n",
    "\n",
    "    def should_use_eventloop(self):\n",
    "        return (\n",
    "            detect_environment() == \"default\"\n",
    "            and self._conninfo.transport.implements.asynchronous\n",
    "            and not self.app.IS_WINDOWS\n",
    "        )\n",
    "\n",
    "    def stop(self, in_sighandler=False, exitcode=None):\n",
    "        \"\"\"Graceful shutdown of the worker server.\"\"\"\n",
    "        if exitcode is not None:\n",
    "            self.exitcode = exitcode\n",
    "        if self.blueprint.state == RUN:\n",
    "            self.signal_consumer_close()\n",
    "            if not in_sighandler or self.pool.signal_safe:\n",
    "                self._shutdown(warm=True)\n",
    "        self._send_worker_shutdown()\n",
    "\n",
    "    def terminate(self, in_sighandler=False):\n",
    "        \"\"\"Not so graceful shutdown of the worker server.\"\"\"\n",
    "        if self.blueprint.state != TERMINATE:\n",
    "            self.signal_consumer_close()\n",
    "            if not in_sighandler or self.pool.signal_safe:\n",
    "                self._shutdown(warm=False)\n",
    "\n",
    "    def _shutdown(self, warm=True):\n",
    "        # if blueprint does not exist it means that we had an\n",
    "        # error before the bootsteps could be initialized.\n",
    "        if self.blueprint is not None:\n",
    "            with default_socket_timeout(SHUTDOWN_SOCKET_TIMEOUT):  # Issue 975\n",
    "                self.blueprint.stop(self, terminate=not warm)\n",
    "                self.blueprint.join()\n",
    "\n",
    "    def reload(self, modules=None, reload=False, reloader=None):\n",
    "        list(self._reload_modules(modules, force_reload=reload, reloader=reloader))\n",
    "\n",
    "        if self.consumer:\n",
    "            self.consumer.update_strategies()\n",
    "            self.consumer.reset_rate_limits()\n",
    "        try:\n",
    "            self.pool.restart()\n",
    "        except NotImplementedError:\n",
    "            pass\n",
    "\n",
    "    def _reload_modules(self, modules=None, **kwargs):\n",
    "        return (\n",
    "            self._maybe_reload_module(m, **kwargs)\n",
    "            for m in set(\n",
    "                self.app.loader.task_modules if modules is None else (modules or ())\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def _maybe_reload_module(self, module, force_reload=False, reloader=None):\n",
    "        if module not in sys.modules:\n",
    "            logger.debug(\"importing module %s\", module)\n",
    "            return self.app.loader.import_from_cwd(module)\n",
    "        elif force_reload:\n",
    "            logger.debug(\"reloading module %s\", module)\n",
    "            return reload_from_cwd(sys.modules[module], reloader)\n",
    "\n",
    "    def info(self):\n",
    "        uptime = datetime.now(timezone.utc) - self.startup_time\n",
    "        return {\n",
    "            \"total\": self.state.total_count,\n",
    "            \"pid\": os.getpid(),\n",
    "            \"clock\": str(self.app.clock),\n",
    "            \"uptime\": round(uptime.total_seconds()),\n",
    "        }\n",
    "\n",
    "    def rusage(self):\n",
    "        if resource is None:\n",
    "            raise NotImplementedError(\"rusage not supported by this platform\")\n",
    "        s = resource.getrusage(resource.RUSAGE_SELF)\n",
    "        return {\n",
    "            \"utime\": s.ru_utime,\n",
    "            \"stime\": s.ru_stime,\n",
    "            \"maxrss\": s.ru_maxrss,\n",
    "            \"ixrss\": s.ru_ixrss,\n",
    "            \"idrss\": s.ru_idrss,\n",
    "            \"isrss\": s.ru_isrss,\n",
    "            \"minflt\": s.ru_minflt,\n",
    "            \"majflt\": s.ru_majflt,\n",
    "            \"nswap\": s.ru_nswap,\n",
    "            \"inblock\": s.ru_inblock,\n",
    "            \"oublock\": s.ru_oublock,\n",
    "            \"msgsnd\": s.ru_msgsnd,\n",
    "            \"msgrcv\": s.ru_msgrcv,\n",
    "            \"nsignals\": s.ru_nsignals,\n",
    "            \"nvcsw\": s.ru_nvcsw,\n",
    "            \"nivcsw\": s.ru_nivcsw,\n",
    "        }\n",
    "\n",
    "    def stats(self):\n",
    "        info = self.info()\n",
    "        info.update(self.blueprint.info(self))\n",
    "        info.update(self.consumer.blueprint.info(self.consumer))\n",
    "        try:\n",
    "            info[\"rusage\"] = self.rusage()\n",
    "        except NotImplementedError:\n",
    "            info[\"rusage\"] = \"N/A\"\n",
    "        return info\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"``repr(worker)``.\"\"\"\n",
    "        return \"<Worker: {self.hostname} ({state})>\".format(\n",
    "            self=self,\n",
    "            state=self.blueprint.human_state() if self.blueprint else \"INIT\",\n",
    "        )\n",
    "\n",
    "    def __str__(self):\n",
    "        \"\"\"``str(worker) == worker.hostname``.\"\"\"\n",
    "        return self.hostname\n",
    "\n",
    "    @property\n",
    "    def state(self):\n",
    "        return state\n",
    "\n",
    "    def setup_defaults(\n",
    "        self,\n",
    "        concurrency=None,\n",
    "        loglevel=\"WARN\",\n",
    "        logfile=None,\n",
    "        task_events=None,\n",
    "        pool=None,\n",
    "        consumer_cls=None,\n",
    "        timer_cls=None,\n",
    "        timer_precision=None,\n",
    "        autoscaler_cls=None,\n",
    "        pool_putlocks=None,\n",
    "        pool_restarts=None,\n",
    "        optimization=None,\n",
    "        O=None,  # O maps to -O=fair\n",
    "        statedb=None,\n",
    "        time_limit=None,\n",
    "        soft_time_limit=None,\n",
    "        scheduler=None,\n",
    "        pool_cls=None,  # XXX use pool\n",
    "        state_db=None,  # XXX use statedb\n",
    "        task_time_limit=None,  # XXX use time_limit\n",
    "        task_soft_time_limit=None,  # XXX use soft_time_limit\n",
    "        scheduler_cls=None,  # XXX use scheduler\n",
    "        schedule_filename=None,\n",
    "        max_tasks_per_child=None,\n",
    "        prefetch_multiplier=None,\n",
    "        disable_rate_limits=None,\n",
    "        worker_lost_wait=None,\n",
    "        max_memory_per_child=None,\n",
    "        **_kw\n",
    "    ):\n",
    "        either = self.app.either\n",
    "        self.loglevel = loglevel\n",
    "        self.logfile = logfile\n",
    "\n",
    "        self.concurrency = either(\"worker_concurrency\", concurrency)\n",
    "        self.task_events = either(\"worker_send_task_events\", task_events)\n",
    "        self.pool_cls = either(\"worker_pool\", pool, pool_cls)\n",
    "        self.consumer_cls = either(\"worker_consumer\", consumer_cls)\n",
    "        self.timer_cls = either(\"worker_timer\", timer_cls)\n",
    "        self.timer_precision = either(\n",
    "            \"worker_timer_precision\",\n",
    "            timer_precision,\n",
    "        )\n",
    "        self.optimization = optimization or O\n",
    "        self.autoscaler_cls = either(\"worker_autoscaler\", autoscaler_cls)\n",
    "        self.pool_putlocks = either(\"worker_pool_putlocks\", pool_putlocks)\n",
    "        self.pool_restarts = either(\"worker_pool_restarts\", pool_restarts)\n",
    "        self.statedb = either(\"worker_state_db\", statedb, state_db)\n",
    "        self.schedule_filename = either(\n",
    "            \"beat_schedule_filename\",\n",
    "            schedule_filename,\n",
    "        )\n",
    "        self.scheduler = either(\"beat_scheduler\", scheduler, scheduler_cls)\n",
    "        self.time_limit = either(\"task_time_limit\", time_limit, task_time_limit)\n",
    "        self.soft_time_limit = either(\n",
    "            \"task_soft_time_limit\",\n",
    "            soft_time_limit,\n",
    "            task_soft_time_limit,\n",
    "        )\n",
    "        self.max_tasks_per_child = either(\n",
    "            \"worker_max_tasks_per_child\",\n",
    "            max_tasks_per_child,\n",
    "        )\n",
    "        self.max_memory_per_child = either(\n",
    "            \"worker_max_memory_per_child\",\n",
    "            max_memory_per_child,\n",
    "        )\n",
    "        self.prefetch_multiplier = int(\n",
    "            either(\n",
    "                \"worker_prefetch_multiplier\",\n",
    "                prefetch_multiplier,\n",
    "            )\n",
    "        )\n",
    "        self.disable_rate_limits = either(\n",
    "            \"worker_disable_rate_limits\",\n",
    "            disable_rate_limits,\n",
    "        )\n",
    "        self.worker_lost_wait = either(\"worker_lost_wait\", worker_lost_wait)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}