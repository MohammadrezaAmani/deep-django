{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pool Autoscaling.\n",
    "\n",
    "This module implements the internal thread responsible\n",
    "for growing and shrinking the pool according to the\n",
    "current autoscale settings.\n",
    "\n",
    "The autoscale thread is only enabled if\n",
    "the :option:`celery worker --autoscale` option is used.\n",
    "\"\"\"\n",
    "import os\n",
    "import threading\n",
    "from time import monotonic, sleep\n",
    "\n",
    "from kombu.asynchronous.semaphore import DummyLock\n",
    "\n",
    "from celery import bootsteps\n",
    "from celery.utils.log import get_logger\n",
    "from celery.utils.threads import bgThread\n",
    "\n",
    "from . import state\n",
    "from .components import Pool\n",
    "\n",
    "__all__ = (\"Autoscaler\", \"WorkerComponent\")\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "debug, info, error = logger.debug, logger.info, logger.error\n",
    "\n",
    "AUTOSCALE_KEEPALIVE = float(os.environ.get(\"AUTOSCALE_KEEPALIVE\", 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorkerComponent(bootsteps.StartStopStep):\n",
    "    \"\"\"Bootstep that starts the autoscaler thread/timer in the worker.\"\"\"\n",
    "\n",
    "    label = \"Autoscaler\"\n",
    "    conditional = True\n",
    "    requires = (Pool,)\n",
    "\n",
    "    def __init__(self, w, **kwargs):\n",
    "        self.enabled = w.autoscale\n",
    "        w.autoscaler = None\n",
    "\n",
    "    def create(self, w):\n",
    "        scaler = w.autoscaler = self.instantiate(\n",
    "            w.autoscaler_cls,\n",
    "            w.pool,\n",
    "            w.max_concurrency,\n",
    "            w.min_concurrency,\n",
    "            worker=w,\n",
    "            mutex=DummyLock() if w.use_eventloop else None,\n",
    "        )\n",
    "        return scaler if not w.use_eventloop else None\n",
    "\n",
    "    def register_with_event_loop(self, w, hub):\n",
    "        w.consumer.on_task_message.add(w.autoscaler.maybe_scale)\n",
    "        hub.call_repeatedly(\n",
    "            w.autoscaler.keepalive,\n",
    "            w.autoscaler.maybe_scale,\n",
    "        )\n",
    "\n",
    "    def info(self, w):\n",
    "        \"\"\"Return `Autoscaler` info.\"\"\"\n",
    "        return {\"autoscaler\": w.autoscaler.info()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoscaler(bgThread):\n",
    "    \"\"\"Background thread to autoscale pool workers.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        pool,\n",
    "        max_concurrency,\n",
    "        min_concurrency=0,\n",
    "        worker=None,\n",
    "        keepalive=AUTOSCALE_KEEPALIVE,\n",
    "        mutex=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.pool = pool\n",
    "        self.mutex = mutex or threading.Lock()\n",
    "        self.max_concurrency = max_concurrency\n",
    "        self.min_concurrency = min_concurrency\n",
    "        self.keepalive = keepalive\n",
    "        self._last_scale_up = None\n",
    "        self.worker = worker\n",
    "\n",
    "        assert self.keepalive, \"cannot scale down too fast.\"\n",
    "\n",
    "    def body(self):\n",
    "        with self.mutex:\n",
    "            self.maybe_scale()\n",
    "        sleep(1.0)\n",
    "\n",
    "    def _maybe_scale(self, req=None):\n",
    "        procs = self.processes\n",
    "        cur = min(self.qty, self.max_concurrency)\n",
    "        if cur > procs:\n",
    "            self.scale_up(cur - procs)\n",
    "            return True\n",
    "        cur = max(self.qty, self.min_concurrency)\n",
    "        if cur < procs:\n",
    "            self.scale_down(procs - cur)\n",
    "            return True\n",
    "\n",
    "    def maybe_scale(self, req=None):\n",
    "        if self._maybe_scale(req):\n",
    "            self.pool.maintain_pool()\n",
    "\n",
    "    def update(self, max=None, min=None):\n",
    "        with self.mutex:\n",
    "            if max is not None:\n",
    "                if max < self.processes:\n",
    "                    self._shrink(self.processes - max)\n",
    "                self._update_consumer_prefetch_count(max)\n",
    "                self.max_concurrency = max\n",
    "            if min is not None:\n",
    "                if min > self.processes:\n",
    "                    self._grow(min - self.processes)\n",
    "                self.min_concurrency = min\n",
    "            return self.max_concurrency, self.min_concurrency\n",
    "\n",
    "    def scale_up(self, n):\n",
    "        self._last_scale_up = monotonic()\n",
    "        return self._grow(n)\n",
    "\n",
    "    def scale_down(self, n):\n",
    "        if self._last_scale_up and (monotonic() - self._last_scale_up > self.keepalive):\n",
    "            return self._shrink(n)\n",
    "\n",
    "    def _grow(self, n):\n",
    "        info(\"Scaling up %s processes.\", n)\n",
    "        self.pool.grow(n)\n",
    "\n",
    "    def _shrink(self, n):\n",
    "        info(\"Scaling down %s processes.\", n)\n",
    "        try:\n",
    "            self.pool.shrink(n)\n",
    "        except ValueError:\n",
    "            debug(\"Autoscaler won't scale down: all processes busy.\")\n",
    "        except Exception as exc:\n",
    "            error(\"Autoscaler: scale_down: %r\", exc, exc_info=True)\n",
    "\n",
    "    def _update_consumer_prefetch_count(self, new_max):\n",
    "        diff = new_max - self.max_concurrency\n",
    "        if diff:\n",
    "            self.worker.consumer._update_prefetch_count(diff)\n",
    "\n",
    "    def info(self):\n",
    "        return {\n",
    "            \"max\": self.max_concurrency,\n",
    "            \"min\": self.min_concurrency,\n",
    "            \"current\": self.processes,\n",
    "            \"qty\": self.qty,\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def qty(self):\n",
    "        return len(state.reserved_requests)\n",
    "\n",
    "    @property\n",
    "    def processes(self):\n",
    "        return self.pool.num_processes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}