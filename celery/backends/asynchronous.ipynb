{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Async I/O backend support utilities.\"\"\"\n",
    "import socket\n",
    "import threading\n",
    "import time\n",
    "from collections import deque\n",
    "from queue import Empty\n",
    "from time import sleep\n",
    "from weakref import WeakKeyDictionary\n",
    "\n",
    "from kombu.utils.compat import detect_environment\n",
    "\n",
    "from celery import states\n",
    "from celery.exceptions import TimeoutError\n",
    "from celery.utils.threads import THREAD_TIMEOUT_MAX\n",
    "\n",
    "__all__ = (\n",
    "    \"AsyncBackendMixin\",\n",
    "    \"BaseResultConsumer\",\n",
    "    \"Drainer\",\n",
    "    \"register_drainer\",\n",
    ")\n",
    "\n",
    "drainers = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_drainer(name):\n",
    "    \"\"\"Decorator used to register a new result drainer type.\"\"\"\n",
    "\n",
    "    def _inner(cls):\n",
    "        drainers[name] = cls\n",
    "        return cls\n",
    "\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_drainer(\"default\")\n",
    "class Drainer:\n",
    "    \"\"\"Result draining service.\"\"\"\n",
    "\n",
    "    def __init__(self, result_consumer):\n",
    "        self.result_consumer = result_consumer\n",
    "\n",
    "    def start(self):\n",
    "        pass\n",
    "\n",
    "    def stop(self):\n",
    "        pass\n",
    "\n",
    "    def drain_events_until(\n",
    "        self, p, timeout=None, interval=1, on_interval=None, wait=None\n",
    "    ):\n",
    "        wait = wait or self.result_consumer.drain_events\n",
    "        time_start = time.monotonic()\n",
    "\n",
    "        while 1:\n",
    "            # Total time spent may exceed a single call to wait()\n",
    "            if timeout and time.monotonic() - time_start >= timeout:\n",
    "                raise socket.timeout()\n",
    "            try:\n",
    "                yield self.wait_for(p, wait, timeout=interval)\n",
    "            except socket.timeout:\n",
    "                pass\n",
    "            if on_interval:\n",
    "                on_interval()\n",
    "            if p.ready:  # got event on the wanted channel.\n",
    "                break\n",
    "\n",
    "    def wait_for(self, p, wait, timeout=None):\n",
    "        wait(timeout=timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class greenletDrainer(Drainer):\n",
    "    spawn = None\n",
    "    _g = None\n",
    "    _drain_complete_event = (\n",
    "        None  # event, sended (and recreated) after every drain_events iteration\n",
    "    )\n",
    "\n",
    "    def _create_drain_complete_event(self):\n",
    "        \"\"\"create new self._drain_complete_event object\"\"\"\n",
    "        pass\n",
    "\n",
    "    def _send_drain_complete_event(self):\n",
    "        \"\"\"raise self._drain_complete_event for wakeup .wait_for\"\"\"\n",
    "        pass\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self._started = threading.Event()\n",
    "        self._stopped = threading.Event()\n",
    "        self._shutdown = threading.Event()\n",
    "        self._create_drain_complete_event()\n",
    "\n",
    "    def run(self):\n",
    "        self._started.set()\n",
    "        while not self._stopped.is_set():\n",
    "            try:\n",
    "                self.result_consumer.drain_events(timeout=1)\n",
    "                self._send_drain_complete_event()\n",
    "                self._create_drain_complete_event()\n",
    "            except socket.timeout:\n",
    "                pass\n",
    "        self._shutdown.set()\n",
    "\n",
    "    def start(self):\n",
    "        if not self._started.is_set():\n",
    "            self._g = self.spawn(self.run)\n",
    "            self._started.wait()\n",
    "\n",
    "    def stop(self):\n",
    "        self._stopped.set()\n",
    "        self._send_drain_complete_event()\n",
    "        self._shutdown.wait(THREAD_TIMEOUT_MAX)\n",
    "\n",
    "    def wait_for(self, p, wait, timeout=None):\n",
    "        self.start()\n",
    "        if not p.ready:\n",
    "            self._drain_complete_event.wait(timeout=timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_drainer(\"eventlet\")\n",
    "class eventletDrainer(greenletDrainer):\n",
    "    def spawn(self, func):\n",
    "        from eventlet import sleep, spawn\n",
    "\n",
    "        g = spawn(func)\n",
    "        sleep(0)\n",
    "        return g\n",
    "\n",
    "    def _create_drain_complete_event(self):\n",
    "        from eventlet.event import Event\n",
    "\n",
    "        self._drain_complete_event = Event()\n",
    "\n",
    "    def _send_drain_complete_event(self):\n",
    "        self._drain_complete_event.send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_drainer(\"gevent\")\n",
    "class geventDrainer(greenletDrainer):\n",
    "    def spawn(self, func):\n",
    "        import gevent\n",
    "\n",
    "        g = gevent.spawn(func)\n",
    "        gevent.sleep(0)\n",
    "        return g\n",
    "\n",
    "    def _create_drain_complete_event(self):\n",
    "        from gevent.event import Event\n",
    "\n",
    "        self._drain_complete_event = Event()\n",
    "\n",
    "    def _send_drain_complete_event(self):\n",
    "        self._drain_complete_event.set()\n",
    "        self._create_drain_complete_event()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AsyncBackendMixin:\n",
    "    \"\"\"Mixin for backends that enables the async API.\"\"\"\n",
    "\n",
    "    def _collect_into(self, result, bucket):\n",
    "        self.result_consumer.buckets[result] = bucket\n",
    "\n",
    "    def iter_native(self, result, no_ack=True, **kwargs):\n",
    "        self._ensure_not_eager()\n",
    "\n",
    "        results = result.results\n",
    "        if not results:\n",
    "            raise StopIteration()\n",
    "\n",
    "        # we tell the result consumer to put consumed results\n",
    "        # into these buckets.\n",
    "        bucket = deque()\n",
    "        for node in results:\n",
    "            if not hasattr(node, \"_cache\"):\n",
    "                bucket.append(node)\n",
    "            elif node._cache:\n",
    "                bucket.append(node)\n",
    "            else:\n",
    "                self._collect_into(node, bucket)\n",
    "\n",
    "        for _ in self._wait_for_pending(result, no_ack=no_ack, **kwargs):\n",
    "            while bucket:\n",
    "                node = bucket.popleft()\n",
    "                if not hasattr(node, \"_cache\"):\n",
    "                    yield node.id, node.children\n",
    "                else:\n",
    "                    yield node.id, node._cache\n",
    "        while bucket:\n",
    "            node = bucket.popleft()\n",
    "            yield node.id, node._cache\n",
    "\n",
    "    def add_pending_result(self, result, weak=False, start_drainer=True):\n",
    "        if start_drainer:\n",
    "            self.result_consumer.drainer.start()\n",
    "        try:\n",
    "            self._maybe_resolve_from_buffer(result)\n",
    "        except Empty:\n",
    "            self._add_pending_result(result.id, result, weak=weak)\n",
    "        return result\n",
    "\n",
    "    def _maybe_resolve_from_buffer(self, result):\n",
    "        result._maybe_set_cache(self._pending_messages.take(result.id))\n",
    "\n",
    "    def _add_pending_result(self, task_id, result, weak=False):\n",
    "        concrete, weak_ = self._pending_results\n",
    "        if task_id not in weak_ and result.id not in concrete:\n",
    "            (weak_ if weak else concrete)[task_id] = result\n",
    "            self.result_consumer.consume_from(task_id)\n",
    "\n",
    "    def add_pending_results(self, results, weak=False):\n",
    "        self.result_consumer.drainer.start()\n",
    "        return [\n",
    "            self.add_pending_result(result, weak=weak, start_drainer=False)\n",
    "            for result in results\n",
    "        ]\n",
    "\n",
    "    def remove_pending_result(self, result):\n",
    "        self._remove_pending_result(result.id)\n",
    "        self.on_result_fulfilled(result)\n",
    "        return result\n",
    "\n",
    "    def _remove_pending_result(self, task_id):\n",
    "        for mapping in self._pending_results:\n",
    "            mapping.pop(task_id, None)\n",
    "\n",
    "    def on_result_fulfilled(self, result):\n",
    "        self.result_consumer.cancel_for(result.id)\n",
    "\n",
    "    def wait_for_pending(self, result, callback=None, propagate=True, **kwargs):\n",
    "        self._ensure_not_eager()\n",
    "        for _ in self._wait_for_pending(result, **kwargs):\n",
    "            pass\n",
    "        return result.maybe_throw(callback=callback, propagate=propagate)\n",
    "\n",
    "    def _wait_for_pending(\n",
    "        self, result, timeout=None, on_interval=None, on_message=None, **kwargs\n",
    "    ):\n",
    "        return self.result_consumer._wait_for_pending(\n",
    "            result,\n",
    "            timeout=timeout,\n",
    "            on_interval=on_interval,\n",
    "            on_message=on_message,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def is_async(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseResultConsumer:\n",
    "    \"\"\"Manager responsible for consuming result messages.\"\"\"\n",
    "\n",
    "    def __init__(self, backend, app, accept, pending_results, pending_messages):\n",
    "        self.backend = backend\n",
    "        self.app = app\n",
    "        self.accept = accept\n",
    "        self._pending_results = pending_results\n",
    "        self._pending_messages = pending_messages\n",
    "        self.on_message = None\n",
    "        self.buckets = WeakKeyDictionary()\n",
    "        self.drainer = drainers[detect_environment()](self)\n",
    "\n",
    "    def start(self, initial_task_id, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def stop(self):\n",
    "        pass\n",
    "\n",
    "    def drain_events(self, timeout=None):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def consume_from(self, task_id):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def cancel_for(self, task_id):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def _after_fork(self):\n",
    "        self.buckets.clear()\n",
    "        self.buckets = WeakKeyDictionary()\n",
    "        self.on_message = None\n",
    "        self.on_after_fork()\n",
    "\n",
    "    def on_after_fork(self):\n",
    "        pass\n",
    "\n",
    "    def drain_events_until(self, p, timeout=None, on_interval=None):\n",
    "        return self.drainer.drain_events_until(\n",
    "            p, timeout=timeout, on_interval=on_interval\n",
    "        )\n",
    "\n",
    "    def _wait_for_pending(\n",
    "        self, result, timeout=None, on_interval=None, on_message=None, **kwargs\n",
    "    ):\n",
    "        self.on_wait_for_pending(result, timeout=timeout, **kwargs)\n",
    "        prev_on_m, self.on_message = self.on_message, on_message\n",
    "        try:\n",
    "            for _ in self.drain_events_until(\n",
    "                result.on_ready, timeout=timeout, on_interval=on_interval\n",
    "            ):\n",
    "                yield\n",
    "                sleep(0)\n",
    "        except socket.timeout:\n",
    "            raise TimeoutError(\"The operation timed out.\")\n",
    "        finally:\n",
    "            self.on_message = prev_on_m\n",
    "\n",
    "    def on_wait_for_pending(self, result, timeout=None, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def on_out_of_band_result(self, message):\n",
    "        self.on_state_change(message.payload, message)\n",
    "\n",
    "    def _get_pending_result(self, task_id):\n",
    "        for mapping in self._pending_results:\n",
    "            try:\n",
    "                return mapping[task_id]\n",
    "            except KeyError:\n",
    "                pass\n",
    "        raise KeyError(task_id)\n",
    "\n",
    "    def on_state_change(self, meta, message):\n",
    "        if self.on_message:\n",
    "            self.on_message(meta)\n",
    "        if meta[\"status\"] in states.READY_STATES:\n",
    "            task_id = meta[\"task_id\"]\n",
    "            try:\n",
    "                result = self._get_pending_result(task_id)\n",
    "            except KeyError:\n",
    "                # send to buffer in case we received this result\n",
    "                # before it was added to _pending_results.\n",
    "                self._pending_messages.put(task_id, meta)\n",
    "            else:\n",
    "                result._maybe_set_cache(meta)\n",
    "                buckets = self.buckets\n",
    "                try:\n",
    "                    # remove bucket for this result, since it's fulfilled\n",
    "                    bucket = buckets.pop(result)\n",
    "                except KeyError:\n",
    "                    pass\n",
    "                else:\n",
    "                    # send to waiter via bucket\n",
    "                    bucket.append(result)\n",
    "        sleep(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}