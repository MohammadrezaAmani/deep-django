{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Logging utilities.\"\"\"\n",
    "import logging\n",
    "import numbers\n",
    "import os\n",
    "import sys\n",
    "import threading\n",
    "import traceback\n",
    "from contextlib import contextmanager\n",
    "from typing import AnyStr, Sequence  # noqa\n",
    "\n",
    "from kombu.log import LOG_LEVELS\n",
    "from kombu.log import get_logger as _get_logger\n",
    "from kombu.utils.encoding import safe_str\n",
    "\n",
    "from .term import colored\n",
    "\n",
    "__all__ = (\n",
    "    \"ColorFormatter\",\n",
    "    \"LoggingProxy\",\n",
    "    \"base_logger\",\n",
    "    \"set_in_sighandler\",\n",
    "    \"in_sighandler\",\n",
    "    \"get_logger\",\n",
    "    \"get_task_logger\",\n",
    "    \"mlevel\",\n",
    "    \"get_multiprocessing_logger\",\n",
    "    \"reset_multiprocessing_logger\",\n",
    "    \"LOG_LEVELS\",\n",
    ")\n",
    "\n",
    "_process_aware = False\n",
    "_in_sighandler = False\n",
    "\n",
    "MP_LOG = os.environ.get(\"MP_LOG\", False)\n",
    "\n",
    "RESERVED_LOGGER_NAMES = {\"celery\", \"celery.task\"}\n",
    "\n",
    "# Sets up our logging hierarchy.\n",
    "#\n",
    "# Every logger in the celery package inherits from the \"celery\"\n",
    "# logger, and every task logger inherits from the \"celery.task\"\n",
    "# logger.\n",
    "base_logger = logger = _get_logger(\"celery\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_in_sighandler(value):\n",
    "    \"\"\"Set flag signifiying that we're inside a signal handler.\"\"\"\n",
    "    global _in_sighandler\n",
    "    _in_sighandler = value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_open_logger_fds():\n",
    "    seen = set()\n",
    "    loggers = list(logging.Logger.manager.loggerDict.values()) + [\n",
    "        logging.getLogger(None)\n",
    "    ]\n",
    "    for l in loggers:\n",
    "        try:\n",
    "            for handler in l.handlers:\n",
    "                try:\n",
    "                    if handler not in seen:  # pragma: no cover\n",
    "                        yield handler.stream\n",
    "                        seen.add(handler)\n",
    "                except AttributeError:\n",
    "                    pass\n",
    "        except AttributeError:  # PlaceHolder does not have handlers\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def in_sighandler():\n",
    "    \"\"\"Context that records that we are in a signal handler.\"\"\"\n",
    "    set_in_sighandler(True)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        set_in_sighandler(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logger_isa(l, p, max=1000):\n",
    "    this, seen = l, set()\n",
    "    for _ in range(max):\n",
    "        if this == p:\n",
    "            return True\n",
    "        else:\n",
    "            if this in seen:\n",
    "                raise RuntimeError(\n",
    "                    f\"Logger {l.name!r} parents recursive\",\n",
    "                )\n",
    "            seen.add(this)\n",
    "            this = this.parent\n",
    "            if not this:\n",
    "                break\n",
    "    else:  # pragma: no cover\n",
    "        raise RuntimeError(f\"Logger hierarchy exceeds {max}\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _using_logger_parent(parent_logger, logger_):\n",
    "    if not logger_isa(logger_, parent_logger):\n",
    "        logger_.parent = parent_logger\n",
    "    return logger_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_logger(name):\n",
    "    \"\"\"Get logger by name.\"\"\"\n",
    "    l = _get_logger(name)\n",
    "    if logging.root not in (l, l.parent) and l is not base_logger:\n",
    "        l = _using_logger_parent(base_logger, l)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_logger = get_logger(\"celery.task\")\n",
    "worker_logger = get_logger(\"celery.worker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_logger(name):\n",
    "    \"\"\"Get logger for task module by name.\"\"\"\n",
    "    if name in RESERVED_LOGGER_NAMES:\n",
    "        raise RuntimeError(f\"Logger name {name!r} is reserved!\")\n",
    "    return _using_logger_parent(task_logger, get_logger(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlevel(level):\n",
    "    \"\"\"Convert level name/int to log level.\"\"\"\n",
    "    if level and not isinstance(level, numbers.Integral):\n",
    "        return LOG_LEVELS[level.upper()]\n",
    "    return level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColorFormatter(logging.Formatter):\n",
    "    \"\"\"Logging formatter that adds colors based on severity.\"\"\"\n",
    "\n",
    "    #: Loglevel -> Color mapping.\n",
    "    COLORS = colored().names\n",
    "    colors = {\n",
    "        \"DEBUG\": COLORS[\"blue\"],\n",
    "        \"WARNING\": COLORS[\"yellow\"],\n",
    "        \"ERROR\": COLORS[\"red\"],\n",
    "        \"CRITICAL\": COLORS[\"magenta\"],\n",
    "    }\n",
    "\n",
    "    def __init__(self, fmt=None, use_color=True):\n",
    "        super().__init__(fmt)\n",
    "        self.use_color = use_color\n",
    "\n",
    "    def formatException(self, ei):\n",
    "        if ei and not isinstance(ei, tuple):\n",
    "            ei = sys.exc_info()\n",
    "        r = super().formatException(ei)\n",
    "        return r\n",
    "\n",
    "    def format(self, record):\n",
    "        msg = super().format(record)\n",
    "        color = self.colors.get(record.levelname)\n",
    "\n",
    "        # reset exception info later for other handlers...\n",
    "        einfo = sys.exc_info() if record.exc_info == 1 else record.exc_info\n",
    "\n",
    "        if color and self.use_color:\n",
    "            try:\n",
    "                # safe_str will repr the color object\n",
    "                # and color will break on non-string objects\n",
    "                # so need to reorder calls based on type.\n",
    "                # Issue #427\n",
    "                try:\n",
    "                    if isinstance(msg, str):\n",
    "                        return str(color(safe_str(msg)))\n",
    "                    return safe_str(color(msg))\n",
    "                except UnicodeDecodeError:  # pragma: no cover\n",
    "                    return safe_str(msg)  # skip colors\n",
    "            except Exception as exc:  # pylint: disable=broad-except\n",
    "                prev_msg, record.exc_info, record.msg = (\n",
    "                    record.msg,\n",
    "                    1,\n",
    "                    \"<Unrepresentable {!r}: {!r}>\".format(type(msg), exc),\n",
    "                )\n",
    "                try:\n",
    "                    return super().format(record)\n",
    "                finally:\n",
    "                    record.msg, record.exc_info = prev_msg, einfo\n",
    "        else:\n",
    "            return safe_str(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoggingProxy:\n",
    "    \"\"\"Forward file object to :class:`logging.Logger` instance.\n",
    "\n",
    "    Arguments:\n",
    "        logger (~logging.Logger): Logger instance to forward to.\n",
    "        loglevel (int, str): Log level to use when logging messages.\n",
    "    \"\"\"\n",
    "\n",
    "    mode = \"w\"\n",
    "    name = None\n",
    "    closed = False\n",
    "    loglevel = logging.ERROR\n",
    "    _thread = threading.local()\n",
    "\n",
    "    def __init__(self, logger, loglevel=None):\n",
    "        # pylint: disable=redefined-outer-name\n",
    "        # Note that the logger global is redefined here, be careful changing.\n",
    "        self.logger = logger\n",
    "        self.loglevel = mlevel(loglevel or self.logger.level or self.loglevel)\n",
    "        self._safewrap_handlers()\n",
    "\n",
    "    def _safewrap_handlers(self):\n",
    "        # Make the logger handlers dump internal errors to\n",
    "        # :data:`sys.__stderr__` instead of :data:`sys.stderr` to circumvent\n",
    "        # infinite loops.\n",
    "\n",
    "        def wrap_handler(handler):  # pragma: no cover\n",
    "            class WithSafeHandleError(logging.Handler):\n",
    "                def handleError(self, record):\n",
    "                    try:\n",
    "                        traceback.print_exc(None, sys.__stderr__)\n",
    "                    except OSError:\n",
    "                        pass  # see python issue 5971\n",
    "\n",
    "            handler.handleError = WithSafeHandleError().handleError\n",
    "\n",
    "        return [wrap_handler(h) for h in self.logger.handlers]\n",
    "\n",
    "    def write(self, data):\n",
    "        # type: (AnyStr) -> int\n",
    "        \"\"\"Write message to logging object.\"\"\"\n",
    "        if _in_sighandler:\n",
    "            safe_data = safe_str(data)\n",
    "            print(safe_data, file=sys.__stderr__)\n",
    "            return len(safe_data)\n",
    "        if getattr(self._thread, \"recurse_protection\", False):\n",
    "            # Logger is logging back to this file, so stop recursing.\n",
    "            return 0\n",
    "        if data and not self.closed:\n",
    "            self._thread.recurse_protection = True\n",
    "            try:\n",
    "                safe_data = safe_str(data).rstrip(\"\\n\")\n",
    "                if safe_data:\n",
    "                    self.logger.log(self.loglevel, safe_data)\n",
    "                    return len(safe_data)\n",
    "            finally:\n",
    "                self._thread.recurse_protection = False\n",
    "        return 0\n",
    "\n",
    "    def writelines(self, sequence):\n",
    "        # type: (Sequence[str]) -> None\n",
    "        \"\"\"Write list of strings to file.\n",
    "\n",
    "        The sequence can be any iterable object producing strings.\n",
    "        This is equivalent to calling :meth:`write` for each string.\n",
    "        \"\"\"\n",
    "        for part in sequence:\n",
    "            self.write(part)\n",
    "\n",
    "    def flush(self):\n",
    "        # This object is not buffered so any :meth:`flush`\n",
    "        # requests are ignored.\n",
    "        pass\n",
    "\n",
    "    def close(self):\n",
    "        # when the object is closed, no write requests are\n",
    "        # forwarded to the logging object anymore.\n",
    "        self.closed = True\n",
    "\n",
    "    def isatty(self):\n",
    "        \"\"\"Here for file support.\"\"\"\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multiprocessing_logger():\n",
    "    \"\"\"Return the multiprocessing logger.\"\"\"\n",
    "    try:\n",
    "        from billiard import util\n",
    "    except ImportError:\n",
    "        pass\n",
    "    else:\n",
    "        return util.get_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_multiprocessing_logger():\n",
    "    \"\"\"Reset multiprocessing logging setup.\"\"\"\n",
    "    try:\n",
    "        from billiard import util\n",
    "    except ImportError:\n",
    "        pass\n",
    "    else:\n",
    "        if hasattr(util, \"_logger\"):  # pragma: no cover\n",
    "            util._logger = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_process():\n",
    "    try:\n",
    "        from billiard import process\n",
    "    except ImportError:\n",
    "        pass\n",
    "    else:\n",
    "        return process.current_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def current_process_index(base=1):\n",
    "    index = getattr(current_process(), \"index\", None)\n",
    "    return index + base if index is not None else index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}