{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Worker Remote Control Client.\n",
    "\n",
    "Client for worker remote control commands.\n",
    "Server implementation is in :mod:`celery.worker.control`.\n",
    "There are two types of remote control commands:\n",
    "\n",
    "* Inspect commands: Does not have side effects, will usually just return some value\n",
    "  found in the worker, like the list of currently registered tasks, the list of active tasks, etc.\n",
    "  Commands are accessible via :class:`Inspect` class.\n",
    "\n",
    "* Control commands: Performs side effects, like adding a new queue to consume from.\n",
    "  Commands are accessible via :class:`Control` class.\n",
    "\"\"\"\n",
    "import warnings\n",
    "\n",
    "from billiard.common import TERM_SIGNAME\n",
    "from kombu.matcher import match\n",
    "from kombu.pidbox import Mailbox\n",
    "from kombu.utils.compat import register_after_fork\n",
    "from kombu.utils.functional import lazy\n",
    "from kombu.utils.objects import cached_property\n",
    "\n",
    "from celery.exceptions import DuplicateNodenameWarning\n",
    "from celery.utils.log import get_logger\n",
    "from celery.utils.text import pluralize\n",
    "\n",
    "__all__ = (\"Inspect\", \"Control\", \"flatten_reply\")\n",
    "\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "W_DUPNODE = \"\"\"\\\n",
    "Received multiple replies from node {0}: {1}.\n",
    "Please make sure you give each node a unique nodename using\n",
    "the celery worker `-n` option.\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_reply(reply):\n",
    "    \"\"\"Flatten node replies.\n",
    "\n",
    "    Convert from a list of replies in this format::\n",
    "\n",
    "        [{'a@example.com': reply},\n",
    "         {'b@example.com': reply}]\n",
    "\n",
    "    into this format::\n",
    "\n",
    "        {'a@example.com': reply,\n",
    "         'b@example.com': reply}\n",
    "    \"\"\"\n",
    "    nodes, dupes = {}, set()\n",
    "    for item in reply:\n",
    "        [dupes.add(name) for name in item if name in nodes]\n",
    "        nodes.update(item)\n",
    "    if dupes:\n",
    "        warnings.warn(\n",
    "            DuplicateNodenameWarning(\n",
    "                W_DUPNODE.format(\n",
    "                    pluralize(len(dupes), \"name\"),\n",
    "                    \", \".join(sorted(dupes)),\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _after_fork_cleanup_control(control):\n",
    "    try:\n",
    "        control._after_fork()\n",
    "    except Exception as exc:  # pylint: disable=broad-except\n",
    "        logger.info(\"after fork raised exception: %r\", exc, exc_info=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Inspect:\n",
    "    \"\"\"API for inspecting workers.\n",
    "\n",
    "    This class provides proxy for accessing Inspect API of workers. The API is\n",
    "    defined in :py:mod:`celery.worker.control`\n",
    "    \"\"\"\n",
    "\n",
    "    app = None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        destination=None,\n",
    "        timeout=1.0,\n",
    "        callback=None,\n",
    "        connection=None,\n",
    "        app=None,\n",
    "        limit=None,\n",
    "        pattern=None,\n",
    "        matcher=None,\n",
    "    ):\n",
    "        self.app = app or self.app\n",
    "        self.destination = destination\n",
    "        self.timeout = timeout\n",
    "        self.callback = callback\n",
    "        self.connection = connection\n",
    "        self.limit = limit\n",
    "        self.pattern = pattern\n",
    "        self.matcher = matcher\n",
    "\n",
    "    def _prepare(self, reply):\n",
    "        if reply:\n",
    "            by_node = flatten_reply(reply)\n",
    "            if self.destination and not isinstance(self.destination, (list, tuple)):\n",
    "                return by_node.get(self.destination)\n",
    "            if self.pattern:\n",
    "                pattern = self.pattern\n",
    "                matcher = self.matcher\n",
    "                return {\n",
    "                    node: reply\n",
    "                    for node, reply in by_node.items()\n",
    "                    if match(node, pattern, matcher)\n",
    "                }\n",
    "            return by_node\n",
    "\n",
    "    def _request(self, command, **kwargs):\n",
    "        return self._prepare(\n",
    "            self.app.control.broadcast(\n",
    "                command,\n",
    "                arguments=kwargs,\n",
    "                destination=self.destination,\n",
    "                callback=self.callback,\n",
    "                connection=self.connection,\n",
    "                limit=self.limit,\n",
    "                timeout=self.timeout,\n",
    "                reply=True,\n",
    "                pattern=self.pattern,\n",
    "                matcher=self.matcher,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def report(self):\n",
    "        \"\"\"Return human readable report for each worker.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: {'ok': REPORT_STRING}}``.\n",
    "        \"\"\"\n",
    "        return self._request(\"report\")\n",
    "\n",
    "    def clock(self):\n",
    "        \"\"\"Get the Clock value on workers.\n",
    "\n",
    "        >>> app.control.inspect().clock()\n",
    "        {'celery@node1': {'clock': 12}}\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: CLOCK_VALUE}``.\n",
    "        \"\"\"\n",
    "        return self._request(\"clock\")\n",
    "\n",
    "    def active(self, safe=None):\n",
    "        \"\"\"Return list of tasks currently executed by workers.\n",
    "\n",
    "        Arguments:\n",
    "            safe (Boolean): Set to True to disable deserialization.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: [TASK_INFO,...]}``.\n",
    "\n",
    "        See Also:\n",
    "            For ``TASK_INFO`` details see :func:`query_task` return value.\n",
    "\n",
    "        \"\"\"\n",
    "        return self._request(\"active\", safe=safe)\n",
    "\n",
    "    def scheduled(self, safe=None):\n",
    "        \"\"\"Return list of scheduled tasks with details.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: [TASK_SCHEDULED_INFO,...]}``.\n",
    "\n",
    "        Here is the list of ``TASK_SCHEDULED_INFO`` fields:\n",
    "\n",
    "        * ``eta`` - scheduled time for task execution as string in ISO 8601 format\n",
    "        * ``priority`` - priority of the task\n",
    "        * ``request`` - field containing ``TASK_INFO`` value.\n",
    "\n",
    "        See Also:\n",
    "            For more details about ``TASK_INFO``  see :func:`query_task` return value.\n",
    "        \"\"\"\n",
    "        return self._request(\"scheduled\")\n",
    "\n",
    "    def reserved(self, safe=None):\n",
    "        \"\"\"Return list of currently reserved tasks, not including scheduled/active.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: [TASK_INFO,...]}``.\n",
    "\n",
    "        See Also:\n",
    "            For ``TASK_INFO`` details see :func:`query_task` return value.\n",
    "        \"\"\"\n",
    "        return self._request(\"reserved\")\n",
    "\n",
    "    def stats(self):\n",
    "        \"\"\"Return statistics of worker.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: STAT_INFO}``.\n",
    "\n",
    "        Here is the list of ``STAT_INFO`` fields:\n",
    "\n",
    "        * ``broker`` - Section for broker information.\n",
    "            * ``connect_timeout`` - Timeout in seconds (int/float) for establishing a new connection.\n",
    "            * ``heartbeat`` - Current heartbeat value (set by client).\n",
    "            * ``hostname`` - Node name of the remote broker.\n",
    "            * ``insist`` - No longer used.\n",
    "            * ``login_method`` - Login method used to connect to the broker.\n",
    "            * ``port`` - Port of the remote broker.\n",
    "            * ``ssl`` - SSL enabled/disabled.\n",
    "            * ``transport`` - Name of transport used (e.g., amqp or redis)\n",
    "            * ``transport_options`` - Options passed to transport.\n",
    "            * ``uri_prefix`` - Some transports expects the host name to be a URL.\n",
    "              E.g. ``redis+socket:///tmp/redis.sock``.\n",
    "              In this example the URI-prefix will be redis.\n",
    "            * ``userid`` - User id used to connect to the broker with.\n",
    "            * ``virtual_host`` - Virtual host used.\n",
    "        * ``clock`` - Value of the workers logical clock. This is a positive integer\n",
    "          and should be increasing every time you receive statistics.\n",
    "        * ``uptime`` - Numbers of seconds since the worker controller was started\n",
    "        * ``pid`` - Process id of the worker instance (Main process).\n",
    "        * ``pool`` - Pool-specific section.\n",
    "            * ``max-concurrency`` - Max number of processes/threads/green threads.\n",
    "            * ``max-tasks-per-child`` - Max number of tasks a thread may execute before being recycled.\n",
    "            * ``processes`` - List of PIDs (or thread-idâ€™s).\n",
    "            * ``put-guarded-by-semaphore`` - Internal\n",
    "            * ``timeouts`` - Default values for time limits.\n",
    "            * ``writes`` - Specific to the prefork pool, this shows the distribution\n",
    "              of writes to each process in the pool when using async I/O.\n",
    "        * ``prefetch_count`` - Current prefetch count value for the task consumer.\n",
    "        * ``rusage`` - System usage statistics. The fields available may be different on your platform.\n",
    "          From :manpage:`getrusage(2)`:\n",
    "\n",
    "            * ``stime`` - Time spent in operating system code on behalf of this process.\n",
    "            * ``utime`` - Time spent executing user instructions.\n",
    "            * ``maxrss`` - The maximum resident size used by this process (in kilobytes).\n",
    "            * ``idrss`` - Amount of non-shared memory used for data (in kilobytes times\n",
    "              ticks of execution)\n",
    "            * ``isrss`` - Amount of non-shared memory used for stack space\n",
    "              (in kilobytes times ticks of execution)\n",
    "            * ``ixrss`` - Amount of memory shared with other processes\n",
    "              (in kilobytes times ticks of execution).\n",
    "            * ``inblock`` - Number of times the file system had to read from the disk\n",
    "              on behalf of this process.\n",
    "            * ``oublock`` - Number of times the file system has to write to disk\n",
    "              on behalf of this process.\n",
    "            * ``majflt`` - Number of page faults that were serviced by doing I/O.\n",
    "            * ``minflt`` - Number of page faults that were serviced without doing I/O.\n",
    "            * ``msgrcv`` - Number of IPC messages received.\n",
    "            * ``msgsnd`` - Number of IPC messages sent.\n",
    "            * ``nvcsw`` - Number of times this process voluntarily invoked a context switch.\n",
    "            * ``nivcsw`` - Number of times an involuntary context switch took place.\n",
    "            * ``nsignals`` - Number of signals received.\n",
    "            * ``nswap`` - The number of times this process was swapped entirely\n",
    "              out of memory.\n",
    "        * ``total`` - Map of task names and the total number of tasks with that type\n",
    "          the worker has accepted since start-up.\n",
    "        \"\"\"\n",
    "        return self._request(\"stats\")\n",
    "\n",
    "    def revoked(self):\n",
    "        \"\"\"Return list of revoked tasks.\n",
    "\n",
    "        >>> app.control.inspect().revoked()\n",
    "        {'celery@node1': ['16f527de-1c72-47a6-b477-c472b92fef7a']}\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: [TASK_ID, ...]}``.\n",
    "        \"\"\"\n",
    "        return self._request(\"revoked\")\n",
    "\n",
    "    def registered(self, *taskinfoitems):\n",
    "        \"\"\"Return all registered tasks per worker.\n",
    "\n",
    "        >>> app.control.inspect().registered()\n",
    "        {'celery@node1': ['task1', 'task1']}\n",
    "        >>> app.control.inspect().registered('serializer', 'max_retries')\n",
    "        {'celery@node1': ['task_foo [serializer=json max_retries=3]', 'tasb_bar [serializer=json max_retries=3]']}\n",
    "\n",
    "        Arguments:\n",
    "            taskinfoitems (Sequence[str]): List of :class:`~celery.app.task.Task`\n",
    "                                           attributes to include.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: [TASK1_INFO, ...]}``.\n",
    "        \"\"\"\n",
    "        return self._request(\"registered\", taskinfoitems=taskinfoitems)\n",
    "\n",
    "    registered_tasks = registered\n",
    "\n",
    "    def ping(self, destination=None):\n",
    "        \"\"\"Ping all (or specific) workers.\n",
    "\n",
    "        >>> app.control.inspect().ping()\n",
    "        {'celery@node1': {'ok': 'pong'}, 'celery@node2': {'ok': 'pong'}}\n",
    "        >>> app.control.inspect().ping(destination=['celery@node1'])\n",
    "        {'celery@node1': {'ok': 'pong'}}\n",
    "\n",
    "        Arguments:\n",
    "            destination (List): If set, a list of the hosts to send the\n",
    "                command to, when empty broadcast to all workers.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: {'ok': 'pong'}}``.\n",
    "\n",
    "        See Also:\n",
    "            :meth:`broadcast` for supported keyword arguments.\n",
    "        \"\"\"\n",
    "        if destination:\n",
    "            self.destination = destination\n",
    "        return self._request(\"ping\")\n",
    "\n",
    "    def active_queues(self):\n",
    "        \"\"\"Return information about queues from which worker consumes tasks.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: [QUEUE_INFO, QUEUE_INFO,...]}``.\n",
    "\n",
    "        Here is the list of ``QUEUE_INFO`` fields:\n",
    "\n",
    "        * ``name``\n",
    "        * ``exchange``\n",
    "            * ``name``\n",
    "            * ``type``\n",
    "            * ``arguments``\n",
    "            * ``durable``\n",
    "            * ``passive``\n",
    "            * ``auto_delete``\n",
    "            * ``delivery_mode``\n",
    "            * ``no_declare``\n",
    "        * ``routing_key``\n",
    "        * ``queue_arguments``\n",
    "        * ``binding_arguments``\n",
    "        * ``consumer_arguments``\n",
    "        * ``durable``\n",
    "        * ``exclusive``\n",
    "        * ``auto_delete``\n",
    "        * ``no_ack``\n",
    "        * ``alias``\n",
    "        * ``bindings``\n",
    "        * ``no_declare``\n",
    "        * ``expires``\n",
    "        * ``message_ttl``\n",
    "        * ``max_length``\n",
    "        * ``max_length_bytes``\n",
    "        * ``max_priority``\n",
    "\n",
    "        See Also:\n",
    "            See the RabbitMQ/AMQP documentation for more details about\n",
    "            ``queue_info`` fields.\n",
    "        Note:\n",
    "            The ``queue_info`` fields are RabbitMQ/AMQP oriented.\n",
    "            Not all fields applies for other transports.\n",
    "        \"\"\"\n",
    "        return self._request(\"active_queues\")\n",
    "\n",
    "    def query_task(self, *ids):\n",
    "        \"\"\"Return detail of tasks currently executed by workers.\n",
    "\n",
    "        Arguments:\n",
    "            *ids (str): IDs of tasks to be queried.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: {TASK_ID: [STATE, TASK_INFO]}}``.\n",
    "\n",
    "        Here is the list of ``TASK_INFO`` fields:\n",
    "            * ``id`` - ID of the task\n",
    "            * ``name`` - Name of the task\n",
    "            * ``args`` - Positinal arguments passed to the task\n",
    "            * ``kwargs`` - Keyword arguments passed to the task\n",
    "            * ``type`` - Type of the task\n",
    "            * ``hostname`` - Hostname of the worker processing the task\n",
    "            * ``time_start`` - Time of processing start\n",
    "            * ``acknowledged`` - True when task was acknowledged to broker\n",
    "            * ``delivery_info`` - Dictionary containing delivery information\n",
    "                * ``exchange`` - Name of exchange where task was published\n",
    "                * ``routing_key`` - Routing key used when task was published\n",
    "                * ``priority`` - Priority used when task was published\n",
    "                * ``redelivered`` - True if the task was redelivered\n",
    "            * ``worker_pid`` - PID of worker processing the task\n",
    "\n",
    "        \"\"\"\n",
    "        # signature used be unary: query_task(ids=[id1, id2])\n",
    "        # we need this to preserve backward compatibility.\n",
    "        if len(ids) == 1 and isinstance(ids[0], (list, tuple)):\n",
    "            ids = ids[0]\n",
    "        return self._request(\"query_task\", ids=ids)\n",
    "\n",
    "    def conf(self, with_defaults=False):\n",
    "        \"\"\"Return configuration of each worker.\n",
    "\n",
    "        Arguments:\n",
    "            with_defaults (bool): if set to True, method returns also\n",
    "                                   configuration options with default values.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{HOSTNAME: WORKER_CONFIGURATION}``.\n",
    "\n",
    "        See Also:\n",
    "            ``WORKER_CONFIGURATION`` is a dictionary containing current configuration options.\n",
    "            See :ref:`configuration` for possible values.\n",
    "        \"\"\"\n",
    "        return self._request(\"conf\", with_defaults=with_defaults)\n",
    "\n",
    "    def hello(self, from_node, revoked=None):\n",
    "        return self._request(\"hello\", from_node=from_node, revoked=revoked)\n",
    "\n",
    "    def memsample(self):\n",
    "        \"\"\"Return sample current RSS memory usage.\n",
    "\n",
    "        Note:\n",
    "            Requires the psutils library.\n",
    "        \"\"\"\n",
    "        return self._request(\"memsample\")\n",
    "\n",
    "    def memdump(self, samples=10):\n",
    "        \"\"\"Dump statistics of previous memsample requests.\n",
    "\n",
    "        Note:\n",
    "            Requires the psutils library.\n",
    "        \"\"\"\n",
    "        return self._request(\"memdump\", samples=samples)\n",
    "\n",
    "    def objgraph(self, type=\"Request\", n=200, max_depth=10):\n",
    "        \"\"\"Create graph of uncollected objects (memory-leak debugging).\n",
    "\n",
    "        Arguments:\n",
    "            n (int): Max number of objects to graph.\n",
    "            max_depth (int): Traverse at most n levels deep.\n",
    "            type (str): Name of object to graph.  Default is ``\"Request\"``.\n",
    "\n",
    "        Returns:\n",
    "            Dict: Dictionary ``{'filename': FILENAME}``\n",
    "\n",
    "        Note:\n",
    "            Requires the objgraph library.\n",
    "        \"\"\"\n",
    "        return self._request(\"objgraph\", num=n, max_depth=max_depth, type=type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Control:\n",
    "    \"\"\"Worker remote control client.\"\"\"\n",
    "\n",
    "    Mailbox = Mailbox\n",
    "\n",
    "    def __init__(self, app=None):\n",
    "        self.app = app\n",
    "        self.mailbox = self.Mailbox(\n",
    "            app.conf.control_exchange,\n",
    "            type=\"fanout\",\n",
    "            accept=app.conf.accept_content,\n",
    "            serializer=app.conf.task_serializer,\n",
    "            producer_pool=lazy(lambda: self.app.amqp.producer_pool),\n",
    "            queue_ttl=app.conf.control_queue_ttl,\n",
    "            reply_queue_ttl=app.conf.control_queue_ttl,\n",
    "            queue_expires=app.conf.control_queue_expires,\n",
    "            reply_queue_expires=app.conf.control_queue_expires,\n",
    "        )\n",
    "        register_after_fork(self, _after_fork_cleanup_control)\n",
    "\n",
    "    def _after_fork(self):\n",
    "        del self.mailbox.producer_pool\n",
    "\n",
    "    @cached_property\n",
    "    def inspect(self):\n",
    "        \"\"\"Create new :class:`Inspect` instance.\"\"\"\n",
    "        return self.app.subclass_with_self(Inspect, reverse=\"control.inspect\")\n",
    "\n",
    "    def purge(self, connection=None):\n",
    "        \"\"\"Discard all waiting tasks.\n",
    "\n",
    "        This will ignore all tasks waiting for execution, and they will\n",
    "        be deleted from the messaging server.\n",
    "\n",
    "        Arguments:\n",
    "            connection (kombu.Connection): Optional specific connection\n",
    "                instance to use.  If not provided a connection will\n",
    "                be acquired from the connection pool.\n",
    "\n",
    "        Returns:\n",
    "            int: the number of tasks discarded.\n",
    "        \"\"\"\n",
    "        with self.app.connection_or_acquire(connection) as conn:\n",
    "            return self.app.amqp.TaskConsumer(conn).purge()\n",
    "\n",
    "    discard_all = purge\n",
    "\n",
    "    def election(self, id, topic, action=None, connection=None):\n",
    "        self.broadcast(\n",
    "            \"election\",\n",
    "            connection=connection,\n",
    "            destination=None,\n",
    "            arguments={\n",
    "                \"id\": id,\n",
    "                \"topic\": topic,\n",
    "                \"action\": action,\n",
    "            },\n",
    "        )\n",
    "\n",
    "    def revoke(\n",
    "        self, task_id, destination=None, terminate=False, signal=TERM_SIGNAME, **kwargs\n",
    "    ):\n",
    "        \"\"\"Tell all (or specific) workers to revoke a task by id (or list of ids).\n",
    "\n",
    "        If a task is revoked, the workers will ignore the task and\n",
    "        not execute it after all.\n",
    "\n",
    "        Arguments:\n",
    "            task_id (Union(str, list)): Id of the task to revoke\n",
    "                (or list of ids).\n",
    "            terminate (bool): Also terminate the process currently working\n",
    "                on the task (if any).\n",
    "            signal (str): Name of signal to send to process if terminate.\n",
    "                Default is TERM.\n",
    "\n",
    "        See Also:\n",
    "            :meth:`broadcast` for supported keyword arguments.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"revoke\",\n",
    "            destination=destination,\n",
    "            arguments={\n",
    "                \"task_id\": task_id,\n",
    "                \"terminate\": terminate,\n",
    "                \"signal\": signal,\n",
    "            },\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def revoke_by_stamped_headers(\n",
    "        self, headers, destination=None, terminate=False, signal=TERM_SIGNAME, **kwargs\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Tell all (or specific) workers to revoke a task by headers.\n",
    "\n",
    "        If a task is revoked, the workers will ignore the task and\n",
    "        not execute it after all.\n",
    "\n",
    "        Arguments:\n",
    "            headers (dict[str, Union(str, list)]): Headers to match when revoking tasks.\n",
    "            terminate (bool): Also terminate the process currently working\n",
    "                on the task (if any).\n",
    "            signal (str): Name of signal to send to process if terminate.\n",
    "                Default is TERM.\n",
    "\n",
    "        See Also:\n",
    "            :meth:`broadcast` for supported keyword arguments.\n",
    "        \"\"\"\n",
    "        result = self.broadcast(\n",
    "            \"revoke_by_stamped_headers\",\n",
    "            destination=destination,\n",
    "            arguments={\n",
    "                \"headers\": headers,\n",
    "                \"terminate\": terminate,\n",
    "                \"signal\": signal,\n",
    "            },\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        task_ids = set()\n",
    "        if result:\n",
    "            for host in result:\n",
    "                for response in host.values():\n",
    "                    task_ids.update(response[\"ok\"])\n",
    "\n",
    "        if task_ids:\n",
    "            return self.revoke(\n",
    "                list(task_ids),\n",
    "                destination=destination,\n",
    "                terminate=terminate,\n",
    "                signal=signal,\n",
    "                **kwargs\n",
    "            )\n",
    "        else:\n",
    "            return result\n",
    "\n",
    "    def terminate(self, task_id, destination=None, signal=TERM_SIGNAME, **kwargs):\n",
    "        \"\"\"Tell all (or specific) workers to terminate a task by id (or list of ids).\n",
    "\n",
    "        See Also:\n",
    "            This is just a shortcut to :meth:`revoke` with the terminate\n",
    "            argument enabled.\n",
    "        \"\"\"\n",
    "        return self.revoke(\n",
    "            task_id, destination=destination, terminate=True, signal=signal, **kwargs\n",
    "        )\n",
    "\n",
    "    def ping(self, destination=None, timeout=1.0, **kwargs):\n",
    "        \"\"\"Ping all (or specific) workers.\n",
    "\n",
    "        >>> app.control.ping()\n",
    "        [{'celery@node1': {'ok': 'pong'}}, {'celery@node2': {'ok': 'pong'}}]\n",
    "        >>> app.control.ping(destination=['celery@node2'])\n",
    "        [{'celery@node2': {'ok': 'pong'}}]\n",
    "\n",
    "        Returns:\n",
    "            List[Dict]: List of ``{HOSTNAME: {'ok': 'pong'}}`` dictionaries.\n",
    "\n",
    "        See Also:\n",
    "            :meth:`broadcast` for supported keyword arguments.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"ping\",\n",
    "            reply=True,\n",
    "            arguments={},\n",
    "            destination=destination,\n",
    "            timeout=timeout,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def rate_limit(self, task_name, rate_limit, destination=None, **kwargs):\n",
    "        \"\"\"Tell workers to set a new rate limit for task by type.\n",
    "\n",
    "        Arguments:\n",
    "            task_name (str): Name of task to change rate limit for.\n",
    "            rate_limit (int, str): The rate limit as tasks per second,\n",
    "                or a rate limit string (`'100/m'`, etc.\n",
    "                see :attr:`celery.app.task.Task.rate_limit` for\n",
    "                more information).\n",
    "\n",
    "        See Also:\n",
    "            :meth:`broadcast` for supported keyword arguments.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"rate_limit\",\n",
    "            destination=destination,\n",
    "            arguments={\n",
    "                \"task_name\": task_name,\n",
    "                \"rate_limit\": rate_limit,\n",
    "            },\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def add_consumer(\n",
    "        self,\n",
    "        queue,\n",
    "        exchange=None,\n",
    "        exchange_type=\"direct\",\n",
    "        routing_key=None,\n",
    "        options=None,\n",
    "        destination=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        \"\"\"Tell all (or specific) workers to start consuming from a new queue.\n",
    "\n",
    "        Only the queue name is required as if only the queue is specified\n",
    "        then the exchange/routing key will be set to the same name (\n",
    "        like automatic queues do).\n",
    "\n",
    "        Note:\n",
    "            This command does not respect the default queue/exchange\n",
    "            options in the configuration.\n",
    "\n",
    "        Arguments:\n",
    "            queue (str): Name of queue to start consuming from.\n",
    "            exchange (str): Optional name of exchange.\n",
    "            exchange_type (str): Type of exchange (defaults to 'direct')\n",
    "                command to, when empty broadcast to all workers.\n",
    "            routing_key (str): Optional routing key.\n",
    "            options (Dict): Additional options as supported\n",
    "                by :meth:`kombu.entity.Queue.from_dict`.\n",
    "\n",
    "        See Also:\n",
    "            :meth:`broadcast` for supported keyword arguments.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"add_consumer\",\n",
    "            destination=destination,\n",
    "            arguments=dict(\n",
    "                {\n",
    "                    \"queue\": queue,\n",
    "                    \"exchange\": exchange,\n",
    "                    \"exchange_type\": exchange_type,\n",
    "                    \"routing_key\": routing_key,\n",
    "                },\n",
    "                **options or {}\n",
    "            ),\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def cancel_consumer(self, queue, destination=None, **kwargs):\n",
    "        \"\"\"Tell all (or specific) workers to stop consuming from ``queue``.\n",
    "\n",
    "        See Also:\n",
    "            Supports the same arguments as :meth:`broadcast`.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"cancel_consumer\",\n",
    "            destination=destination,\n",
    "            arguments={\"queue\": queue},\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def time_limit(self, task_name, soft=None, hard=None, destination=None, **kwargs):\n",
    "        \"\"\"Tell workers to set time limits for a task by type.\n",
    "\n",
    "        Arguments:\n",
    "            task_name (str): Name of task to change time limits for.\n",
    "            soft (float): New soft time limit (in seconds).\n",
    "            hard (float): New hard time limit (in seconds).\n",
    "            **kwargs (Any): arguments passed on to :meth:`broadcast`.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"time_limit\",\n",
    "            arguments={\n",
    "                \"task_name\": task_name,\n",
    "                \"hard\": hard,\n",
    "                \"soft\": soft,\n",
    "            },\n",
    "            destination=destination,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def enable_events(self, destination=None, **kwargs):\n",
    "        \"\"\"Tell all (or specific) workers to enable events.\n",
    "\n",
    "        See Also:\n",
    "            Supports the same arguments as :meth:`broadcast`.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"enable_events\", arguments={}, destination=destination, **kwargs\n",
    "        )\n",
    "\n",
    "    def disable_events(self, destination=None, **kwargs):\n",
    "        \"\"\"Tell all (or specific) workers to disable events.\n",
    "\n",
    "        See Also:\n",
    "            Supports the same arguments as :meth:`broadcast`.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"disable_events\", arguments={}, destination=destination, **kwargs\n",
    "        )\n",
    "\n",
    "    def pool_grow(self, n=1, destination=None, **kwargs):\n",
    "        \"\"\"Tell all (or specific) workers to grow the pool by ``n``.\n",
    "\n",
    "        See Also:\n",
    "            Supports the same arguments as :meth:`broadcast`.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"pool_grow\", arguments={\"n\": n}, destination=destination, **kwargs\n",
    "        )\n",
    "\n",
    "    def pool_shrink(self, n=1, destination=None, **kwargs):\n",
    "        \"\"\"Tell all (or specific) workers to shrink the pool by ``n``.\n",
    "\n",
    "        See Also:\n",
    "            Supports the same arguments as :meth:`broadcast`.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"pool_shrink\", arguments={\"n\": n}, destination=destination, **kwargs\n",
    "        )\n",
    "\n",
    "    def autoscale(self, max, min, destination=None, **kwargs):\n",
    "        \"\"\"Change worker(s) autoscale setting.\n",
    "\n",
    "        See Also:\n",
    "            Supports the same arguments as :meth:`broadcast`.\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"autoscale\",\n",
    "            arguments={\"max\": max, \"min\": min},\n",
    "            destination=destination,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def shutdown(self, destination=None, **kwargs):\n",
    "        \"\"\"Shutdown worker(s).\n",
    "\n",
    "        See Also:\n",
    "            Supports the same arguments as :meth:`broadcast`\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"shutdown\", arguments={}, destination=destination, **kwargs\n",
    "        )\n",
    "\n",
    "    def pool_restart(\n",
    "        self, modules=None, reload=False, reloader=None, destination=None, **kwargs\n",
    "    ):\n",
    "        \"\"\"Restart the execution pools of all or specific workers.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            modules (Sequence[str]): List of modules to reload.\n",
    "            reload (bool): Flag to enable module reloading.  Default is False.\n",
    "            reloader (Any): Function to reload a module.\n",
    "            destination (Sequence[str]): List of worker names to send this\n",
    "                command to.\n",
    "\n",
    "        See Also:\n",
    "            Supports the same arguments as :meth:`broadcast`\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"pool_restart\",\n",
    "            arguments={\n",
    "                \"modules\": modules,\n",
    "                \"reload\": reload,\n",
    "                \"reloader\": reloader,\n",
    "            },\n",
    "            destination=destination,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def heartbeat(self, destination=None, **kwargs):\n",
    "        \"\"\"Tell worker(s) to send a heartbeat immediately.\n",
    "\n",
    "        See Also:\n",
    "            Supports the same arguments as :meth:`broadcast`\n",
    "        \"\"\"\n",
    "        return self.broadcast(\n",
    "            \"heartbeat\", arguments={}, destination=destination, **kwargs\n",
    "        )\n",
    "\n",
    "    def broadcast(\n",
    "        self,\n",
    "        command,\n",
    "        arguments=None,\n",
    "        destination=None,\n",
    "        connection=None,\n",
    "        reply=False,\n",
    "        timeout=1.0,\n",
    "        limit=None,\n",
    "        callback=None,\n",
    "        channel=None,\n",
    "        pattern=None,\n",
    "        matcher=None,\n",
    "        **extra_kwargs\n",
    "    ):\n",
    "        \"\"\"Broadcast a control command to the celery workers.\n",
    "\n",
    "        Arguments:\n",
    "            command (str): Name of command to send.\n",
    "            arguments (Dict): Keyword arguments for the command.\n",
    "            destination (List): If set, a list of the hosts to send the\n",
    "                command to, when empty broadcast to all workers.\n",
    "            connection (kombu.Connection): Custom broker connection to use,\n",
    "                if not set, a connection will be acquired from the pool.\n",
    "            reply (bool): Wait for and return the reply.\n",
    "            timeout (float): Timeout in seconds to wait for the reply.\n",
    "            limit (int): Limit number of replies.\n",
    "            callback (Callable): Callback called immediately for\n",
    "                each reply received.\n",
    "            pattern (str): Custom pattern string to match\n",
    "            matcher (Callable): Custom matcher to run the pattern to match\n",
    "        \"\"\"\n",
    "        with self.app.connection_or_acquire(connection) as conn:\n",
    "            arguments = dict(arguments or {}, **extra_kwargs)\n",
    "            if pattern and matcher:\n",
    "                # tests pass easier without requiring pattern/matcher to\n",
    "                # always be sent in\n",
    "                return self.mailbox(conn)._broadcast(\n",
    "                    command,\n",
    "                    arguments,\n",
    "                    destination,\n",
    "                    reply,\n",
    "                    timeout,\n",
    "                    limit,\n",
    "                    callback,\n",
    "                    channel=channel,\n",
    "                    pattern=pattern,\n",
    "                    matcher=matcher,\n",
    "                )\n",
    "            else:\n",
    "                return self.mailbox(conn)._broadcast(\n",
    "                    command,\n",
    "                    arguments,\n",
    "                    destination,\n",
    "                    reply,\n",
    "                    timeout,\n",
    "                    limit,\n",
    "                    callback,\n",
    "                    channel=channel,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}