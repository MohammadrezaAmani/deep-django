{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Task implementation: request context and the task base class.\"\"\"\n",
    "import sys\n",
    "\n",
    "from billiard.einfo import ExceptionInfo, ExceptionWithTraceback\n",
    "from kombu import serialization\n",
    "from kombu.exceptions import OperationalError\n",
    "from kombu.utils.uuid import uuid\n",
    "\n",
    "from celery import current_app, states\n",
    "from celery._state import _task_stack\n",
    "from celery.canvas import _chain, group, signature\n",
    "from celery.exceptions import (\n",
    "    Ignore,\n",
    "    ImproperlyConfigured,\n",
    "    MaxRetriesExceededError,\n",
    "    Reject,\n",
    "    Retry,\n",
    ")\n",
    "from celery.local import class_property\n",
    "from celery.result import EagerResult, denied_join_result\n",
    "from celery.utils import abstract\n",
    "from celery.utils.functional import mattrgetter, maybe_list\n",
    "from celery.utils.imports import instantiate\n",
    "from celery.utils.nodenames import gethostname\n",
    "from celery.utils.serialization import raise_with_context\n",
    "\n",
    "from .annotations import resolve_all as resolve_all_annotations\n",
    "from .registry import _unpickle_task_v2\n",
    "from .utils import appstr\n",
    "\n",
    "__all__ = (\"Context\", \"Task\")\n",
    "\n",
    "#: extracts attributes related to publishing a message from an object.\n",
    "extract_exec_options = mattrgetter(\n",
    "    \"queue\",\n",
    "    \"routing_key\",\n",
    "    \"exchange\",\n",
    "    \"priority\",\n",
    "    \"expires\",\n",
    "    \"serializer\",\n",
    "    \"delivery_mode\",\n",
    "    \"compression\",\n",
    "    \"time_limit\",\n",
    "    \"soft_time_limit\",\n",
    "    \"immediate\",\n",
    "    \"mandatory\",  # imm+man is deprecated\n",
    ")\n",
    "\n",
    "# We take __repr__ very seriously around here ;)\n",
    "R_BOUND_TASK = \"<class {0.__name__} of {app}{flags}>\"\n",
    "R_UNBOUND_TASK = \"<unbound {0.__name__}{flags}>\"\n",
    "R_INSTANCE = \"<@task: {0.name} of {app}{flags}>\"\n",
    "\n",
    "#: Here for backwards compatibility as tasks no longer use a custom meta-class.\n",
    "TaskType = type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _strflags(flags, default=\"\"):\n",
    "    if flags:\n",
    "        return \" ({})\".format(\", \".join(flags))\n",
    "    return default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _reprtask(task, fmt=None, flags=None):\n",
    "    flags = list(flags) if flags is not None else []\n",
    "    flags.append(\"v2 compatible\") if task.__v2_compat__ else None\n",
    "    if not fmt:\n",
    "        fmt = R_BOUND_TASK if task._app else R_UNBOUND_TASK\n",
    "    return fmt.format(\n",
    "        task,\n",
    "        flags=_strflags(flags),\n",
    "        app=appstr(task._app) if task._app else None,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Context:\n",
    "    \"\"\"Task request variables (Task.request).\"\"\"\n",
    "\n",
    "    _children = None  # see property\n",
    "    _protected = 0\n",
    "    args = None\n",
    "    callbacks = None\n",
    "    called_directly = True\n",
    "    chain = None\n",
    "    chord = None\n",
    "    correlation_id = None\n",
    "    delivery_info = None\n",
    "    errbacks = None\n",
    "    eta = None\n",
    "    expires = None\n",
    "    group = None\n",
    "    group_index = None\n",
    "    headers = None\n",
    "    hostname = None\n",
    "    id = None\n",
    "    ignore_result = False\n",
    "    is_eager = False\n",
    "    kwargs = None\n",
    "    logfile = None\n",
    "    loglevel = None\n",
    "    origin = None\n",
    "    parent_id = None\n",
    "    properties = None\n",
    "    retries = 0\n",
    "    reply_to = None\n",
    "    replaced_task_nesting = 0\n",
    "    root_id = None\n",
    "    shadow = None\n",
    "    taskset = None  # compat alias to group\n",
    "    timelimit = None\n",
    "    utc = None\n",
    "    stamped_headers = None\n",
    "    stamps = None\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.update(*args, **kwargs)\n",
    "        if self.headers is None:\n",
    "            self.headers = self._get_custom_headers(*args, **kwargs)\n",
    "\n",
    "    def _get_custom_headers(self, *args, **kwargs):\n",
    "        headers = {}\n",
    "        headers.update(*args, **kwargs)\n",
    "        celery_keys = {\n",
    "            *Context.__dict__.keys(),\n",
    "            \"lang\",\n",
    "            \"task\",\n",
    "            \"argsrepr\",\n",
    "            \"kwargsrepr\",\n",
    "            \"compression\",\n",
    "        }\n",
    "        for key in celery_keys:\n",
    "            headers.pop(key, None)\n",
    "        if not headers:\n",
    "            return None\n",
    "        return headers\n",
    "\n",
    "    def update(self, *args, **kwargs):\n",
    "        return self.__dict__.update(*args, **kwargs)\n",
    "\n",
    "    def clear(self):\n",
    "        return self.__dict__.clear()\n",
    "\n",
    "    def get(self, key, default=None):\n",
    "        return getattr(self, key, default)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"<Context: {vars(self)!r}>\"\n",
    "\n",
    "    def as_execution_options(self):\n",
    "        limit_hard, limit_soft = self.timelimit or (None, None)\n",
    "        execution_options = {\n",
    "            \"task_id\": self.id,\n",
    "            \"root_id\": self.root_id,\n",
    "            \"parent_id\": self.parent_id,\n",
    "            \"group_id\": self.group,\n",
    "            \"group_index\": self.group_index,\n",
    "            \"shadow\": self.shadow,\n",
    "            \"chord\": self.chord,\n",
    "            \"chain\": self.chain,\n",
    "            \"link\": self.callbacks,\n",
    "            \"link_error\": self.errbacks,\n",
    "            \"expires\": self.expires,\n",
    "            \"soft_time_limit\": limit_soft,\n",
    "            \"time_limit\": limit_hard,\n",
    "            \"headers\": self.headers,\n",
    "            \"retries\": self.retries,\n",
    "            \"reply_to\": self.reply_to,\n",
    "            \"replaced_task_nesting\": self.replaced_task_nesting,\n",
    "            \"origin\": self.origin,\n",
    "        }\n",
    "        if hasattr(self, \"stamps\") and hasattr(self, \"stamped_headers\"):\n",
    "            if self.stamps is not None and self.stamped_headers is not None:\n",
    "                execution_options[\"stamped_headers\"] = self.stamped_headers\n",
    "                for k, v in self.stamps.items():\n",
    "                    execution_options[k] = v\n",
    "        return execution_options\n",
    "\n",
    "    @property\n",
    "    def children(self):\n",
    "        # children must be an empty list for every thread\n",
    "        if self._children is None:\n",
    "            self._children = []\n",
    "        return self._children"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@abstract.CallableTask.register\n",
    "class Task:\n",
    "    \"\"\"Task base class.\n",
    "\n",
    "    Note:\n",
    "        When called tasks apply the :meth:`run` method.  This method must\n",
    "        be defined by all tasks (that is unless the :meth:`__call__` method\n",
    "        is overridden).\n",
    "    \"\"\"\n",
    "\n",
    "    __trace__ = None\n",
    "    __v2_compat__ = False  # set by old base in celery.task.base\n",
    "\n",
    "    MaxRetriesExceededError = MaxRetriesExceededError\n",
    "    OperationalError = OperationalError\n",
    "\n",
    "    #: Execution strategy used, or the qualified name of one.\n",
    "    Strategy = \"celery.worker.strategy:default\"\n",
    "\n",
    "    #: Request class used, or the qualified name of one.\n",
    "    Request = \"celery.worker.request:Request\"\n",
    "\n",
    "    #: The application instance associated with this task class.\n",
    "    _app = None\n",
    "\n",
    "    #: Name of the task.\n",
    "    name = None\n",
    "\n",
    "    #: Enable argument checking.\n",
    "    #: You can set this to false if you don't want the signature to be\n",
    "    #: checked when calling the task.\n",
    "    #: Defaults to :attr:`app.strict_typing <@Celery.strict_typing>`.\n",
    "    typing = None\n",
    "\n",
    "    #: Maximum number of retries before giving up.  If set to :const:`None`,\n",
    "    #: it will **never** stop retrying.\n",
    "    max_retries = 3\n",
    "\n",
    "    #: Default time in seconds before a retry of the task should be\n",
    "    #: executed.  3 minutes by default.\n",
    "    default_retry_delay = 3 * 60\n",
    "\n",
    "    #: Rate limit for this task type.  Examples: :const:`None` (no rate\n",
    "    #: limit), `'100/s'` (hundred tasks a second), `'100/m'` (hundred tasks\n",
    "    #: a minute),`'100/h'` (hundred tasks an hour)\n",
    "    rate_limit = None\n",
    "\n",
    "    #: If enabled the worker won't store task state and return values\n",
    "    #: for this task.  Defaults to the :setting:`task_ignore_result`\n",
    "    #: setting.\n",
    "    ignore_result = None\n",
    "\n",
    "    #: If enabled the request will keep track of subtasks started by\n",
    "    #: this task, and this information will be sent with the result\n",
    "    #: (``result.children``).\n",
    "    trail = True\n",
    "\n",
    "    #: If enabled the worker will send monitoring events related to\n",
    "    #: this task (but only if the worker is configured to send\n",
    "    #: task related events).\n",
    "    #: Note that this has no effect on the task-failure event case\n",
    "    #: where a task is not registered (as it will have no task class\n",
    "    #: to check this flag).\n",
    "    send_events = True\n",
    "\n",
    "    #: When enabled errors will be stored even if the task is otherwise\n",
    "    #: configured to ignore results.\n",
    "    store_errors_even_if_ignored = None\n",
    "\n",
    "    #: The name of a serializer that are registered with\n",
    "    #: :mod:`kombu.serialization.registry`.  Default is `'json'`.\n",
    "    serializer = None\n",
    "\n",
    "    #: Hard time limit.\n",
    "    #: Defaults to the :setting:`task_time_limit` setting.\n",
    "    time_limit = None\n",
    "\n",
    "    #: Soft time limit.\n",
    "    #: Defaults to the :setting:`task_soft_time_limit` setting.\n",
    "    soft_time_limit = None\n",
    "\n",
    "    #: The result store backend used for this task.\n",
    "    backend = None\n",
    "\n",
    "    #: If enabled the task will report its status as 'started' when the task\n",
    "    #: is executed by a worker.  Disabled by default as the normal behavior\n",
    "    #: is to not report that level of granularity.  Tasks are either pending,\n",
    "    #: finished, or waiting to be retried.\n",
    "    #:\n",
    "    #: Having a 'started' status can be useful for when there are long\n",
    "    #: running tasks and there's a need to report what task is currently\n",
    "    #: running.\n",
    "    #:\n",
    "    #: The application default can be overridden using the\n",
    "    #: :setting:`task_track_started` setting.\n",
    "    track_started = None\n",
    "\n",
    "    #: When enabled messages for this task will be acknowledged **after**\n",
    "    #: the task has been executed, and not *right before* (the\n",
    "    #: default behavior).\n",
    "    #:\n",
    "    #: Please note that this means the task may be executed twice if the\n",
    "    #: worker crashes mid execution.\n",
    "    #:\n",
    "    #: The application default can be overridden with the\n",
    "    #: :setting:`task_acks_late` setting.\n",
    "    acks_late = None\n",
    "\n",
    "    #: When enabled messages for this task will be acknowledged even if it\n",
    "    #: fails or times out.\n",
    "    #:\n",
    "    #: Configuring this setting only applies to tasks that are\n",
    "    #: acknowledged **after** they have been executed and only if\n",
    "    #: :setting:`task_acks_late` is enabled.\n",
    "    #:\n",
    "    #: The application default can be overridden with the\n",
    "    #: :setting:`task_acks_on_failure_or_timeout` setting.\n",
    "    acks_on_failure_or_timeout = None\n",
    "\n",
    "    #: Even if :attr:`acks_late` is enabled, the worker will\n",
    "    #: acknowledge tasks when the worker process executing them abruptly\n",
    "    #: exits or is signaled (e.g., :sig:`KILL`/:sig:`INT`, etc).\n",
    "    #:\n",
    "    #: Setting this to true allows the message to be re-queued instead,\n",
    "    #: so that the task will execute again by the same worker, or another\n",
    "    #: worker.\n",
    "    #:\n",
    "    #: Warning: Enabling this can cause message loops; make sure you know\n",
    "    #: what you're doing.\n",
    "    reject_on_worker_lost = None\n",
    "\n",
    "    #: Tuple of expected exceptions.\n",
    "    #:\n",
    "    #: These are errors that are expected in normal operation\n",
    "    #: and that shouldn't be regarded as a real error by the worker.\n",
    "    #: Currently this means that the state will be updated to an error\n",
    "    #: state, but the worker won't log the event as an error.\n",
    "    throws = ()\n",
    "\n",
    "    #: Default task expiry time.\n",
    "    expires = None\n",
    "\n",
    "    #: Default task priority.\n",
    "    priority = None\n",
    "\n",
    "    #: Max length of result representation used in logs and events.\n",
    "    resultrepr_maxsize = 1024\n",
    "\n",
    "    #: Task request stack, the current request will be the topmost.\n",
    "    request_stack = None\n",
    "\n",
    "    #: Some may expect a request to exist even if the task hasn't been\n",
    "    #: called.  This should probably be deprecated.\n",
    "    _default_request = None\n",
    "\n",
    "    #: Deprecated attribute ``abstract`` here for compatibility.\n",
    "    abstract = True\n",
    "\n",
    "    _exec_options = None\n",
    "\n",
    "    __bound__ = False\n",
    "\n",
    "    from_config = (\n",
    "        (\"serializer\", \"task_serializer\"),\n",
    "        (\"rate_limit\", \"task_default_rate_limit\"),\n",
    "        (\"priority\", \"task_default_priority\"),\n",
    "        (\"track_started\", \"task_track_started\"),\n",
    "        (\"acks_late\", \"task_acks_late\"),\n",
    "        (\"acks_on_failure_or_timeout\", \"task_acks_on_failure_or_timeout\"),\n",
    "        (\"reject_on_worker_lost\", \"task_reject_on_worker_lost\"),\n",
    "        (\"ignore_result\", \"task_ignore_result\"),\n",
    "        (\"store_eager_result\", \"task_store_eager_result\"),\n",
    "        (\"store_errors_even_if_ignored\", \"task_store_errors_even_if_ignored\"),\n",
    "    )\n",
    "\n",
    "    _backend = None  # set by backend property.\n",
    "\n",
    "    # - Tasks are lazily bound, so that configuration is not set\n",
    "    # - until the task is actually used\n",
    "\n",
    "    @classmethod\n",
    "    def bind(cls, app):\n",
    "        was_bound, cls.__bound__ = cls.__bound__, True\n",
    "        cls._app = app\n",
    "        conf = app.conf\n",
    "        cls._exec_options = None  # clear option cache\n",
    "\n",
    "        if cls.typing is None:\n",
    "            cls.typing = app.strict_typing\n",
    "\n",
    "        for attr_name, config_name in cls.from_config:\n",
    "            if getattr(cls, attr_name, None) is None:\n",
    "                setattr(cls, attr_name, conf[config_name])\n",
    "\n",
    "        # decorate with annotations from config.\n",
    "        if not was_bound:\n",
    "            cls.annotate()\n",
    "\n",
    "            from celery.utils.threads import LocalStack\n",
    "\n",
    "            cls.request_stack = LocalStack()\n",
    "\n",
    "        # PeriodicTask uses this to add itself to the PeriodicTask schedule.\n",
    "        cls.on_bound(app)\n",
    "\n",
    "        return app\n",
    "\n",
    "    @classmethod\n",
    "    def on_bound(cls, app):\n",
    "        \"\"\"Called when the task is bound to an app.\n",
    "\n",
    "        Note:\n",
    "            This class method can be defined to do additional actions when\n",
    "            the task class is bound to an app.\n",
    "        \"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def _get_app(cls):\n",
    "        if cls._app is None:\n",
    "            cls._app = current_app\n",
    "        if not cls.__bound__:\n",
    "            # The app property's __set__  method is not called\n",
    "            # if Task.app is set (on the class), so must bind on use.\n",
    "            cls.bind(cls._app)\n",
    "        return cls._app\n",
    "\n",
    "    app = class_property(_get_app, bind)\n",
    "\n",
    "    @classmethod\n",
    "    def annotate(cls):\n",
    "        for d in resolve_all_annotations(cls.app.annotations, cls):\n",
    "            for key, value in d.items():\n",
    "                if key.startswith(\"@\"):\n",
    "                    cls.add_around(key[1:], value)\n",
    "                else:\n",
    "                    setattr(cls, key, value)\n",
    "\n",
    "    @classmethod\n",
    "    def add_around(cls, attr, around):\n",
    "        orig = getattr(cls, attr)\n",
    "        if getattr(orig, \"__wrapped__\", None):\n",
    "            orig = orig.__wrapped__\n",
    "        meth = around(orig)\n",
    "        meth.__wrapped__ = orig\n",
    "        setattr(cls, attr, meth)\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        _task_stack.push(self)\n",
    "        self.push_request(args=args, kwargs=kwargs)\n",
    "        try:\n",
    "            return self.run(*args, **kwargs)\n",
    "        finally:\n",
    "            self.pop_request()\n",
    "            _task_stack.pop()\n",
    "\n",
    "    def __reduce__(self):\n",
    "        # - tasks are pickled into the name of the task only, and the receiver\n",
    "        # - simply grabs it from the local registry.\n",
    "        # - in later versions the module of the task is also included,\n",
    "        # - and the receiving side tries to import that module so that\n",
    "        # - it will work even if the task hasn't been registered.\n",
    "        mod = type(self).__module__\n",
    "        mod = mod if mod and mod in sys.modules else None\n",
    "        return (_unpickle_task_v2, (self.name, mod), None)\n",
    "\n",
    "    def run(self, *args, **kwargs):\n",
    "        \"\"\"The body of the task executed by workers.\"\"\"\n",
    "        raise NotImplementedError(\"Tasks must define the run method.\")\n",
    "\n",
    "    def start_strategy(self, app, consumer, **kwargs):\n",
    "        return instantiate(self.Strategy, self, app, consumer, **kwargs)\n",
    "\n",
    "    def delay(self, *args, **kwargs):\n",
    "        \"\"\"Star argument version of :meth:`apply_async`.\n",
    "\n",
    "        Does not support the extra options enabled by :meth:`apply_async`.\n",
    "\n",
    "        Arguments:\n",
    "            *args (Any): Positional arguments passed on to the task.\n",
    "            **kwargs (Any): Keyword arguments passed on to the task.\n",
    "        Returns:\n",
    "            celery.result.AsyncResult: Future promise.\n",
    "        \"\"\"\n",
    "        return self.apply_async(args, kwargs)\n",
    "\n",
    "    def apply_async(\n",
    "        self,\n",
    "        args=None,\n",
    "        kwargs=None,\n",
    "        task_id=None,\n",
    "        producer=None,\n",
    "        link=None,\n",
    "        link_error=None,\n",
    "        shadow=None,\n",
    "        **options,\n",
    "    ):\n",
    "        \"\"\"Apply tasks asynchronously by sending a message.\n",
    "\n",
    "        Arguments:\n",
    "            args (Tuple): The positional arguments to pass on to the task.\n",
    "\n",
    "            kwargs (Dict): The keyword arguments to pass on to the task.\n",
    "\n",
    "            countdown (float): Number of seconds into the future that the\n",
    "                task should execute.  Defaults to immediate execution.\n",
    "\n",
    "            eta (~datetime.datetime): Absolute time and date of when the task\n",
    "                should be executed.  May not be specified if `countdown`\n",
    "                is also supplied.\n",
    "\n",
    "            expires (float, ~datetime.datetime): Datetime or\n",
    "                seconds in the future for the task should expire.\n",
    "                The task won't be executed after the expiration time.\n",
    "\n",
    "            shadow (str): Override task name used in logs/monitoring.\n",
    "                Default is retrieved from :meth:`shadow_name`.\n",
    "\n",
    "            connection (kombu.Connection): Re-use existing broker connection\n",
    "                instead of acquiring one from the connection pool.\n",
    "\n",
    "            retry (bool): If enabled sending of the task message will be\n",
    "                retried in the event of connection loss or failure.\n",
    "                Default is taken from the :setting:`task_publish_retry`\n",
    "                setting.  Note that you need to handle the\n",
    "                producer/connection manually for this to work.\n",
    "\n",
    "            retry_policy (Mapping): Override the retry policy used.\n",
    "                See the :setting:`task_publish_retry_policy` setting.\n",
    "\n",
    "            time_limit (int): If set, overrides the default time limit.\n",
    "\n",
    "            soft_time_limit (int): If set, overrides the default soft\n",
    "                time limit.\n",
    "\n",
    "            queue (str, kombu.Queue): The queue to route the task to.\n",
    "                This must be a key present in :setting:`task_queues`, or\n",
    "                :setting:`task_create_missing_queues` must be\n",
    "                enabled.  See :ref:`guide-routing` for more\n",
    "                information.\n",
    "\n",
    "            exchange (str, kombu.Exchange): Named custom exchange to send the\n",
    "                task to.  Usually not used in combination with the ``queue``\n",
    "                argument.\n",
    "\n",
    "            routing_key (str): Custom routing key used to route the task to a\n",
    "                worker server.  If in combination with a ``queue`` argument\n",
    "                only used to specify custom routing keys to topic exchanges.\n",
    "\n",
    "            priority (int): The task priority, a number between 0 and 9.\n",
    "                Defaults to the :attr:`priority` attribute.\n",
    "\n",
    "            serializer (str): Serialization method to use.\n",
    "                Can be `pickle`, `json`, `yaml`, `msgpack` or any custom\n",
    "                serialization method that's been registered\n",
    "                with :mod:`kombu.serialization.registry`.\n",
    "                Defaults to the :attr:`serializer` attribute.\n",
    "\n",
    "            compression (str): Optional compression method\n",
    "                to use.  Can be one of ``zlib``, ``bzip2``,\n",
    "                or any custom compression methods registered with\n",
    "                :func:`kombu.compression.register`.\n",
    "                Defaults to the :setting:`task_compression` setting.\n",
    "\n",
    "            link (Signature): A single, or a list of tasks signatures\n",
    "                to apply if the task returns successfully.\n",
    "\n",
    "            link_error (Signature): A single, or a list of task signatures\n",
    "                to apply if an error occurs while executing the task.\n",
    "\n",
    "            producer (kombu.Producer): custom producer to use when publishing\n",
    "                the task.\n",
    "\n",
    "            add_to_parent (bool): If set to True (default) and the task\n",
    "                is applied while executing another task, then the result\n",
    "                will be appended to the parent tasks ``request.children``\n",
    "                attribute.  Trailing can also be disabled by default using the\n",
    "                :attr:`trail` attribute\n",
    "\n",
    "            ignore_result (bool): If set to `False` (default) the result\n",
    "                of a task will be stored in the backend. If set to `True`\n",
    "                the result will not be stored. This can also be set\n",
    "                using the :attr:`ignore_result` in the `app.task` decorator.\n",
    "\n",
    "            publisher (kombu.Producer): Deprecated alias to ``producer``.\n",
    "\n",
    "            headers (Dict): Message headers to be included in the message.\n",
    "\n",
    "        Returns:\n",
    "            celery.result.AsyncResult: Promise of future evaluation.\n",
    "\n",
    "        Raises:\n",
    "            TypeError: If not enough arguments are passed, or too many\n",
    "                arguments are passed.  Note that signature checks may\n",
    "                be disabled by specifying ``@task(typing=False)``.\n",
    "            kombu.exceptions.OperationalError: If a connection to the\n",
    "               transport cannot be made, or if the connection is lost.\n",
    "\n",
    "        Note:\n",
    "            Also supports all keyword arguments supported by\n",
    "            :meth:`kombu.Producer.publish`.\n",
    "        \"\"\"\n",
    "        if self.typing:\n",
    "            try:\n",
    "                check_arguments = self.__header__\n",
    "            except AttributeError:  # pragma: no cover\n",
    "                pass\n",
    "            else:\n",
    "                check_arguments(*(args or ()), **(kwargs or {}))\n",
    "\n",
    "        if self.__v2_compat__:\n",
    "            shadow = shadow or self.shadow_name(self(), args, kwargs, options)\n",
    "        else:\n",
    "            shadow = shadow or self.shadow_name(args, kwargs, options)\n",
    "\n",
    "        preopts = self._get_exec_options()\n",
    "        options = dict(preopts, **options) if options else preopts\n",
    "\n",
    "        options.setdefault(\"ignore_result\", self.ignore_result)\n",
    "        if self.priority:\n",
    "            options.setdefault(\"priority\", self.priority)\n",
    "\n",
    "        app = self._get_app()\n",
    "        if app.conf.task_always_eager:\n",
    "            with app.producer_or_acquire(producer) as eager_producer:\n",
    "                serializer = options.get(\"serializer\")\n",
    "                if serializer is None:\n",
    "                    if eager_producer.serializer:\n",
    "                        serializer = eager_producer.serializer\n",
    "                    else:\n",
    "                        serializer = app.conf.task_serializer\n",
    "                body = args, kwargs\n",
    "                content_type, content_encoding, data = serialization.dumps(\n",
    "                    body,\n",
    "                    serializer,\n",
    "                )\n",
    "                args, kwargs = serialization.loads(\n",
    "                    data, content_type, content_encoding, accept=[content_type]\n",
    "                )\n",
    "            with denied_join_result():\n",
    "                return self.apply(\n",
    "                    args,\n",
    "                    kwargs,\n",
    "                    task_id=task_id or uuid(),\n",
    "                    link=link,\n",
    "                    link_error=link_error,\n",
    "                    **options,\n",
    "                )\n",
    "        else:\n",
    "            return app.send_task(\n",
    "                self.name,\n",
    "                args,\n",
    "                kwargs,\n",
    "                task_id=task_id,\n",
    "                producer=producer,\n",
    "                link=link,\n",
    "                link_error=link_error,\n",
    "                result_cls=self.AsyncResult,\n",
    "                shadow=shadow,\n",
    "                task_type=self,\n",
    "                **options,\n",
    "            )\n",
    "\n",
    "    def shadow_name(self, args, kwargs, options):\n",
    "        \"\"\"Override for custom task name in worker logs/monitoring.\n",
    "\n",
    "        Example:\n",
    "            .. code-block:: python\n",
    "\n",
    "                from celery.utils.imports import qualname\n",
    "\n",
    "                def shadow_name(task, args, kwargs, options):\n",
    "                    return qualname(args[0])\n",
    "\n",
    "                @app.task(shadow_name=shadow_name, serializer='pickle')\n",
    "                def apply_function_async(fun, *args, **kwargs):\n",
    "                    return fun(*args, **kwargs)\n",
    "\n",
    "        Arguments:\n",
    "            args (Tuple): Task positional arguments.\n",
    "            kwargs (Dict): Task keyword arguments.\n",
    "            options (Dict): Task execution options.\n",
    "        \"\"\"\n",
    "\n",
    "    def signature_from_request(\n",
    "        self, request=None, args=None, kwargs=None, queue=None, **extra_options\n",
    "    ):\n",
    "        request = self.request if request is None else request\n",
    "        args = request.args if args is None else args\n",
    "        kwargs = request.kwargs if kwargs is None else kwargs\n",
    "        options = {**request.as_execution_options(), **extra_options}\n",
    "        delivery_info = request.delivery_info or {}\n",
    "        priority = delivery_info.get(\"priority\")\n",
    "        if priority is not None:\n",
    "            options[\"priority\"] = priority\n",
    "        if queue:\n",
    "            options[\"queue\"] = queue\n",
    "        else:\n",
    "            exchange = delivery_info.get(\"exchange\")\n",
    "            routing_key = delivery_info.get(\"routing_key\")\n",
    "            if exchange == \"\" and routing_key:\n",
    "                # sent to anon-exchange\n",
    "                options[\"queue\"] = routing_key\n",
    "            else:\n",
    "                options.update(delivery_info)\n",
    "        return self.signature(args, kwargs, options, type=self, **extra_options)\n",
    "\n",
    "    subtask_from_request = signature_from_request  # XXX compat\n",
    "\n",
    "    def retry(\n",
    "        self,\n",
    "        args=None,\n",
    "        kwargs=None,\n",
    "        exc=None,\n",
    "        throw=True,\n",
    "        eta=None,\n",
    "        countdown=None,\n",
    "        max_retries=None,\n",
    "        **options,\n",
    "    ):\n",
    "        \"\"\"Retry the task, adding it to the back of the queue.\n",
    "\n",
    "        Example:\n",
    "            >>> from imaginary_twitter_lib import Twitter\n",
    "            >>> from proj.celery import app\n",
    "\n",
    "            >>> @app.task(bind=True)\n",
    "            ... def tweet(self, auth, message):\n",
    "            ...     twitter = Twitter(oauth=auth)\n",
    "            ...     try:\n",
    "            ...         twitter.post_status_update(message)\n",
    "            ...     except twitter.FailWhale as exc:\n",
    "            ...         # Retry in 5 minutes.\n",
    "            ...         raise self.retry(countdown=60 * 5, exc=exc)\n",
    "\n",
    "        Note:\n",
    "            Although the task will never return above as `retry` raises an\n",
    "            exception to notify the worker, we use `raise` in front of the\n",
    "            retry to convey that the rest of the block won't be executed.\n",
    "\n",
    "        Arguments:\n",
    "            args (Tuple): Positional arguments to retry with.\n",
    "            kwargs (Dict): Keyword arguments to retry with.\n",
    "            exc (Exception): Custom exception to report when the max retry\n",
    "                limit has been exceeded (default:\n",
    "                :exc:`~@MaxRetriesExceededError`).\n",
    "\n",
    "                If this argument is set and retry is called while\n",
    "                an exception was raised (``sys.exc_info()`` is set)\n",
    "                it will attempt to re-raise the current exception.\n",
    "\n",
    "                If no exception was raised it will raise the ``exc``\n",
    "                argument provided.\n",
    "            countdown (float): Time in seconds to delay the retry for.\n",
    "            eta (~datetime.datetime): Explicit time and date to run the\n",
    "                retry at.\n",
    "            max_retries (int): If set, overrides the default retry limit for\n",
    "                this execution.  Changes to this parameter don't propagate to\n",
    "                subsequent task retry attempts.  A value of :const:`None`,\n",
    "                means \"use the default\", so if you want infinite retries you'd\n",
    "                have to set the :attr:`max_retries` attribute of the task to\n",
    "                :const:`None` first.\n",
    "            time_limit (int): If set, overrides the default time limit.\n",
    "            soft_time_limit (int): If set, overrides the default soft\n",
    "                time limit.\n",
    "            throw (bool): If this is :const:`False`, don't raise the\n",
    "                :exc:`~@Retry` exception, that tells the worker to mark\n",
    "                the task as being retried.  Note that this means the task\n",
    "                will be marked as failed if the task raises an exception,\n",
    "                or successful if it returns after the retry call.\n",
    "            **options (Any): Extra options to pass on to :meth:`apply_async`.\n",
    "\n",
    "        Raises:\n",
    "\n",
    "            celery.exceptions.Retry:\n",
    "                To tell the worker that the task has been re-sent for retry.\n",
    "                This always happens, unless the `throw` keyword argument\n",
    "                has been explicitly set to :const:`False`, and is considered\n",
    "                normal operation.\n",
    "        \"\"\"\n",
    "        request = self.request\n",
    "        retries = request.retries + 1\n",
    "        if max_retries is not None:\n",
    "            self.override_max_retries = max_retries\n",
    "        max_retries = self.max_retries if max_retries is None else max_retries\n",
    "\n",
    "        # Not in worker or emulated by (apply/always_eager),\n",
    "        # so just raise the original exception.\n",
    "        if request.called_directly:\n",
    "            # raises orig stack if PyErr_Occurred,\n",
    "            # and augments with exc' if that argument is defined.\n",
    "            raise_with_context(exc or Retry(\"Task can be retried\", None))\n",
    "\n",
    "        if not eta and countdown is None:\n",
    "            countdown = self.default_retry_delay\n",
    "\n",
    "        is_eager = request.is_eager\n",
    "        S = self.signature_from_request(\n",
    "            request,\n",
    "            args,\n",
    "            kwargs,\n",
    "            countdown=countdown,\n",
    "            eta=eta,\n",
    "            retries=retries,\n",
    "            **options,\n",
    "        )\n",
    "\n",
    "        if max_retries is not None and retries > max_retries:\n",
    "            if exc:\n",
    "                # On Py3: will augment any current exception with\n",
    "                # the exc' argument provided (raise exc from orig)\n",
    "                raise_with_context(exc)\n",
    "            raise self.MaxRetriesExceededError(\n",
    "                \"Can't retry {}[{}] args:{} kwargs:{}\".format(\n",
    "                    self.name, request.id, S.args, S.kwargs\n",
    "                ),\n",
    "                task_args=S.args,\n",
    "                task_kwargs=S.kwargs,\n",
    "            )\n",
    "\n",
    "        ret = Retry(exc=exc, when=eta or countdown, is_eager=is_eager, sig=S)\n",
    "\n",
    "        if is_eager:\n",
    "            # if task was executed eagerly using apply(),\n",
    "            # then the retry must also be executed eagerly in apply method\n",
    "            if throw:\n",
    "                raise ret\n",
    "            return ret\n",
    "\n",
    "        try:\n",
    "            S.apply_async()\n",
    "        except Exception as exc:\n",
    "            raise Reject(exc, requeue=False)\n",
    "        if throw:\n",
    "            raise ret\n",
    "        return ret\n",
    "\n",
    "    def apply(\n",
    "        self,\n",
    "        args=None,\n",
    "        kwargs=None,\n",
    "        link=None,\n",
    "        link_error=None,\n",
    "        task_id=None,\n",
    "        retries=None,\n",
    "        throw=None,\n",
    "        logfile=None,\n",
    "        loglevel=None,\n",
    "        headers=None,\n",
    "        **options,\n",
    "    ):\n",
    "        \"\"\"Execute this task locally, by blocking until the task returns.\n",
    "\n",
    "        Arguments:\n",
    "            args (Tuple): positional arguments passed on to the task.\n",
    "            kwargs (Dict): keyword arguments passed on to the task.\n",
    "            throw (bool): Re-raise task exceptions.\n",
    "                Defaults to the :setting:`task_eager_propagates` setting.\n",
    "\n",
    "        Returns:\n",
    "            celery.result.EagerResult: pre-evaluated result.\n",
    "        \"\"\"\n",
    "        # trace imports Task, so need to import inline.\n",
    "        from celery.app.trace import build_tracer\n",
    "\n",
    "        app = self._get_app()\n",
    "        args = args or ()\n",
    "        kwargs = kwargs or {}\n",
    "        task_id = task_id or uuid()\n",
    "        retries = retries or 0\n",
    "        if throw is None:\n",
    "            throw = app.conf.task_eager_propagates\n",
    "\n",
    "        # Make sure we get the task instance, not class.\n",
    "        task = app._tasks[self.name]\n",
    "\n",
    "        request = {\n",
    "            \"id\": task_id,\n",
    "            \"task\": self.name,\n",
    "            \"retries\": retries,\n",
    "            \"is_eager\": True,\n",
    "            \"logfile\": logfile,\n",
    "            \"loglevel\": loglevel or 0,\n",
    "            \"hostname\": gethostname(),\n",
    "            \"callbacks\": maybe_list(link),\n",
    "            \"errbacks\": maybe_list(link_error),\n",
    "            \"headers\": headers,\n",
    "            \"ignore_result\": options.get(\"ignore_result\", False),\n",
    "            \"delivery_info\": {\n",
    "                \"is_eager\": True,\n",
    "                \"exchange\": options.get(\"exchange\"),\n",
    "                \"routing_key\": options.get(\"routing_key\"),\n",
    "                \"priority\": options.get(\"priority\"),\n",
    "            },\n",
    "        }\n",
    "        if \"stamped_headers\" in options:\n",
    "            request[\"stamped_headers\"] = maybe_list(options[\"stamped_headers\"])\n",
    "            request[\"stamps\"] = {\n",
    "                header: maybe_list(options.get(header, []))\n",
    "                for header in request[\"stamped_headers\"]\n",
    "            }\n",
    "\n",
    "        tb = None\n",
    "        tracer = build_tracer(\n",
    "            task.name,\n",
    "            task,\n",
    "            eager=True,\n",
    "            propagate=throw,\n",
    "            app=self._get_app(),\n",
    "        )\n",
    "        ret = tracer(task_id, args, kwargs, request)\n",
    "        retval = ret.retval\n",
    "        if isinstance(retval, ExceptionInfo):\n",
    "            retval, tb = retval.exception, retval.traceback\n",
    "            if isinstance(retval, ExceptionWithTraceback):\n",
    "                retval = retval.exc\n",
    "        if isinstance(retval, Retry) and retval.sig is not None:\n",
    "            return retval.sig.apply(retries=retries + 1)\n",
    "        state = states.SUCCESS if ret.info is None else ret.info.state\n",
    "        return EagerResult(task_id, retval, state, traceback=tb, name=self.name)\n",
    "\n",
    "    def AsyncResult(self, task_id, **kwargs):\n",
    "        \"\"\"Get AsyncResult instance for the specified task.\n",
    "\n",
    "        Arguments:\n",
    "            task_id (str): Task id to get result for.\n",
    "        \"\"\"\n",
    "        return self._get_app().AsyncResult(\n",
    "            task_id, backend=self.backend, task_name=self.name, **kwargs\n",
    "        )\n",
    "\n",
    "    def signature(self, args=None, *starargs, **starkwargs):\n",
    "        \"\"\"Create signature.\n",
    "\n",
    "        Returns:\n",
    "            :class:`~celery.signature`:  object for\n",
    "                this task, wrapping arguments and execution options\n",
    "                for a single task invocation.\n",
    "        \"\"\"\n",
    "        starkwargs.setdefault(\"app\", self.app)\n",
    "        return signature(self, args, *starargs, **starkwargs)\n",
    "\n",
    "    subtask = signature\n",
    "\n",
    "    def s(self, *args, **kwargs):\n",
    "        \"\"\"Create signature.\n",
    "\n",
    "        Shortcut for ``.s(*a, **k) -> .signature(a, k)``.\n",
    "        \"\"\"\n",
    "        return self.signature(args, kwargs)\n",
    "\n",
    "    def si(self, *args, **kwargs):\n",
    "        \"\"\"Create immutable signature.\n",
    "\n",
    "        Shortcut for ``.si(*a, **k) -> .signature(a, k, immutable=True)``.\n",
    "        \"\"\"\n",
    "        return self.signature(args, kwargs, immutable=True)\n",
    "\n",
    "    def chunks(self, it, n):\n",
    "        \"\"\"Create a :class:`~celery.canvas.chunks` task for this task.\"\"\"\n",
    "        from celery import chunks\n",
    "\n",
    "        return chunks(self.s(), it, n, app=self.app)\n",
    "\n",
    "    def map(self, it):\n",
    "        \"\"\"Create a :class:`~celery.canvas.xmap` task from ``it``.\"\"\"\n",
    "        from celery import xmap\n",
    "\n",
    "        return xmap(self.s(), it, app=self.app)\n",
    "\n",
    "    def starmap(self, it):\n",
    "        \"\"\"Create a :class:`~celery.canvas.xstarmap` task from ``it``.\"\"\"\n",
    "        from celery import xstarmap\n",
    "\n",
    "        return xstarmap(self.s(), it, app=self.app)\n",
    "\n",
    "    def send_event(self, type_, retry=True, retry_policy=None, **fields):\n",
    "        \"\"\"Send monitoring event message.\n",
    "\n",
    "        This can be used to add custom event types in :pypi:`Flower`\n",
    "        and other monitors.\n",
    "\n",
    "        Arguments:\n",
    "            type_ (str):  Type of event, e.g. ``\"task-failed\"``.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            retry (bool):  Retry sending the message\n",
    "                if the connection is lost.  Default is taken from the\n",
    "                :setting:`task_publish_retry` setting.\n",
    "            retry_policy (Mapping): Retry settings.  Default is taken\n",
    "                from the :setting:`task_publish_retry_policy` setting.\n",
    "            **fields (Any): Map containing information about the event.\n",
    "                Must be JSON serializable.\n",
    "        \"\"\"\n",
    "        req = self.request\n",
    "        if retry_policy is None:\n",
    "            retry_policy = self.app.conf.task_publish_retry_policy\n",
    "        with self.app.events.default_dispatcher(hostname=req.hostname) as d:\n",
    "            return d.send(\n",
    "                type_, uuid=req.id, retry=retry, retry_policy=retry_policy, **fields\n",
    "            )\n",
    "\n",
    "    def replace(self, sig):\n",
    "        \"\"\"Replace this task, with a new task inheriting the task id.\n",
    "\n",
    "        Execution of the host task ends immediately and no subsequent statements\n",
    "        will be run.\n",
    "\n",
    "        .. versionadded:: 4.0\n",
    "\n",
    "        Arguments:\n",
    "            sig (Signature): signature to replace with.\n",
    "            visitor (StampingVisitor): Visitor API object.\n",
    "\n",
    "        Raises:\n",
    "            ~@Ignore: This is always raised when called in asynchronous context.\n",
    "            It is best to always use ``return self.replace(...)`` to convey\n",
    "            to the reader that the task won't continue after being replaced.\n",
    "        \"\"\"\n",
    "        chord = self.request.chord\n",
    "        if \"chord\" in sig.options:\n",
    "            raise ImproperlyConfigured(\n",
    "                \"A signature replacing a task must not be part of a chord\"\n",
    "            )\n",
    "        if isinstance(sig, _chain) and not getattr(sig, \"tasks\", True):\n",
    "            raise ImproperlyConfigured(\"Cannot replace with an empty chain\")\n",
    "\n",
    "        # Ensure callbacks or errbacks from the replaced signature are retained\n",
    "        if isinstance(sig, group):\n",
    "            # Groups get uplifted to a chord so that we can link onto the body\n",
    "            sig |= self.app.tasks[\"celery.accumulate\"].s(index=0)\n",
    "        for callback in maybe_list(self.request.callbacks) or []:\n",
    "            sig.link(callback)\n",
    "        for errback in maybe_list(self.request.errbacks) or []:\n",
    "            sig.link_error(errback)\n",
    "        # If the replacement signature is a chain, we need to push callbacks\n",
    "        # down to the final task so they run at the right time even if we\n",
    "        # proceed to link further tasks from the original request below\n",
    "        if isinstance(sig, _chain) and \"link\" in sig.options:\n",
    "            final_task_links = sig.tasks[-1].options.setdefault(\"link\", [])\n",
    "            final_task_links.extend(maybe_list(sig.options[\"link\"]))\n",
    "        # We need to freeze the replacement signature with the current task's\n",
    "        # ID to ensure that we don't disassociate it from the existing task IDs\n",
    "        # which would break previously constructed results objects.\n",
    "        sig.freeze(self.request.id)\n",
    "        # Ensure the important options from the original signature are retained\n",
    "        replaced_task_nesting = self.request.get(\"replaced_task_nesting\", 0) + 1\n",
    "        sig.set(\n",
    "            chord=chord,\n",
    "            group_id=self.request.group,\n",
    "            group_index=self.request.group_index,\n",
    "            root_id=self.request.root_id,\n",
    "            replaced_task_nesting=replaced_task_nesting,\n",
    "        )\n",
    "\n",
    "        # If the replaced task is a chain, we want to set all of the chain tasks\n",
    "        # with the same replaced_task_nesting value to mark their replacement nesting level\n",
    "        if isinstance(sig, _chain):\n",
    "            for chain_task in maybe_list(sig.tasks) or []:\n",
    "                chain_task.set(replaced_task_nesting=replaced_task_nesting)\n",
    "\n",
    "        # If the task being replaced is part of a chain, we need to re-create\n",
    "        # it with the replacement signature - these subsequent tasks will\n",
    "        # retain their original task IDs as well\n",
    "        for t in reversed(self.request.chain or []):\n",
    "            chain_task = signature(t, app=self.app)\n",
    "            chain_task.set(replaced_task_nesting=replaced_task_nesting)\n",
    "            sig |= chain_task\n",
    "        return self.on_replace(sig)\n",
    "\n",
    "    def add_to_chord(self, sig, lazy=False):\n",
    "        \"\"\"Add signature to the chord the current task is a member of.\n",
    "\n",
    "        .. versionadded:: 4.0\n",
    "\n",
    "        Currently only supported by the Redis result backend.\n",
    "\n",
    "        Arguments:\n",
    "            sig (Signature): Signature to extend chord with.\n",
    "            lazy (bool): If enabled the new task won't actually be called,\n",
    "                and ``sig.delay()`` must be called manually.\n",
    "        \"\"\"\n",
    "        if not self.request.chord:\n",
    "            raise ValueError(\"Current task is not member of any chord\")\n",
    "        sig.set(\n",
    "            group_id=self.request.group,\n",
    "            group_index=self.request.group_index,\n",
    "            chord=self.request.chord,\n",
    "            root_id=self.request.root_id,\n",
    "        )\n",
    "        result = sig.freeze()\n",
    "        self.backend.add_to_chord(self.request.group, result)\n",
    "        return sig.delay() if not lazy else sig\n",
    "\n",
    "    def update_state(self, task_id=None, state=None, meta=None, **kwargs):\n",
    "        \"\"\"Update task state.\n",
    "\n",
    "        Arguments:\n",
    "            task_id (str): Id of the task to update.\n",
    "                Defaults to the id of the current task.\n",
    "            state (str): New state.\n",
    "            meta (Dict): State meta-data.\n",
    "        \"\"\"\n",
    "        if task_id is None:\n",
    "            task_id = self.request.id\n",
    "        self.backend.store_result(task_id, meta, state, request=self.request, **kwargs)\n",
    "\n",
    "    def before_start(self, task_id, args, kwargs):\n",
    "        \"\"\"Handler called before the task starts.\n",
    "\n",
    "        .. versionadded:: 5.2\n",
    "\n",
    "        Arguments:\n",
    "            task_id (str): Unique id of the task to execute.\n",
    "            args (Tuple): Original arguments for the task to execute.\n",
    "            kwargs (Dict): Original keyword arguments for the task to execute.\n",
    "\n",
    "        Returns:\n",
    "            None: The return value of this handler is ignored.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_success(self, retval, task_id, args, kwargs):\n",
    "        \"\"\"Success handler.\n",
    "\n",
    "        Run by the worker if the task executes successfully.\n",
    "\n",
    "        Arguments:\n",
    "            retval (Any): The return value of the task.\n",
    "            task_id (str): Unique id of the executed task.\n",
    "            args (Tuple): Original arguments for the executed task.\n",
    "            kwargs (Dict): Original keyword arguments for the executed task.\n",
    "\n",
    "        Returns:\n",
    "            None: The return value of this handler is ignored.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_retry(self, exc, task_id, args, kwargs, einfo):\n",
    "        \"\"\"Retry handler.\n",
    "\n",
    "        This is run by the worker when the task is to be retried.\n",
    "\n",
    "        Arguments:\n",
    "            exc (Exception): The exception sent to :meth:`retry`.\n",
    "            task_id (str): Unique id of the retried task.\n",
    "            args (Tuple): Original arguments for the retried task.\n",
    "            kwargs (Dict): Original keyword arguments for the retried task.\n",
    "            einfo (~billiard.einfo.ExceptionInfo): Exception information.\n",
    "\n",
    "        Returns:\n",
    "            None: The return value of this handler is ignored.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_failure(self, exc, task_id, args, kwargs, einfo):\n",
    "        \"\"\"Error handler.\n",
    "\n",
    "        This is run by the worker when the task fails.\n",
    "\n",
    "        Arguments:\n",
    "            exc (Exception): The exception raised by the task.\n",
    "            task_id (str): Unique id of the failed task.\n",
    "            args (Tuple): Original arguments for the task that failed.\n",
    "            kwargs (Dict): Original keyword arguments for the task that failed.\n",
    "            einfo (~billiard.einfo.ExceptionInfo): Exception information.\n",
    "\n",
    "        Returns:\n",
    "            None: The return value of this handler is ignored.\n",
    "        \"\"\"\n",
    "\n",
    "    def after_return(self, status, retval, task_id, args, kwargs, einfo):\n",
    "        \"\"\"Handler called after the task returns.\n",
    "\n",
    "        Arguments:\n",
    "            status (str): Current task state.\n",
    "            retval (Any): Task return value/exception.\n",
    "            task_id (str): Unique id of the task.\n",
    "            args (Tuple): Original arguments for the task.\n",
    "            kwargs (Dict): Original keyword arguments for the task.\n",
    "            einfo (~billiard.einfo.ExceptionInfo): Exception information.\n",
    "\n",
    "        Returns:\n",
    "            None: The return value of this handler is ignored.\n",
    "        \"\"\"\n",
    "\n",
    "    def on_replace(self, sig):\n",
    "        \"\"\"Handler called when the task is replaced.\n",
    "\n",
    "        Must return super().on_replace(sig) when overriding to ensure the task replacement\n",
    "        is properly handled.\n",
    "\n",
    "        .. versionadded:: 5.3\n",
    "\n",
    "        Arguments:\n",
    "            sig (Signature): signature to replace with.\n",
    "        \"\"\"\n",
    "        # Finally, either apply or delay the new signature!\n",
    "        if self.request.is_eager:\n",
    "            return sig.apply().get()\n",
    "        else:\n",
    "            sig.delay()\n",
    "            raise Ignore(\"Replaced by new task\")\n",
    "\n",
    "    def add_trail(self, result):\n",
    "        if self.trail:\n",
    "            self.request.children.append(result)\n",
    "        return result\n",
    "\n",
    "    def push_request(self, *args, **kwargs):\n",
    "        self.request_stack.push(Context(*args, **kwargs))\n",
    "\n",
    "    def pop_request(self):\n",
    "        self.request_stack.pop()\n",
    "\n",
    "    def __repr__(self):\n",
    "        \"\"\"``repr(task)``.\"\"\"\n",
    "        return _reprtask(self, R_INSTANCE)\n",
    "\n",
    "    def _get_request(self):\n",
    "        \"\"\"Get current request object.\"\"\"\n",
    "        req = self.request_stack.top\n",
    "        if req is None:\n",
    "            # task was not called, but some may still expect a request\n",
    "            # to be there, perhaps that should be deprecated.\n",
    "            if self._default_request is None:\n",
    "                self._default_request = Context()\n",
    "            return self._default_request\n",
    "        return req\n",
    "\n",
    "    request = property(_get_request)\n",
    "\n",
    "    def _get_exec_options(self):\n",
    "        if self._exec_options is None:\n",
    "            self._exec_options = extract_exec_options(self)\n",
    "        return self._exec_options\n",
    "\n",
    "    @property\n",
    "    def backend(self):  # noqa: F811\n",
    "        backend = self._backend\n",
    "        if backend is None:\n",
    "            return self.app.backend\n",
    "        return backend\n",
    "\n",
    "    @backend.setter\n",
    "    def backend(self, value):\n",
    "        self._backend = value\n",
    "\n",
    "    @property\n",
    "    def __name__(self):\n",
    "        return self.__class__.__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BaseTask = Task  # XXX compat alias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}