{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Embedded workers for integration tests.\"\"\"\n",
    "import logging\n",
    "import os\n",
    "import threading\n",
    "from contextlib import contextmanager\n",
    "from typing import Any, Iterable, Optional, Union\n",
    "\n",
    "import celery.worker.consumer  # noqa\n",
    "from celery import Celery, worker\n",
    "from celery.result import _set_task_join_will_block, allow_join_result\n",
    "from celery.utils.dispatch import Signal\n",
    "from celery.utils.nodenames import anon_nodename\n",
    "\n",
    "WORKER_LOGLEVEL = os.environ.get(\"WORKER_LOGLEVEL\", \"error\")\n",
    "\n",
    "test_worker_starting = Signal(\n",
    "    name=\"test_worker_starting\",\n",
    "    providing_args={},\n",
    ")\n",
    "test_worker_started = Signal(\n",
    "    name=\"test_worker_started\",\n",
    "    providing_args={\"worker\", \"consumer\"},\n",
    ")\n",
    "test_worker_stopped = Signal(\n",
    "    name=\"test_worker_stopped\",\n",
    "    providing_args={\"worker\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestWorkController(worker.WorkController):\n",
    "    \"\"\"Worker that can synchronize on being fully started.\"\"\"\n",
    "\n",
    "    logger_queue = None\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        # type: (*Any, **Any) -> None\n",
    "        self._on_started = threading.Event()\n",
    "\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        if self.pool_cls.__module__.split(\".\")[-1] == \"prefork\":\n",
    "            from billiard import Queue\n",
    "\n",
    "            self.logger_queue = Queue()\n",
    "            self.pid = os.getpid()\n",
    "\n",
    "            try:\n",
    "                from tblib import pickling_support\n",
    "\n",
    "                pickling_support.install()\n",
    "            except ImportError:\n",
    "                pass\n",
    "\n",
    "            # collect logs from forked process.\n",
    "            # XXX: those logs will appear twice in the live log\n",
    "            self.queue_listener = logging.handlers.QueueListener(\n",
    "                self.logger_queue, logging.getLogger()\n",
    "            )\n",
    "            self.queue_listener.start()\n",
    "\n",
    "    class QueueHandler(logging.handlers.QueueHandler):\n",
    "        def prepare(self, record):\n",
    "            record.from_queue = True\n",
    "            # Keep origin record.\n",
    "            return record\n",
    "\n",
    "        def handleError(self, record):\n",
    "            if logging.raiseExceptions:\n",
    "                raise\n",
    "\n",
    "    def start(self):\n",
    "        if self.logger_queue:\n",
    "            handler = self.QueueHandler(self.logger_queue)\n",
    "            handler.addFilter(\n",
    "                lambda r: r.process != self.pid and not getattr(r, \"from_queue\", False)\n",
    "            )\n",
    "            logger = logging.getLogger()\n",
    "            logger.addHandler(handler)\n",
    "        return super().start()\n",
    "\n",
    "    def on_consumer_ready(self, consumer):\n",
    "        # type: (celery.worker.consumer.Consumer) -> None\n",
    "        \"\"\"Callback called when the Consumer blueprint is fully started.\"\"\"\n",
    "        self._on_started.set()\n",
    "        test_worker_started.send(sender=self.app, worker=self, consumer=consumer)\n",
    "\n",
    "    def ensure_started(self):\n",
    "        # type: () -> None\n",
    "        \"\"\"Wait for worker to be fully up and running.\n",
    "\n",
    "        Warning:\n",
    "            Worker must be started within a thread for this to work,\n",
    "            or it will block forever.\n",
    "        \"\"\"\n",
    "        self._on_started.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def start_worker(\n",
    "    app,  # type: Celery\n",
    "    concurrency=1,  # type: int\n",
    "    pool=\"solo\",  # type: str\n",
    "    loglevel=WORKER_LOGLEVEL,  # type: Union[str, int]\n",
    "    logfile=None,  # type: str\n",
    "    perform_ping_check=True,  # type: bool\n",
    "    ping_task_timeout=10.0,  # type: float\n",
    "    shutdown_timeout=10.0,  # type: float\n",
    "    **kwargs  # type: Any\n",
    "):\n",
    "    # type: (...) -> Iterable\n",
    "    \"\"\"Start embedded worker.\n",
    "\n",
    "    Yields:\n",
    "        celery.app.worker.Worker: worker instance.\n",
    "    \"\"\"\n",
    "    test_worker_starting.send(sender=app)\n",
    "\n",
    "    worker = None\n",
    "    try:\n",
    "        with _start_worker_thread(\n",
    "            app,\n",
    "            concurrency=concurrency,\n",
    "            pool=pool,\n",
    "            loglevel=loglevel,\n",
    "            logfile=logfile,\n",
    "            perform_ping_check=perform_ping_check,\n",
    "            shutdown_timeout=shutdown_timeout,\n",
    "            **kwargs\n",
    "        ) as worker:\n",
    "            if perform_ping_check:\n",
    "                from .tasks import ping\n",
    "\n",
    "                with allow_join_result():\n",
    "                    assert ping.delay().get(timeout=ping_task_timeout) == \"pong\"\n",
    "\n",
    "            yield worker\n",
    "    finally:\n",
    "        test_worker_stopped.send(sender=app, worker=worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def _start_worker_thread(\n",
    "    app: Celery,\n",
    "    concurrency: int = 1,\n",
    "    pool: str = \"solo\",\n",
    "    loglevel: Union[str, int] = WORKER_LOGLEVEL,\n",
    "    logfile: Optional[str] = None,\n",
    "    WorkController: Any = TestWorkController,\n",
    "    perform_ping_check: bool = True,\n",
    "    shutdown_timeout: float = 10.0,\n",
    "    **kwargs\n",
    ") -> Iterable[worker.WorkController]:\n",
    "    \"\"\"Start Celery worker in a thread.\n",
    "\n",
    "    Yields:\n",
    "        celery.worker.Worker: worker instance.\n",
    "    \"\"\"\n",
    "    setup_app_for_worker(app, loglevel, logfile)\n",
    "    if perform_ping_check:\n",
    "        assert \"celery.ping\" in app.tasks\n",
    "    # Make sure we can connect to the broker\n",
    "    with app.connection(hostname=os.environ.get(\"TEST_BROKER\")) as conn:\n",
    "        conn.default_channel.queue_declare\n",
    "\n",
    "    worker = WorkController(\n",
    "        app=app,\n",
    "        concurrency=concurrency,\n",
    "        hostname=anon_nodename(),\n",
    "        pool=pool,\n",
    "        loglevel=loglevel,\n",
    "        logfile=logfile,\n",
    "        # not allowed to override TestWorkController.on_consumer_ready\n",
    "        ready_callback=None,\n",
    "        without_heartbeat=kwargs.pop(\"without_heartbeat\", True),\n",
    "        without_mingle=True,\n",
    "        without_gossip=True,\n",
    "        **kwargs\n",
    "    )\n",
    "\n",
    "    t = threading.Thread(target=worker.start, daemon=True)\n",
    "    t.start()\n",
    "    worker.ensure_started()\n",
    "    _set_task_join_will_block(False)\n",
    "\n",
    "    try:\n",
    "        yield worker\n",
    "    finally:\n",
    "        from celery.worker import state\n",
    "\n",
    "        state.should_terminate = 0\n",
    "        t.join(shutdown_timeout)\n",
    "        if t.is_alive():\n",
    "            raise RuntimeError(\n",
    "                \"Worker thread failed to exit within the allocated timeout. \"\n",
    "                \"Consider raising `shutdown_timeout` if your tasks take longer \"\n",
    "                \"to execute.\"\n",
    "            )\n",
    "        state.should_terminate = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def _start_worker_process(\n",
    "    app, concurrency=1, pool=\"solo\", loglevel=WORKER_LOGLEVEL, logfile=None, **kwargs\n",
    "):\n",
    "    # type (Celery, int, str, Union[int, str], str, **Any) -> Iterable\n",
    "    \"\"\"Start worker in separate process.\n",
    "\n",
    "    Yields:\n",
    "        celery.app.worker.Worker: worker instance.\n",
    "    \"\"\"\n",
    "    from celery.apps.multi import Cluster, Node\n",
    "\n",
    "    app.set_current()\n",
    "    cluster = Cluster([Node(\"testworker1@%h\")])\n",
    "    cluster.start()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        cluster.stopwait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_app_for_worker(app: Celery, loglevel: Union[str, int], logfile: str) -> None:\n",
    "    \"\"\"Setup the app to be used for starting an embedded worker.\"\"\"\n",
    "    app.finalize()\n",
    "    app.set_current()\n",
    "    app.set_default()\n",
    "    type(app.log)._setup = False\n",
    "    app.log.setup(loglevel=loglevel, logfile=logfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}